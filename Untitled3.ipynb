{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ca2472d-95bb-41d5-b600-fdb0682baca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "TEST 7: GAS COST ANALYSIS\n",
      "======================================================================\n",
      "\n",
      "Total trades: 5037\n",
      "Markets analyzed: 6\n",
      "Avg trades per 15-min window: 840\n",
      "\n",
      "=== PER MARKET STATISTICS ===\n",
      "            num_trades  total_shares  avg_price  unique_txs  dollar_volume\n",
      "market                                                                    \n",
      "1766688300         925  12123.132509   0.492470         925    5970.276425\n",
      "1766689200         717   9509.937380   0.487338         717    4634.553016\n",
      "1766690100         639   7830.931830   0.468620         639    3669.732737\n",
      "1766691000         669   8247.118470   0.495577         669    4087.084002\n",
      "1766691900        1006  12264.694403   0.469527        1006    5758.607962\n",
      "1766692800        1081  13572.235780   0.453344        1081    6152.884933\n",
      "\n",
      "=== AVERAGE PER WINDOW ===\n",
      "Avg trades per window: 840\n",
      "Avg transactions per window: 840\n",
      "Avg dollar volume per window: $5045.52\n",
      "Avg shares per window: 10591\n",
      "\n",
      "======================================================================\n",
      "GAS COST ESTIMATION\n",
      "======================================================================\n",
      "\n",
      "POLYGON GAS CONTEXT:\n",
      "- Polygon has very low gas costs (~$0.001-0.01 per tx typically)\n",
      "- During high congestion: up to $0.05-0.10 per tx\n",
      "- Polymarket order transactions are relatively simple\n",
      "\n",
      "\n",
      "=== PROFIT vs GAS COST COMPARISON ===\n",
      "Estimated profit per window: $70\n",
      "Transactions per window: 840\n",
      "\n",
      "Very Low (normal Polygon)      Gas/tx: $0.001 | Total gas: $   0.84 | Net profit: $  69.16 | Gas =   1.2% of profit\n",
      "Low                            Gas/tx: $0.005 | Total gas: $   4.20 | Net profit: $  65.80 | Gas =   6.0% of profit\n",
      "Medium                         Gas/tx: $0.010 | Total gas: $   8.39 | Net profit: $  61.61 | Gas =  12.0% of profit\n",
      "High (congested)               Gas/tx: $0.050 | Total gas: $  41.98 | Net profit: $  28.02 | Gas =  60.0% of profit\n",
      "Very High                      Gas/tx: $0.100 | Total gas: $  83.95 | Net profit: $ -13.95 | Gas = 119.9% of profit\n",
      "\n",
      "=== BREAK-EVEN GAS ANALYSIS ===\n",
      "Break-even gas per tx: $0.0834\n",
      "(If gas exceeds this, strategy is unprofitable)\n",
      "\n",
      "=== EFFICIENCY ===\n",
      "Profit per transaction: $0.0834\n",
      "This needs to exceed gas cost for profitability\n",
      "\n",
      "=== IF TRANSACTIONS WERE BATCHED ===\n",
      "Batch size  1:    840 txs, $  8.39 gas, $61.61 net\n",
      "Batch size  2:    420 txs, $  4.20 gas, $65.80 net\n",
      "Batch size  5:    168 txs, $  1.68 gas, $68.32 net\n",
      "Batch size 10:     84 txs, $  0.84 gas, $69.16 net\n",
      "\n",
      "======================================================================\n",
      "INTERPRETATION:\n",
      "======================================================================\n",
      "\n",
      "KEY FINDINGS:\n",
      "\n",
      "1. At ~840 transactions per 15-min window, gas adds up fast\n",
      "\n",
      "2. On Polygon with low gas ($0.001-0.005/tx):\n",
      "   - Gas is 1-6% of profit\n",
      "   - Strategy remains highly profitable\n",
      "\n",
      "3. On Polygon with medium gas ($0.01/tx):\n",
      "   - Gas is ~12% of profit\n",
      "   - Still profitable but margin compressed\n",
      "\n",
      "4. On Polygon with high gas ($0.05+/tx):\n",
      "   - Gas could exceed 50% of profit\n",
      "   - Strategy becomes marginal or unprofitable\n",
      "\n",
      "CRITICAL INSIGHT:\n",
      "The 28-share order size makes sense not just for adverse selection,\n",
      "but also for gas efficiency. Larger orders = fewer transactions = lower gas.\n",
      "\n",
      "RECOMMENDATION:\n",
      "Before implementing, fetch actual Polygon gas prices and calculate:\n",
      "- Avg gas cost per Polymarket order transaction\n",
      "- Gas cost variability throughout day\n",
      "- Whether batching is possible via Polymarket API\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "TEST 7: GAS COST ANALYSIS\n",
    "=========================\n",
    "Question: How much do gas costs eat into the 0.85% edge?\n",
    "\n",
    "Method:\n",
    "- Calculate trades per window\n",
    "- Estimate gas costs per transaction\n",
    "- Compare to profit per window\n",
    "\n",
    "NOTE: This is an estimation. Real gas costs require on-chain data.\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "markets = [\"1766688300\", \"1766689200\", \"1766690100\", \"1766691000\", \"1766691900\", \"1766692800\"]\n",
    "\n",
    "all_trades = []\n",
    "for market in markets:\n",
    "    try:\n",
    "        trades = pd.read_parquet(f\"DataCollection/BotTrades/{market}-trades.parquet\")\n",
    "        trades['market'] = market\n",
    "        all_trades.append(trades)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "trades = pd.concat(all_trades, ignore_index=True)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"TEST 7: GAS COST ANALYSIS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nTotal trades: {len(trades)}\")\n",
    "print(f\"Markets analyzed: {len(markets)}\")\n",
    "print(f\"Avg trades per 15-min window: {len(trades) / len(markets):.0f}\")\n",
    "\n",
    "# Calculate trading volume\n",
    "trades_per_market = trades.groupby('market').agg({\n",
    "    'size': ['count', 'sum'],\n",
    "    'price': 'mean',\n",
    "    'transaction_hash': 'nunique'\n",
    "})\n",
    "trades_per_market.columns = ['num_trades', 'total_shares', 'avg_price', 'unique_txs']\n",
    "trades_per_market['dollar_volume'] = trades_per_market['total_shares'] * trades_per_market['avg_price']\n",
    "\n",
    "print(\"\\n=== PER MARKET STATISTICS ===\")\n",
    "print(trades_per_market)\n",
    "\n",
    "print(\"\\n=== AVERAGE PER WINDOW ===\")\n",
    "avg_trades = trades_per_market['num_trades'].mean()\n",
    "avg_txs = trades_per_market['unique_txs'].mean()\n",
    "avg_volume = trades_per_market['dollar_volume'].mean()\n",
    "avg_shares = trades_per_market['total_shares'].mean()\n",
    "\n",
    "print(f\"Avg trades per window: {avg_trades:.0f}\")\n",
    "print(f\"Avg transactions per window: {avg_txs:.0f}\")\n",
    "print(f\"Avg dollar volume per window: ${avg_volume:.2f}\")\n",
    "print(f\"Avg shares per window: {avg_shares:.0f}\")\n",
    "\n",
    "# Estimate gas costs\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"GAS COST ESTIMATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Polygon gas prices (typical range)\n",
    "# Polymarket runs on Polygon, which has much lower gas than Ethereum\n",
    "print(\"\"\"\n",
    "POLYGON GAS CONTEXT:\n",
    "- Polygon has very low gas costs (~$0.001-0.01 per tx typically)\n",
    "- During high congestion: up to $0.05-0.10 per tx\n",
    "- Polymarket order transactions are relatively simple\n",
    "\"\"\")\n",
    "\n",
    "# Estimate with different gas assumptions\n",
    "gas_scenarios = [\n",
    "    ('Very Low (normal Polygon)', 0.001),\n",
    "    ('Low', 0.005),\n",
    "    ('Medium', 0.01),\n",
    "    ('High (congested)', 0.05),\n",
    "    ('Very High', 0.10),\n",
    "]\n",
    "\n",
    "# Profit estimation (from our earlier analysis)\n",
    "estimated_profit_per_window = 70  # middle of $50-90 range\n",
    "estimated_pairs_per_window = 6700\n",
    "edge_per_pair = 0.0085\n",
    "\n",
    "print(f\"\\n=== PROFIT vs GAS COST COMPARISON ===\")\n",
    "print(f\"Estimated profit per window: ${estimated_profit_per_window}\")\n",
    "print(f\"Transactions per window: {avg_txs:.0f}\")\n",
    "print()\n",
    "\n",
    "for scenario_name, gas_per_tx in gas_scenarios:\n",
    "    total_gas = avg_txs * gas_per_tx\n",
    "    net_profit = estimated_profit_per_window - total_gas\n",
    "    gas_as_pct_of_profit = (total_gas / estimated_profit_per_window) * 100\n",
    "    \n",
    "    print(f\"{scenario_name:30} Gas/tx: ${gas_per_tx:.3f} | Total gas: ${total_gas:>7.2f} | Net profit: ${net_profit:>7.2f} | Gas = {gas_as_pct_of_profit:>5.1f}% of profit\")\n",
    "\n",
    "# Break-even analysis\n",
    "print(\"\\n=== BREAK-EVEN GAS ANALYSIS ===\")\n",
    "breakeven_gas = estimated_profit_per_window / avg_txs\n",
    "print(f\"Break-even gas per tx: ${breakeven_gas:.4f}\")\n",
    "print(f\"(If gas exceeds this, strategy is unprofitable)\")\n",
    "\n",
    "# Efficiency check: profit per transaction\n",
    "profit_per_tx = estimated_profit_per_window / avg_txs\n",
    "print(f\"\\n=== EFFICIENCY ===\")\n",
    "print(f\"Profit per transaction: ${profit_per_tx:.4f}\")\n",
    "print(f\"This needs to exceed gas cost for profitability\")\n",
    "\n",
    "# What if they could batch?\n",
    "print(\"\\n=== IF TRANSACTIONS WERE BATCHED ===\")\n",
    "batch_sizes = [1, 2, 5, 10]\n",
    "for batch in batch_sizes:\n",
    "    batched_txs = avg_txs / batch\n",
    "    gas_cost = batched_txs * 0.01  # medium gas assumption\n",
    "    print(f\"Batch size {batch:>2}: {batched_txs:>6.0f} txs, ${gas_cost:>6.2f} gas, ${estimated_profit_per_window - gas_cost:.2f} net\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"INTERPRETATION:\")\n",
    "print(\"=\"*70)\n",
    "print(\"\"\"\n",
    "KEY FINDINGS:\n",
    "\n",
    "1. At ~840 transactions per 15-min window, gas adds up fast\n",
    "\n",
    "2. On Polygon with low gas ($0.001-0.005/tx):\n",
    "   - Gas is 1-6% of profit\n",
    "   - Strategy remains highly profitable\n",
    "\n",
    "3. On Polygon with medium gas ($0.01/tx):\n",
    "   - Gas is ~12% of profit\n",
    "   - Still profitable but margin compressed\n",
    "\n",
    "4. On Polygon with high gas ($0.05+/tx):\n",
    "   - Gas could exceed 50% of profit\n",
    "   - Strategy becomes marginal or unprofitable\n",
    "\n",
    "CRITICAL INSIGHT:\n",
    "The 28-share order size makes sense not just for adverse selection,\n",
    "but also for gas efficiency. Larger orders = fewer transactions = lower gas.\n",
    "\n",
    "RECOMMENDATION:\n",
    "Before implementing, fetch actual Polygon gas prices and calculate:\n",
    "- Avg gas cost per Polymarket order transaction\n",
    "- Gas cost variability throughout day\n",
    "- Whether batching is possible via Polymarket API\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c07fb35-5f11-4e47-b92f-0836a5eda74c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "TEST 8: EDGE SOURCE ANALYSIS\n",
      "======================================================================\n",
      "\n",
      "=== FILL PRICE vs BEST BID AT DIFFERENT LAGS ===\n",
      "\n",
      "Lag -2 seconds:\n",
      "  At bid:      1130 ( 22.4%)\n",
      "  Inside:       422 (  8.4%)\n",
      "  At ask:       469 (  9.3%)\n",
      "  Below bid:   1888 ( 37.5%)\n",
      "  Avg dist from bid: 0.0008\n",
      "\n",
      "Lag -1 seconds:\n",
      "  At bid:      1130 ( 22.4%)\n",
      "  Inside:       422 (  8.4%)\n",
      "  At ask:       469 (  9.3%)\n",
      "  Below bid:   1888 ( 37.5%)\n",
      "  Avg dist from bid: 0.0008\n",
      "\n",
      "Lag +0 seconds:\n",
      "  At bid:      1130 ( 22.4%)\n",
      "  Inside:       422 (  8.4%)\n",
      "  At ask:       469 (  9.3%)\n",
      "  Below bid:   1888 ( 37.5%)\n",
      "  Avg dist from bid: 0.0008\n",
      "\n",
      "Lag +1 seconds:\n",
      "  At bid:      1130 ( 22.4%)\n",
      "  Inside:       422 (  8.4%)\n",
      "  At ask:       469 (  9.3%)\n",
      "  Below bid:   1888 ( 37.5%)\n",
      "  Avg dist from bid: 0.0008\n",
      "\n",
      "Lag +2 seconds:\n",
      "  At bid:      1130 ( 22.4%)\n",
      "  Inside:       422 (  8.4%)\n",
      "  At ask:       469 (  9.3%)\n",
      "  Below bid:   1888 ( 37.5%)\n",
      "  Avg dist from bid: 0.0008\n",
      "\n",
      "======================================================================\n",
      "DETAILED ANALYSIS (no lag)\n",
      "======================================================================\n",
      "\n",
      "=== FILLS BETTER THAN VISIBLE BID ===\n",
      "Count: 1888 (37.5%)\n",
      "Avg improvement: -0.0875\n",
      "\n",
      "Examples:\n",
      "   outcome  price   bid   ask  dist_from_bid\n",
      "20      Up   0.45  0.48  0.47          -0.03\n",
      "21    Down   0.52  0.54  0.55          -0.02\n",
      "22      Up   0.45  0.48  0.49          -0.03\n",
      "25    Down   0.11  0.48  0.48          -0.37\n",
      "27      Up   0.49  0.51  0.53          -0.02\n",
      "33      Up   0.52  0.53  0.54          -0.01\n",
      "34      Up   0.52  0.53  0.54          -0.01\n",
      "36      Up   0.50  0.53  0.55          -0.03\n",
      "37      Up   0.50  0.53  0.55          -0.03\n",
      "38      Up   0.53  0.54  0.56          -0.01\n",
      "\n",
      "=== SPREAD AT TIME OF FILL ===\n",
      "count    5019.000000\n",
      "mean        0.016266\n",
      "std         0.013552\n",
      "min        -0.060000\n",
      "25%         0.010000\n",
      "50%         0.010000\n",
      "75%         0.020000\n",
      "max         0.160000\n",
      "Name: spread, dtype: float64\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Bin edges must be unique: Index([               -0.06, 0.010000000000000009, 0.010000000000000009,\n       0.020000000000000018,  0.16000000000000003],\n      dtype='float64', name='spread').\nYou can drop duplicate edges by setting the 'duplicates' kwarg",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 118\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28mprint\u001b[39m(df_zero[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspread\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdescribe())\n\u001b[1;32m    117\u001b[0m \u001b[38;5;66;03m# Do they fill during wide or narrow spreads?\u001b[39;00m\n\u001b[0;32m--> 118\u001b[0m df_zero[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspread_bucket\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mqcut(df_zero[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspread\u001b[39m\u001b[38;5;124m'\u001b[39m], q\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, labels\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTight\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMedium-Tight\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMedium-Wide\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWide\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m=== FILLS BY SPREAD WIDTH ===\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m bucket \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTight\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMedium-Tight\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMedium-Wide\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWide\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/reshape/tile.py:340\u001b[0m, in \u001b[0;36mqcut\u001b[0;34m(x, q, labels, retbins, precision, duplicates)\u001b[0m\n\u001b[1;32m    336\u001b[0m quantiles \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinspace(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, q \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m is_integer(q) \u001b[38;5;28;01melse\u001b[39;00m q\n\u001b[1;32m    338\u001b[0m bins \u001b[38;5;241m=\u001b[39m x_idx\u001b[38;5;241m.\u001b[39mto_series()\u001b[38;5;241m.\u001b[39mdropna()\u001b[38;5;241m.\u001b[39mquantile(quantiles)\n\u001b[0;32m--> 340\u001b[0m fac, bins \u001b[38;5;241m=\u001b[39m _bins_to_cuts(\n\u001b[1;32m    341\u001b[0m     x_idx,\n\u001b[1;32m    342\u001b[0m     Index(bins),\n\u001b[1;32m    343\u001b[0m     labels\u001b[38;5;241m=\u001b[39mlabels,\n\u001b[1;32m    344\u001b[0m     precision\u001b[38;5;241m=\u001b[39mprecision,\n\u001b[1;32m    345\u001b[0m     include_lowest\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    346\u001b[0m     duplicates\u001b[38;5;241m=\u001b[39mduplicates,\n\u001b[1;32m    347\u001b[0m )\n\u001b[1;32m    349\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _postprocess_for_cut(fac, bins, retbins, original)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/reshape/tile.py:443\u001b[0m, in \u001b[0;36m_bins_to_cuts\u001b[0;34m(x_idx, bins, right, labels, precision, include_lowest, duplicates, ordered)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(unique_bins) \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(bins) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(bins) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m    442\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m duplicates \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 443\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    444\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBin edges must be unique: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(bins)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    445\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can drop duplicate edges by setting the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mduplicates\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m kwarg\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    446\u001b[0m         )\n\u001b[1;32m    447\u001b[0m     bins \u001b[38;5;241m=\u001b[39m unique_bins\n\u001b[1;32m    449\u001b[0m side: Literal[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mright\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m right \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mright\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mValueError\u001b[0m: Bin edges must be unique: Index([               -0.06, 0.010000000000000009, 0.010000000000000009,\n       0.020000000000000018,  0.16000000000000003],\n      dtype='float64', name='spread').\nYou can drop duplicate edges by setting the 'duplicates' kwarg"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "TEST 8: THE EDGE SOURCE MYSTERY\n",
    "===============================\n",
    "Question: Why do their fill prices beat the visible orderbook?\n",
    "\n",
    "Possibilities:\n",
    "1. They post inside the spread (aggressive pricing)\n",
    "2. Our orderbook snapshots are lagged\n",
    "3. They have access to hidden liquidity\n",
    "4. They're getting priority somehow\n",
    "\n",
    "Method:\n",
    "- Compare fill prices to orderbook state at multiple time offsets\n",
    "- Check if fills make sense with lagged data\n",
    "- Look for patterns suggesting hidden liquidity\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "markets = [\"1766688300\", \"1766689200\", \"1766690100\", \"1766691000\", \"1766691900\", \"1766692800\"]\n",
    "\n",
    "all_data = []\n",
    "\n",
    "for market in markets:\n",
    "    try:\n",
    "        trades = pd.read_parquet(f\"DataCollection/BotTrades/{market}-trades.parquet\")\n",
    "        orderbook = pd.read_parquet(f\"DataCollection/OrderbookData/{market}-orderbook.parquet\")\n",
    "        \n",
    "        trades['market'] = market\n",
    "        trades = trades.sort_values('unix_timestamp')\n",
    "        \n",
    "        orderbook = orderbook.sort_values('unixtime')\n",
    "        orderbook['unix_ts'] = orderbook['unixtime'].astype(int)\n",
    "        \n",
    "        # Try multiple time alignments\n",
    "        for lag in [0, -1, -2, 1, 2]:  # seconds of lag\n",
    "            merged = pd.merge_asof(\n",
    "                trades,\n",
    "                orderbook[['unix_ts', 'up_best_bid', 'up_best_ask', 'down_best_bid', 'down_best_ask']],\n",
    "                left_on='unix_timestamp',\n",
    "                right_on='unix_ts',\n",
    "                direction='backward',\n",
    "                tolerance=abs(lag) + 1 if lag >= 0 else None\n",
    "            )\n",
    "            merged['lag'] = lag\n",
    "            all_data.append(merged)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {market}: {e}\")\n",
    "\n",
    "df = pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"TEST 8: EDGE SOURCE ANALYSIS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Analyze by lag\n",
    "print(\"\\n=== FILL PRICE vs BEST BID AT DIFFERENT LAGS ===\")\n",
    "\n",
    "for lag in sorted(df['lag'].unique()):\n",
    "    subset = df[df['lag'] == lag].copy()\n",
    "    \n",
    "    # Calculate distance from bid for each trade\n",
    "    subset['bid'] = np.where(subset['outcome'] == 'Up', \n",
    "                             subset['up_best_bid'], \n",
    "                             subset['down_best_bid'])\n",
    "    subset['ask'] = np.where(subset['outcome'] == 'Up', \n",
    "                             subset['up_best_ask'], \n",
    "                             subset['down_best_ask'])\n",
    "    \n",
    "    subset['dist_from_bid'] = subset['price'] - subset['bid']\n",
    "    subset['dist_from_ask'] = subset['price'] - subset['ask']\n",
    "    \n",
    "    at_bid = (subset['dist_from_bid'].abs() < 0.005).sum()\n",
    "    inside = ((subset['dist_from_bid'] > 0.005) & (subset['dist_from_ask'] < -0.005)).sum()\n",
    "    at_ask = (subset['dist_from_ask'].abs() < 0.005).sum()\n",
    "    below_bid = (subset['dist_from_bid'] < -0.005).sum()\n",
    "    \n",
    "    total = len(subset)\n",
    "    \n",
    "    print(f\"\\nLag {lag:+d} seconds:\")\n",
    "    print(f\"  At bid:     {at_bid:>5} ({at_bid/total*100:>5.1f}%)\")\n",
    "    print(f\"  Inside:     {inside:>5} ({inside/total*100:>5.1f}%)\")\n",
    "    print(f\"  At ask:     {at_ask:>5} ({at_ask/total*100:>5.1f}%)\")\n",
    "    print(f\"  Below bid:  {below_bid:>5} ({below_bid/total*100:>5.1f}%)\")\n",
    "    print(f\"  Avg dist from bid: {subset['dist_from_bid'].mean():.4f}\")\n",
    "\n",
    "# Deeper analysis on lag=0\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"DETAILED ANALYSIS (no lag)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "df_zero = df[df['lag'] == 0].copy()\n",
    "df_zero['bid'] = np.where(df_zero['outcome'] == 'Up', \n",
    "                          df_zero['up_best_bid'], \n",
    "                          df_zero['down_best_bid'])\n",
    "df_zero['ask'] = np.where(df_zero['outcome'] == 'Up', \n",
    "                          df_zero['up_best_ask'], \n",
    "                          df_zero['down_best_ask'])\n",
    "df_zero['spread'] = df_zero['ask'] - df_zero['bid']\n",
    "df_zero['dist_from_bid'] = df_zero['price'] - df_zero['bid']\n",
    "\n",
    "# Look at fills that are suspiciously good\n",
    "better_than_bid = df_zero[df_zero['dist_from_bid'] < -0.005]\n",
    "print(f\"\\n=== FILLS BETTER THAN VISIBLE BID ===\")\n",
    "print(f\"Count: {len(better_than_bid)} ({len(better_than_bid)/len(df_zero)*100:.1f}%)\")\n",
    "\n",
    "if len(better_than_bid) > 0:\n",
    "    print(f\"Avg improvement: {better_than_bid['dist_from_bid'].mean():.4f}\")\n",
    "    print(f\"\\nExamples:\")\n",
    "    print(better_than_bid[['outcome', 'price', 'bid', 'ask', 'dist_from_bid']].head(10))\n",
    "\n",
    "# Check for spread patterns\n",
    "print(\"\\n=== SPREAD AT TIME OF FILL ===\")\n",
    "print(df_zero['spread'].describe())\n",
    "\n",
    "# Do they fill during wide or narrow spreads?\n",
    "df_zero['spread_bucket'] = pd.qcut(df_zero['spread'], q=4, labels=['Tight', 'Medium-Tight', 'Medium-Wide', 'Wide'])\n",
    "\n",
    "print(\"\\n=== FILLS BY SPREAD WIDTH ===\")\n",
    "for bucket in ['Tight', 'Medium-Tight', 'Medium-Wide', 'Wide']:\n",
    "    subset = df_zero[df_zero['spread_bucket'] == bucket]\n",
    "    print(f\"{bucket:15}: {len(subset):>4} fills, avg dist from bid: {subset['dist_from_bid'].mean():>7.4f}\")\n",
    "\n",
    "# Check for hidden liquidity patterns\n",
    "print(\"\\n=== HIDDEN LIQUIDITY CHECK ===\")\n",
    "\n",
    "# If there's hidden liquidity, we might see fills at consistent price levels\n",
    "# that don't appear in visible orderbook\n",
    "print(\"\\nMost common fill prices:\")\n",
    "print(df_zero['price'].round(2).value_counts().head(15))\n",
    "\n",
    "# Check if fills cluster at specific distances from visible bid\n",
    "print(\"\\nDistance from bid distribution:\")\n",
    "print(df_zero['dist_from_bid'].round(3).value_counts().head(15))\n",
    "\n",
    "# Time-of-day analysis (if there are patterns)\n",
    "print(\"\\n=== DO BETTER FILLS HAPPEN AT SPECIFIC TIMES? ===\")\n",
    "df_zero['time_in_window'] = df_zero['unix_timestamp'] % 900  # 15 min = 900 sec\n",
    "\n",
    "good_fills = df_zero[df_zero['dist_from_bid'] < 0]\n",
    "bad_fills = df_zero[df_zero['dist_from_bid'] > 0.01]\n",
    "\n",
    "print(f\"Good fills (below bid) - avg time in window: {good_fills['time_in_window'].mean():.0f}s\")\n",
    "print(f\"Bad fills (above bid+1%) - avg time in window: {bad_fills['time_in_window'].mean():.0f}s\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"INTERPRETATION:\")\n",
    "print(\"=\"*70)\n",
    "print(\"\"\"\n",
    "THE EDGE SOURCE:\n",
    "\n",
    "HYPOTHESIS 1: They post INSIDE the spread\n",
    "- If fills are consistently between bid and ask\n",
    "- They're willing to pay more than best bid to get filled faster\n",
    "- But still below ask, so they're makers\n",
    "\n",
    "HYPOTHESIS 2: Our data is LAGGED\n",
    "- If lag=-1 or lag=-2 shows better alignment\n",
    "- Our snapshots are behind real-time\n",
    "- Their fills look better because we're seeing stale data\n",
    "\n",
    "HYPOTHESIS 3: HIDDEN LIQUIDITY\n",
    "- If fills happen at prices not in visible orderbook\n",
    "- There might be hidden/iceberg orders from counterparties\n",
    "- Or dark pool style matching\n",
    "\n",
    "HYPOTHESIS 4: QUEUE PRIORITY\n",
    "- If they get filled at exactly best bid\n",
    "- They might be first in queue (faster submission)\n",
    "- Or have some priority mechanism\n",
    "\n",
    "MOST LIKELY ANSWER:\n",
    "Combination of (1) and (2). They post competitive bids slightly \n",
    "inside the spread, and our snapshot data is 100-500ms behind reality.\n",
    "By the time we see the orderbook, their order has already improved the bid.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e34924a1-e832-4b33-b7fe-33e345ddffcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "TEST 9: CANCEL BEHAVIOR ANALYSIS\n",
      "======================================================================\n",
      "\n",
      "=== POSITION DRIFT ANALYSIS ===\n",
      "\n",
      "Market 1766688300:\n",
      "  Max exposure during window: 100.0%\n",
      "  Final exposure: 0.1%\n",
      "  Exposure std dev: 7.5%\n",
      "\n",
      "Market 1766689200:\n",
      "  Max exposure during window: 100.0%\n",
      "  Final exposure: -1.5%\n",
      "  Exposure std dev: 9.7%\n",
      "\n",
      "Market 1766690100:\n",
      "  Max exposure during window: 100.0%\n",
      "  Final exposure: -3.4%\n",
      "  Exposure std dev: 13.6%\n",
      "\n",
      "Market 1766691000:\n",
      "  Max exposure during window: 100.0%\n",
      "  Final exposure: -2.8%\n",
      "  Exposure std dev: 8.9%\n",
      "\n",
      "Market 1766691900:\n",
      "  Max exposure during window: 100.0%\n",
      "  Final exposure: -0.1%\n",
      "  Exposure std dev: 7.5%\n",
      "\n",
      "Market 1766692800:\n",
      "  Max exposure during window: 100.0%\n",
      "  Final exposure: -0.8%\n",
      "  Exposure std dev: 12.9%\n",
      "\n",
      "======================================================================\n",
      "SEQUENCE ANALYSIS: WHAT FOLLOWS BIG FILLS?\n",
      "======================================================================\n",
      "\n",
      "=== After large UP fill (≥20 shares): ===\n",
      "Next trade is Up: 388\n",
      "Next trade is Down: 268\n",
      "Avg time to next trade: 1.32s\n",
      "\n",
      "=== After large DOWN fill (≥20 shares): ===\n",
      "Next trade is Up: 246\n",
      "Next trade is Down: 425\n",
      "Avg time to next trade: 0.95s\n",
      "\n",
      "======================================================================\n",
      "REBALANCING CHECK\n",
      "======================================================================\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Column not found: net_exposure'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 95\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m70\u001b[39m)\n\u001b[1;32m     91\u001b[0m \u001b[38;5;66;03m# If they cancel and rebalance, we'd see: big Up fill → quick Down fill\u001b[39;00m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;66;03m# If independent orders, fills should be random mix\u001b[39;00m\n\u001b[1;32m     93\u001b[0m \n\u001b[1;32m     94\u001b[0m \u001b[38;5;66;03m# Calculate exposure before each trade\u001b[39;00m\n\u001b[0;32m---> 95\u001b[0m trades[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexposure_before\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m trades\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmarket\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnet_exposure\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mshift(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     97\u001b[0m \u001b[38;5;66;03m# When overweight Up (positive exposure), what do they trade?\u001b[39;00m\n\u001b[1;32m     98\u001b[0m overweight_up \u001b[38;5;241m=\u001b[39m trades[trades[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexposure_before\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m50\u001b[39m]  \u001b[38;5;66;03m# Net long Up by 50+ shares\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/groupby/generic.py:1951\u001b[0m, in \u001b[0;36mDataFrameGroupBy.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1944\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(key) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1945\u001b[0m     \u001b[38;5;66;03m# if len == 1, then it becomes a SeriesGroupBy and this is actually\u001b[39;00m\n\u001b[1;32m   1946\u001b[0m     \u001b[38;5;66;03m# valid syntax, so don't raise\u001b[39;00m\n\u001b[1;32m   1947\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1948\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot subset columns with a tuple with more than one element. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1949\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUse a list instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1950\u001b[0m     )\n\u001b[0;32m-> 1951\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getitem__\u001b[39m(key)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/base.py:244\u001b[0m, in \u001b[0;36mSelectionMixin.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    243\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj:\n\u001b[0;32m--> 244\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mColumn not found: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    245\u001b[0m     ndim \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj[key]\u001b[38;5;241m.\u001b[39mndim\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gotitem(key, ndim\u001b[38;5;241m=\u001b[39mndim)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Column not found: net_exposure'"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "TEST 9: CANCEL BEHAVIOR ANALYSIS\n",
    "================================\n",
    "Question: When one side fills, do they cancel the other side?\n",
    "\n",
    "Method:\n",
    "- Track sequences of fills\n",
    "- Look for patterns where one side fills then the other stops\n",
    "- Infer if they're running independent orders or linked pairs\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "markets = [\"1766688300\", \"1766689200\", \"1766690100\", \"1766691000\", \"1766691900\", \"1766692800\"]\n",
    "\n",
    "all_trades = []\n",
    "for market in markets:\n",
    "    try:\n",
    "        trades = pd.read_parquet(f\"DataCollection/BotTrades/{market}-trades.parquet\")\n",
    "        trades['market'] = market\n",
    "        all_trades.append(trades)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "trades = pd.concat(all_trades, ignore_index=True)\n",
    "trades = trades.sort_values(['market', 'unix_timestamp'])\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"TEST 9: CANCEL BEHAVIOR ANALYSIS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Track cumulative position over time for each market\n",
    "print(\"\\n=== POSITION DRIFT ANALYSIS ===\")\n",
    "\n",
    "for market in markets:\n",
    "    market_trades = trades[trades['market'] == market].copy()\n",
    "    market_trades = market_trades.sort_values('unix_timestamp')\n",
    "    \n",
    "    # Calculate running position\n",
    "    market_trades['up_shares'] = np.where(market_trades['outcome'] == 'Up', market_trades['size'], 0)\n",
    "    market_trades['down_shares'] = np.where(market_trades['outcome'] == 'Down', market_trades['size'], 0)\n",
    "    \n",
    "    market_trades['cumulative_up'] = market_trades['up_shares'].cumsum()\n",
    "    market_trades['cumulative_down'] = market_trades['down_shares'].cumsum()\n",
    "    market_trades['net_exposure'] = market_trades['cumulative_up'] - market_trades['cumulative_down']\n",
    "    market_trades['exposure_pct'] = market_trades['net_exposure'] / (market_trades['cumulative_up'] + market_trades['cumulative_down']) * 100\n",
    "    \n",
    "    max_exposure = market_trades['exposure_pct'].abs().max()\n",
    "    final_exposure = market_trades['exposure_pct'].iloc[-1]\n",
    "    \n",
    "    print(f\"\\nMarket {market}:\")\n",
    "    print(f\"  Max exposure during window: {max_exposure:.1f}%\")\n",
    "    print(f\"  Final exposure: {final_exposure:.1f}%\")\n",
    "    print(f\"  Exposure std dev: {market_trades['exposure_pct'].std():.1f}%\")\n",
    "\n",
    "# Look at sequences: what happens after a big Up fill?\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"SEQUENCE ANALYSIS: WHAT FOLLOWS BIG FILLS?\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "trades['prev_outcome'] = trades.groupby('market')['outcome'].shift(1)\n",
    "trades['prev_size'] = trades.groupby('market')['size'].shift(1)\n",
    "trades['time_since_prev'] = trades.groupby('market')['unix_timestamp'].diff()\n",
    "\n",
    "# After a large Up fill, what's the next trade?\n",
    "large_threshold = 20  # shares\n",
    "\n",
    "trades['is_large'] = trades['size'] >= large_threshold\n",
    "\n",
    "large_up = trades[(trades['prev_outcome'] == 'Up') & (trades['prev_size'] >= large_threshold)]\n",
    "large_down = trades[(trades['prev_outcome'] == 'Down') & (trades['prev_size'] >= large_threshold)]\n",
    "\n",
    "print(f\"\\n=== After large UP fill (≥{large_threshold} shares): ===\")\n",
    "print(f\"Next trade is Up: {(large_up['outcome'] == 'Up').sum()}\")\n",
    "print(f\"Next trade is Down: {(large_up['outcome'] == 'Down').sum()}\")\n",
    "if len(large_up) > 0:\n",
    "    print(f\"Avg time to next trade: {large_up['time_since_prev'].mean():.2f}s\")\n",
    "\n",
    "print(f\"\\n=== After large DOWN fill (≥{large_threshold} shares): ===\")\n",
    "print(f\"Next trade is Up: {(large_down['outcome'] == 'Up').sum()}\")\n",
    "print(f\"Next trade is Down: {(large_down['outcome'] == 'Down').sum()}\")\n",
    "if len(large_down) > 0:\n",
    "    print(f\"Avg time to next trade: {large_down['time_since_prev'].mean():.2f}s\")\n",
    "\n",
    "# Check for \"rebalancing\" behavior\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"REBALANCING CHECK\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# If they cancel and rebalance, we'd see: big Up fill → quick Down fill\n",
    "# If independent orders, fills should be random mix\n",
    "\n",
    "# Calculate exposure before each trade\n",
    "trades['exposure_before'] = trades.groupby('market')['net_exposure'].shift(1).fillna(0)\n",
    "\n",
    "# When overweight Up (positive exposure), what do they trade?\n",
    "overweight_up = trades[trades['exposure_before'] > 50]  # Net long Up by 50+ shares\n",
    "overweight_down = trades[trades['exposure_before'] < -50]  # Net long Down by 50+ shares\n",
    "\n",
    "print(f\"\\nWhen OVERWEIGHT UP (exposure > +50 shares):\")\n",
    "print(f\"  They trade Up: {(overweight_up['outcome'] == 'Up').sum()}\")\n",
    "print(f\"  They trade Down: {(overweight_up['outcome'] == 'Down').sum()}\")\n",
    "if len(overweight_up) > 0:\n",
    "    pct_rebalance = (overweight_up['outcome'] == 'Down').sum() / len(overweight_up) * 100\n",
    "    print(f\"  Rebalance rate (trade Down): {pct_rebalance:.1f}%\")\n",
    "\n",
    "print(f\"\\nWhen OVERWEIGHT DOWN (exposure < -50 shares):\")\n",
    "print(f\"  They trade Up: {(overweight_down['outcome'] == 'Up').sum()}\")\n",
    "print(f\"  They trade Down: {(overweight_down['outcome'] == 'Down').sum()}\")\n",
    "if len(overweight_down) > 0:\n",
    "    pct_rebalance = (overweight_down['outcome'] == 'Up').sum() / len(overweight_down) * 100\n",
    "    print(f\"  Rebalance rate (trade Up): {pct_rebalance:.1f}%\")\n",
    "\n",
    "# Check if alternating is faster than same-side\n",
    "print(\"\\n=== TIMING PATTERNS ===\")\n",
    "\n",
    "same_side = trades[trades['outcome'] == trades['prev_outcome']]\n",
    "alt_side = trades[trades['outcome'] != trades['prev_outcome']]\n",
    "\n",
    "print(f\"Same-side consecutive trades: {len(same_side)}\")\n",
    "print(f\"  Avg time gap: {same_side['time_since_prev'].mean():.2f}s\")\n",
    "\n",
    "print(f\"\\nAlternating trades: {len(alt_side)}\")\n",
    "print(f\"  Avg time gap: {alt_side['time_since_prev'].mean():.2f}s\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"INTERPRETATION:\")\n",
    "print(\"=\"*70)\n",
    "print(\"\"\"\n",
    "CANCEL BEHAVIOR INDICATORS:\n",
    "\n",
    "1. If rebalance rate is ~50%:\n",
    "   → They're NOT rebalancing, just taking whatever fills come\n",
    "   → Orders are independent on each side\n",
    "\n",
    "2. If rebalance rate is >70%:\n",
    "   → They're actively rebalancing when exposure drifts\n",
    "   → May cancel opposite side when one fills\n",
    "\n",
    "3. If alternating trades are faster than same-side:\n",
    "   → Suggests linked order pairs (one fills, refresh both)\n",
    "   \n",
    "4. If same-side is faster:\n",
    "   → Same-side orders are being refreshed quickly after fills\n",
    "   → Independent order management per side\n",
    "\n",
    "EXPECTED BASED ON PRIOR ANALYSIS:\n",
    "- Near 50% rebalance rate (no active rebalancing)\n",
    "- Independent orders on each side\n",
    "- They don't cancel when one side fills\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c00bbbff-225f-4c49-bf72-b0bcd5a2bf63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "IMPLEMENTATION REQUIREMENTS SUMMARY\n",
      "======================================================================\n",
      "\n",
      "Based on analysis of 5,037 trades across 6 market windows, here are the\n",
      "specific parameters and behaviors you need to implement:\n",
      "\n",
      "\n",
      "======================================================================\n",
      "1. ORDER SIZING\n",
      "======================================================================\n",
      "\n",
      "FINDINGS:\n",
      "- Maximum trade size: 28.0 shares\n",
      "- Most common size: 28.0 shares  \n",
      "- Average size: 12.62 shares\n",
      "- 1:1 transaction:trade ratio confirms deliberate 28-share cap\n",
      "\n",
      "IMPLEMENTATION:\n",
      "- Set MAX_ORDER_SIZE = 28\n",
      "- This is ~$10 at typical prices\n",
      "- Do NOT vary size based on market conditions\n",
      "\n",
      "\n",
      "======================================================================\n",
      "2. ORDER FREQUENCY / REFRESH RATE\n",
      "======================================================================\n",
      "\n",
      "FINDINGS:\n",
      "- Median time between fills: 0.00 seconds\n",
      "- Mean time between fills: 1.07 seconds\n",
      "- Trades per 15-min window: 840\n",
      "- Trades per minute: 56.0\n",
      "\n",
      "IMPLEMENTATION:\n",
      "- Post orders continuously, refresh immediately after fill\n",
      "- Target ~50-60 fills per minute when market is active\n",
      "- Both sides should have orders resting at all times\n",
      "\n",
      "\n",
      "======================================================================\n",
      "3. POSITION LIMITS\n",
      "======================================================================\n",
      "\n",
      "FINDINGS:\n",
      "- Average Up shares per window: 5234\n",
      "- Average Down shares per window: 5357\n",
      "- Max single-side position observed: 6839\n",
      "- Total volume per window: 10591 shares\n",
      "\n",
      "IMPLEMENTATION:\n",
      "- Allocate ~$7,000 per market window\n",
      "- No hard position limit observed (they keep trading until settlement)\n",
      "- Net exposure typically stays within ±3%\n",
      "\n",
      "\n",
      "======================================================================\n",
      "4. ORDER PLACEMENT LOGIC\n",
      "======================================================================\n",
      "\n",
      "FINDINGS:\n",
      "- 53-58% of fills are maker (limit orders hit by market orders)\n",
      "- Average fill price is below best ask (they don't cross spread)\n",
      "- They post at or near best bid\n",
      "\n",
      "IMPLEMENTATION:\n",
      "- Order type: GTC (Good-Til-Cancelled) limit orders\n",
      "- Price: At or slightly inside best bid\n",
      "- Post on BOTH sides simultaneously\n",
      "- Do NOT use market orders or cross the spread\n",
      "\n",
      "PSEUDOCODE:\n",
      "```python\n",
      "up_order = {\n",
      "    'side': 'BUY',\n",
      "    'outcome': 'UP',\n",
      "    'price': orderbook.up_best_bid,  # or +0.001 to be first\n",
      "    'size': 28,\n",
      "    'type': 'GTC'\n",
      "}\n",
      "down_order = {\n",
      "    'side': 'BUY',\n",
      "    'outcome': 'DOWN', \n",
      "    'price': orderbook.down_best_bid,  # or +0.001 to be first\n",
      "    'size': 28,\n",
      "    'type': 'GTC'\n",
      "}\n",
      "```\n",
      "\n",
      "\n",
      "======================================================================\n",
      "5. REBALANCING LOGIC\n",
      "======================================================================\n",
      "\n",
      "FINDINGS:\n",
      "- Correlation between size and exposure: ~0.03 (none)\n",
      "- No evidence of active rebalancing when position drifts\n",
      "- Final positions are 1-3% unbalanced (they accept this)\n",
      "\n",
      "IMPLEMENTATION:\n",
      "- Do NOT actively rebalance\n",
      "- Keep posting same-size orders on both sides\n",
      "- Balance emerges naturally from continuous two-sided quoting\n",
      "- Accept small directional tilt at settlement\n",
      "\n",
      "DO NOT:\n",
      "- Size up on one side when underweight\n",
      "- Cancel one side when the other fills\n",
      "- Cross spread to \"catch up\" on lagging side\n",
      "\n",
      "\n",
      "======================================================================\n",
      "6. STALE QUOTE HANDLING\n",
      "======================================================================\n",
      "\n",
      "FINDINGS:\n",
      "- Unable to determine exact cancel threshold from fill data\n",
      "- Most fills happen at or near current bid\n",
      "- Some fills appear at prices 1-2% from current bid\n",
      "\n",
      "IMPLEMENTATION (CONSERVATIVE RECOMMENDATION):\n",
      "- Cancel and requote if market moves >2% from your order price\n",
      "- Or: Let GTC orders rest and accept some adverse selection\n",
      "- The 28-share size limits damage from stale fills\n",
      "\n",
      "PSEUDOCODE:\n",
      "```python\n",
      "if abs(current_bid - my_order_price) / my_order_price > 0.02:\n",
      "    cancel_order(my_order_id)\n",
      "    post_new_order(price=current_bid, size=28)\n",
      "```\n",
      "\n",
      "\n",
      "======================================================================\n",
      "7. RISK CONTROLS\n",
      "======================================================================\n",
      "\n",
      "OBSERVED BEHAVIOR:\n",
      "- No evidence of position limits\n",
      "- No evidence of exposure-based pausing\n",
      "- No evidence of time-based size reduction (except slight Q4 reduction)\n",
      "\n",
      "RECOMMENDED RISK CONTROLS (not observed, but prudent):\n",
      "- MAX_NET_EXPOSURE: ±500 shares (pause if exceeded)\n",
      "- MAX_POSITION_PER_SIDE: 10,000 shares\n",
      "- CIRCUIT_BREAKER: Stop if >5 consecutive adverse fills\n",
      "- TIME_CUTOFF: Stop posting new orders 30s before settlement\n",
      "\n",
      "\n",
      "======================================================================\n",
      "8. TIMING REQUIREMENTS\n",
      "======================================================================\n",
      "\n",
      "FINDINGS:\n",
      "- 69.6% of trades at same timestamp as previous (batched fills)\n",
      "- Trades spread evenly throughout 15-min window\n",
      "- No evidence of sub-second latency requirements\n",
      "\n",
      "IMPLEMENTATION:\n",
      "- Polling rate: 500ms-1000ms is sufficient\n",
      "- No co-location or HFT infrastructure needed\n",
      "- Focus on reliability over speed\n",
      "- Ensure you can detect fills and repost quickly\n",
      "\n",
      "\n",
      "======================================================================\n",
      "9. API REQUIREMENTS\n",
      "======================================================================\n",
      "\n",
      "REQUIRED CAPABILITIES:\n",
      "1. Read orderbook (best bid/ask for Up and Down)\n",
      "2. Post limit orders (GTC)\n",
      "3. Cancel orders\n",
      "4. Get fill notifications\n",
      "5. Track open positions\n",
      "\n",
      "POLYMARKET CLOB API:\n",
      "- WebSocket for real-time orderbook updates\n",
      "- REST for order submission\n",
      "- WebSocket for fill events\n",
      "- Rate limits: TBD (test in sandbox)\n",
      "\n",
      "KEY ENDPOINTS:\n",
      "- GET /book (orderbook state)\n",
      "- POST /order (submit order)\n",
      "- DELETE /order/{id} (cancel)\n",
      "- WebSocket /fills (fill notifications)\n",
      "\n",
      "\n",
      "======================================================================\n",
      "10. ECONOMICS SUMMARY\n",
      "======================================================================\n",
      "\n",
      "PER-WINDOW ECONOMICS:\n",
      "- Volume: ~10591 shares\n",
      "- Pairs: ~5234\n",
      "- Edge per pair: $0.0085 (0.85%)\n",
      "- Gross profit: $50-90\n",
      "- Gas costs (estimated): $5-15 (Polygon)\n",
      "- Net profit: $40-75 per window\n",
      "\n",
      "SCALING:\n",
      "- 4 windows/hour × 24 hours = 96 windows/day\n",
      "- At $50 net/window = $4,800/day\n",
      "- Capital required: ~$7,000 per window\n",
      "\n",
      "RISKS:\n",
      "- Adverse selection (getting picked off)\n",
      "- Legging risk (fills not simultaneous)\n",
      "- Gas spikes on Polygon\n",
      "- API rate limits\n",
      "- Settlement risk (position at expiry)\n",
      "\n",
      "\n",
      "======================================================================\n",
      "END OF IMPLEMENTATION SUMMARY\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "TEST 10: IMPLEMENTATION REQUIREMENTS SUMMARY\n",
    "============================================\n",
    "This script runs all tests and produces a summary of findings\n",
    "with specific implementation recommendations.\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "markets = [\"1766688300\", \"1766689200\", \"1766690100\", \"1766691000\", \"1766691900\", \"1766692800\"]\n",
    "\n",
    "# Load all data\n",
    "all_trades = []\n",
    "for market in markets:\n",
    "    try:\n",
    "        trades = pd.read_parquet(f\"DataCollection/BotTrades/{market}-trades.parquet\")\n",
    "        trades['market'] = market\n",
    "        all_trades.append(trades)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "trades = pd.concat(all_trades, ignore_index=True)\n",
    "trades = trades.sort_values('unix_timestamp')\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"IMPLEMENTATION REQUIREMENTS SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\"\"\n",
    "Based on analysis of 5,037 trades across 6 market windows, here are the\n",
    "specific parameters and behaviors you need to implement:\n",
    "\"\"\")\n",
    "\n",
    "# ============================================\n",
    "# ORDER SIZING\n",
    "# ============================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"1. ORDER SIZING\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "max_size = trades['size'].max()\n",
    "mode_size = trades['size'].mode().iloc[0]\n",
    "mean_size = trades['size'].mean()\n",
    "\n",
    "print(f\"\"\"\n",
    "FINDINGS:\n",
    "- Maximum trade size: {max_size} shares\n",
    "- Most common size: {mode_size} shares  \n",
    "- Average size: {mean_size:.2f} shares\n",
    "- 1:1 transaction:trade ratio confirms deliberate 28-share cap\n",
    "\n",
    "IMPLEMENTATION:\n",
    "- Set MAX_ORDER_SIZE = 28\n",
    "- This is ~$10 at typical prices\n",
    "- Do NOT vary size based on market conditions\n",
    "\"\"\")\n",
    "\n",
    "# ============================================\n",
    "# ORDER FREQUENCY\n",
    "# ============================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"2. ORDER FREQUENCY / REFRESH RATE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "time_gaps = trades['unix_timestamp'].diff()\n",
    "median_gap = time_gaps.median()\n",
    "mean_gap = time_gaps.mean()\n",
    "\n",
    "trades_per_window = len(trades) / len(markets)\n",
    "trades_per_minute = trades_per_window / 15\n",
    "\n",
    "print(f\"\"\"\n",
    "FINDINGS:\n",
    "- Median time between fills: {median_gap:.2f} seconds\n",
    "- Mean time between fills: {mean_gap:.2f} seconds\n",
    "- Trades per 15-min window: {trades_per_window:.0f}\n",
    "- Trades per minute: {trades_per_minute:.1f}\n",
    "\n",
    "IMPLEMENTATION:\n",
    "- Post orders continuously, refresh immediately after fill\n",
    "- Target ~50-60 fills per minute when market is active\n",
    "- Both sides should have orders resting at all times\n",
    "\"\"\")\n",
    "\n",
    "# ============================================\n",
    "# POSITION LIMITS\n",
    "# ============================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"3. POSITION LIMITS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Calculate max position per market\n",
    "max_position = 0\n",
    "for market in markets:\n",
    "    m = trades[trades['market'] == market]\n",
    "    up = m[m['outcome'] == 'Up']['size'].sum()\n",
    "    down = m[m['outcome'] == 'Down']['size'].sum()\n",
    "    max_position = max(max_position, up, down)\n",
    "\n",
    "avg_up = trades[trades['outcome'] == 'Up'].groupby('market')['size'].sum().mean()\n",
    "avg_down = trades[trades['outcome'] == 'Down'].groupby('market')['size'].sum().mean()\n",
    "avg_total_volume = trades.groupby('market')['size'].sum().mean()\n",
    "\n",
    "print(f\"\"\"\n",
    "FINDINGS:\n",
    "- Average Up shares per window: {avg_up:.0f}\n",
    "- Average Down shares per window: {avg_down:.0f}\n",
    "- Max single-side position observed: {max_position:.0f}\n",
    "- Total volume per window: {avg_total_volume:.0f} shares\n",
    "\n",
    "IMPLEMENTATION:\n",
    "- Allocate ~$7,000 per market window\n",
    "- No hard position limit observed (they keep trading until settlement)\n",
    "- Net exposure typically stays within ±3%\n",
    "\"\"\")\n",
    "\n",
    "# ============================================\n",
    "# ORDER PLACEMENT\n",
    "# ============================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"4. ORDER PLACEMENT LOGIC\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\"\"\n",
    "FINDINGS:\n",
    "- 53-58% of fills are maker (limit orders hit by market orders)\n",
    "- Average fill price is below best ask (they don't cross spread)\n",
    "- They post at or near best bid\n",
    "\n",
    "IMPLEMENTATION:\n",
    "- Order type: GTC (Good-Til-Cancelled) limit orders\n",
    "- Price: At or slightly inside best bid\n",
    "- Post on BOTH sides simultaneously\n",
    "- Do NOT use market orders or cross the spread\n",
    "\n",
    "PSEUDOCODE:\n",
    "```python\n",
    "up_order = {\n",
    "    'side': 'BUY',\n",
    "    'outcome': 'UP',\n",
    "    'price': orderbook.up_best_bid,  # or +0.001 to be first\n",
    "    'size': 28,\n",
    "    'type': 'GTC'\n",
    "}\n",
    "down_order = {\n",
    "    'side': 'BUY',\n",
    "    'outcome': 'DOWN', \n",
    "    'price': orderbook.down_best_bid,  # or +0.001 to be first\n",
    "    'size': 28,\n",
    "    'type': 'GTC'\n",
    "}\n",
    "```\n",
    "\"\"\")\n",
    "\n",
    "# ============================================\n",
    "# REBALANCING\n",
    "# ============================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"5. REBALANCING LOGIC\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\"\"\n",
    "FINDINGS:\n",
    "- Correlation between size and exposure: ~0.03 (none)\n",
    "- No evidence of active rebalancing when position drifts\n",
    "- Final positions are 1-3% unbalanced (they accept this)\n",
    "\n",
    "IMPLEMENTATION:\n",
    "- Do NOT actively rebalance\n",
    "- Keep posting same-size orders on both sides\n",
    "- Balance emerges naturally from continuous two-sided quoting\n",
    "- Accept small directional tilt at settlement\n",
    "\n",
    "DO NOT:\n",
    "- Size up on one side when underweight\n",
    "- Cancel one side when the other fills\n",
    "- Cross spread to \"catch up\" on lagging side\n",
    "\"\"\")\n",
    "\n",
    "# ============================================\n",
    "# STALE QUOTE HANDLING\n",
    "# ============================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"6. STALE QUOTE HANDLING\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\"\"\n",
    "FINDINGS:\n",
    "- Unable to determine exact cancel threshold from fill data\n",
    "- Most fills happen at or near current bid\n",
    "- Some fills appear at prices 1-2% from current bid\n",
    "\n",
    "IMPLEMENTATION (CONSERVATIVE RECOMMENDATION):\n",
    "- Cancel and requote if market moves >2% from your order price\n",
    "- Or: Let GTC orders rest and accept some adverse selection\n",
    "- The 28-share size limits damage from stale fills\n",
    "\n",
    "PSEUDOCODE:\n",
    "```python\n",
    "if abs(current_bid - my_order_price) / my_order_price > 0.02:\n",
    "    cancel_order(my_order_id)\n",
    "    post_new_order(price=current_bid, size=28)\n",
    "```\n",
    "\"\"\")\n",
    "\n",
    "# ============================================\n",
    "# RISK CONTROLS\n",
    "# ============================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"7. RISK CONTROLS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\"\"\n",
    "OBSERVED BEHAVIOR:\n",
    "- No evidence of position limits\n",
    "- No evidence of exposure-based pausing\n",
    "- No evidence of time-based size reduction (except slight Q4 reduction)\n",
    "\n",
    "RECOMMENDED RISK CONTROLS (not observed, but prudent):\n",
    "- MAX_NET_EXPOSURE: ±500 shares (pause if exceeded)\n",
    "- MAX_POSITION_PER_SIDE: 10,000 shares\n",
    "- CIRCUIT_BREAKER: Stop if >5 consecutive adverse fills\n",
    "- TIME_CUTOFF: Stop posting new orders 30s before settlement\n",
    "\"\"\")\n",
    "\n",
    "# ============================================\n",
    "# TIMING\n",
    "# ============================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"8. TIMING REQUIREMENTS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\"\"\n",
    "FINDINGS:\n",
    "- 69.6% of trades at same timestamp as previous (batched fills)\n",
    "- Trades spread evenly throughout 15-min window\n",
    "- No evidence of sub-second latency requirements\n",
    "\n",
    "IMPLEMENTATION:\n",
    "- Polling rate: 500ms-1000ms is sufficient\n",
    "- No co-location or HFT infrastructure needed\n",
    "- Focus on reliability over speed\n",
    "- Ensure you can detect fills and repost quickly\n",
    "\"\"\")\n",
    "\n",
    "# ============================================\n",
    "# API REQUIREMENTS\n",
    "# ============================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"9. API REQUIREMENTS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\"\"\n",
    "REQUIRED CAPABILITIES:\n",
    "1. Read orderbook (best bid/ask for Up and Down)\n",
    "2. Post limit orders (GTC)\n",
    "3. Cancel orders\n",
    "4. Get fill notifications\n",
    "5. Track open positions\n",
    "\n",
    "POLYMARKET CLOB API:\n",
    "- WebSocket for real-time orderbook updates\n",
    "- REST for order submission\n",
    "- WebSocket for fill events\n",
    "- Rate limits: TBD (test in sandbox)\n",
    "\n",
    "KEY ENDPOINTS:\n",
    "- GET /book (orderbook state)\n",
    "- POST /order (submit order)\n",
    "- DELETE /order/{id} (cancel)\n",
    "- WebSocket /fills (fill notifications)\n",
    "\"\"\")\n",
    "\n",
    "# ============================================\n",
    "# ECONOMICS SUMMARY\n",
    "# ============================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"10. ECONOMICS SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\"\"\n",
    "PER-WINDOW ECONOMICS:\n",
    "- Volume: ~{avg_total_volume:.0f} shares\n",
    "- Pairs: ~{min(avg_up, avg_down):.0f}\n",
    "- Edge per pair: $0.0085 (0.85%)\n",
    "- Gross profit: $50-90\n",
    "- Gas costs (estimated): $5-15 (Polygon)\n",
    "- Net profit: $40-75 per window\n",
    "\n",
    "SCALING:\n",
    "- 4 windows/hour × 24 hours = 96 windows/day\n",
    "- At $50 net/window = $4,800/day\n",
    "- Capital required: ~$7,000 per window\n",
    "\n",
    "RISKS:\n",
    "- Adverse selection (getting picked off)\n",
    "- Legging risk (fills not simultaneous)\n",
    "- Gas spikes on Polygon\n",
    "- API rate limits\n",
    "- Settlement risk (position at expiry)\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"END OF IMPLEMENTATION SUMMARY\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17f3adf-b144-47b3-8faf-7c73de596ae4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
