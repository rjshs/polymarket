{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9802d378-7dce-4a98-8d76-2935fdf76ccd",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "from dataclasses import dataclass\n",
    "from typing import Optional, Dict, Any\n",
    "\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f4d9036d-39fd-4e1d-a0d3-81d2204168d3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "73e32727-5772-486f-9396-779d6c21d84b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATA_API: str = \"https://data-api.polymarket.com\"\n",
    "GAMMA: str = \"https://gamma-api.polymarket.com\"\n",
    "CLOB: str = \"https://clob.polymarket.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c5ae13fa-2dd1-4d9a-9acd-b990340791de",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Up': '65746565293819997775300173478269020460544951341535209461919854133553859025488', 'Down': '42751939750927982695925613318616870696027411162171797959002334921720792035718'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "slug = \"btc-updown-15m-1766302200\"\n",
    "url = f\"https://gamma-api.polymarket.com/markets/slug/{slug}\"\n",
    "\n",
    "mkt = requests.get(url).json()\n",
    "\n",
    "# clobTokenIds is sometimes a JSON-encoded string, sometimes already a list\n",
    "clob_ids = mkt[\"clobTokenIds\"]\n",
    "if isinstance(clob_ids, str):\n",
    "    clob_ids = json.loads(clob_ids)\n",
    "\n",
    "# outcomes is sometimes a JSON-encoded string, sometimes already a list\n",
    "outcomes = mkt[\"outcomes\"]\n",
    "if isinstance(outcomes, str):\n",
    "    outcomes = json.loads(outcomes)\n",
    "\n",
    "token_map = dict(zip(outcomes, clob_ids))\n",
    "print(token_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ca6b110c-fb64-4f22-9f0b-8cda0f44f09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, Any, List, Optional, Tuple\n",
    "import requests\n",
    "\n",
    "DATA_API = \"https://data-api.polymarket.com\"\n",
    "\n",
    "ASSETS = {\n",
    "    \"Up\":   \"65746565293819997775300173478269020460544951341535209461919854133553859025488\",\n",
    "    \"Down\": \"42751939750927982695925613318616870696027411162171797959002334921720792035718\",\n",
    "}\n",
    "\n",
    "@dataclass\n",
    "class TradeEvent:\n",
    "    timestamp: int          # unix seconds (per docs)\n",
    "    side: str               # BUY / SELL\n",
    "    asset: str              # asset id string\n",
    "    price: float\n",
    "    size: float\n",
    "    usdc_size: Optional[float]\n",
    "    tx_hash: Optional[str]\n",
    "\n",
    "def _trade_key(t: Dict[str, Any]) -> Tuple:\n",
    "    \"\"\"\n",
    "    Dedup key. Prefer transactionHash if present; otherwise fall back to a composite key.\n",
    "    \"\"\"\n",
    "    tx = t.get(\"transactionHash\") or t.get(\"txHash\") or None\n",
    "    if tx:\n",
    "        return (\"tx\", tx)\n",
    "    return (\n",
    "        \"k\",\n",
    "        int(t[\"timestamp\"]),\n",
    "        t.get(\"asset\"),\n",
    "        t.get(\"side\"),\n",
    "        float(t.get(\"price\", 0)),\n",
    "        float(t.get(\"size\", 0)),\n",
    "    )\n",
    "\n",
    "def fetch_trades(session: requests.Session, *, user: str,\n",
    "                 condition_id: Optional[str] = None,\n",
    "                 event_slug: Optional[str] = None,\n",
    "                 limit: int = 200,\n",
    "                 after_ts: Optional[int] = None) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Fetch trades for a user, optionally filtered.\n",
    "    Docs show user/proxyWallet, conditionId/eventSlug, side, etc. :contentReference[oaicite:6]{index=6}\n",
    "    \"\"\"\n",
    "    params: Dict[str, Any] = {\"user\": user, \"limit\": limit}\n",
    "\n",
    "    # Use whichever filter you have that the endpoint supports in your environment.\n",
    "    # conditionId is the most canonical filter for “this market”.\n",
    "    if condition_id:\n",
    "        params[\"conditionId\"] = condition_id\n",
    "    if event_slug:\n",
    "        params[\"eventSlug\"] = event_slug\n",
    "\n",
    "    # Some variants support time filters. If your call errors, remove this and just dedupe locally.\n",
    "    if after_ts is not None:\n",
    "        params[\"after\"] = after_ts  # if unsupported, server will ignore or error\n",
    "\n",
    "    r = session.get(f\"{DATA_API}/trades\", params=params, timeout=20)\n",
    "    r.raise_for_status()\n",
    "    data = r.json()\n",
    "    # Some endpoints return list; some wrap in {\"data\": [...]}.\n",
    "    if isinstance(data, dict) and \"data\" in data:\n",
    "        return data[\"data\"]\n",
    "    if isinstance(data, list):\n",
    "        return data\n",
    "    raise ValueError(f\"Unexpected trades response shape: {type(data)}\")\n",
    "\n",
    "def fetch_positions(session: requests.Session, *, user: str,\n",
    "                    condition_id: Optional[str] = None,\n",
    "                    event_slug: Optional[str] = None) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Fetch current positions for a user. :contentReference[oaicite:7]{index=7}\n",
    "    \"\"\"\n",
    "    params: Dict[str, Any] = {\"user\": user}\n",
    "    if condition_id:\n",
    "        params[\"conditionId\"] = condition_id\n",
    "    if event_slug:\n",
    "        params[\"eventSlug\"] = event_slug\n",
    "\n",
    "    r = session.get(f\"{DATA_API}/positions\", params=params, timeout=20)\n",
    "    r.raise_for_status()\n",
    "    data = r.json()\n",
    "    if isinstance(data, dict) and \"data\" in data:\n",
    "        return data[\"data\"]\n",
    "    if isinstance(data, list):\n",
    "        return data\n",
    "    raise ValueError(f\"Unexpected positions response shape: {type(data)}\")\n",
    "\n",
    "def normalize_trade(t: Dict[str, Any]) -> TradeEvent:\n",
    "    return TradeEvent(\n",
    "        timestamp=int(t[\"timestamp\"]),\n",
    "        side=str(t[\"side\"]).upper(),\n",
    "        asset=str(t[\"asset\"]),\n",
    "        price=float(t[\"price\"]),\n",
    "        size=float(t[\"size\"]),\n",
    "        usdc_size=(float(t[\"usdcSize\"]) if t.get(\"usdcSize\") is not None else None),\n",
    "        tx_hash=t.get(\"transactionHash\") or t.get(\"txHash\"),\n",
    "    )\n",
    "\n",
    "def apply_trade_to_position(pos: Dict[str, float], te: TradeEvent) -> None:\n",
    "    \"\"\"\n",
    "    Positions tracked in contract units per asset_id.\n",
    "    BUY increases holdings; SELL decreases.\n",
    "    \"\"\"\n",
    "    delta = te.size if te.side == \"BUY\" else -te.size\n",
    "    pos[te.asset] = pos.get(te.asset, 0.0) + delta\n",
    "\n",
    "def run_tracker(\n",
    "    *,\n",
    "    bot_wallet: str,\n",
    "    condition_id: Optional[str] = None,\n",
    "    event_slug: Optional[str] = None,\n",
    "    poll_seconds: float = 2.0,\n",
    "    positions_poll_every: int = 20,\n",
    "    out_jsonl_path: str = \"bot_fills_with_position.jsonl\",\n",
    "):\n",
    "    session = requests.Session()\n",
    "\n",
    "    # Local reconstructed position (only for the assets we care about)\n",
    "    position: Dict[str, float] = {ASSETS[\"Up\"]: 0.0, ASSETS[\"Down\"]: 0.0}\n",
    "\n",
    "    seen = set()\n",
    "    last_seen_ts: Optional[int] = None\n",
    "    iter_count = 0\n",
    "\n",
    "    # Optional: initialize from current positions snapshot (best-effort)\n",
    "    try:\n",
    "        cur = fetch_positions(session, user=bot_wallet, condition_id=condition_id, event_slug=event_slug)\n",
    "        # Try to seed only our two assets; schema varies so be defensive.\n",
    "        for p in cur:\n",
    "            asset = str(p.get(\"asset\") or p.get(\"token\") or \"\")\n",
    "            if asset in position:\n",
    "                # size/position fields differ across versions\n",
    "                qty = p.get(\"size\") or p.get(\"quantity\") or p.get(\"position\") or 0\n",
    "                position[asset] = float(qty)\n",
    "        print(\"Seeded from /positions:\", position)\n",
    "    except Exception as e:\n",
    "        print(\"Could not seed from /positions (ok):\", e)\n",
    "\n",
    "    while True:\n",
    "        iter_count += 1\n",
    "        try:\n",
    "            trades_raw = fetch_trades(\n",
    "                session,\n",
    "                user=bot_wallet,\n",
    "                condition_id=condition_id,\n",
    "                event_slug=event_slug,\n",
    "                limit=200,\n",
    "                after_ts=last_seen_ts,\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(\"fetch_trades error:\", e)\n",
    "            time.sleep(min(10.0, poll_seconds * 2))\n",
    "            continue\n",
    "\n",
    "        # Filter to our two assets (Up/Down)\n",
    "        trades_raw = [t for t in trades_raw if str(t.get(\"asset\")) in position]\n",
    "\n",
    "        # Sort oldest->newest so replay is consistent\n",
    "        trades_raw.sort(key=lambda x: int(x[\"timestamp\"]))\n",
    "\n",
    "        new_events = 0\n",
    "        with open(out_jsonl_path, \"a\") as f:\n",
    "            for t in trades_raw:\n",
    "                k = _trade_key(t)\n",
    "                if k in seen:\n",
    "                    continue\n",
    "                seen.add(k)\n",
    "\n",
    "                te = normalize_trade(t)\n",
    "                apply_trade_to_position(position, te)\n",
    "\n",
    "                snapshot = {\n",
    "                    \"timestamp\": te.timestamp,\n",
    "                    \"side\": te.side,\n",
    "                    \"asset\": te.asset,\n",
    "                    \"price\": te.price,\n",
    "                    \"size\": te.size,\n",
    "                    \"usdcSize\": te.usdc_size,\n",
    "                    \"txHash\": te.tx_hash,\n",
    "                    \"pos_up\": position[ASSETS[\"Up\"]],\n",
    "                    \"pos_down\": position[ASSETS[\"Down\"]],\n",
    "                    \"slug\": event_slug,\n",
    "                    \"conditionId\": condition_id,\n",
    "                }\n",
    "                f.write(json.dumps(snapshot) + \"\\n\")\n",
    "                new_events += 1\n",
    "                last_seen_ts = max(last_seen_ts or te.timestamp, te.timestamp)\n",
    "\n",
    "        if new_events:\n",
    "            print(f\"+{new_events} trades | pos_up={position[ASSETS['Up']]:.4f} pos_down={position[ASSETS['Down']]:.4f}\")\n",
    "\n",
    "        # Periodic reconciliation against /positions (optional but recommended)\n",
    "        if iter_count % positions_poll_every == 0:\n",
    "            try:\n",
    "                cur = fetch_positions(session, user=bot_wallet, condition_id=condition_id, event_slug=event_slug)\n",
    "                # Extract our two assets if present\n",
    "                cur_map = {}\n",
    "                for p in cur:\n",
    "                    asset = str(p.get(\"asset\") or p.get(\"token\") or \"\")\n",
    "                    if asset in position:\n",
    "                        qty = p.get(\"size\") or p.get(\"quantity\") or p.get(\"position\") or 0\n",
    "                        cur_map[asset] = float(qty)\n",
    "                if cur_map:\n",
    "                    print(\"reconcile /positions:\", cur_map, \"local:\", position)\n",
    "            except Exception as e:\n",
    "                print(\"fetch_positions error:\", e)\n",
    "\n",
    "        time.sleep(poll_seconds)\n",
    "\n",
    "# Example usage:\n",
    "# run_tracker(\n",
    "#   bot_wallet=\"0xBOTPROXYWALLET...\",\n",
    "#   condition_id=\"0x....\",          # best if you have it\n",
    "#   event_slug=\"btc-updown-15m-1766301300\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7bcf8b11-08ae-412f-a14d-1ef3aff5649a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seeded from /positions: {'65746565293819997775300173478269020460544951341535209461919854133553859025488': 2168.037785, '42751939750927982695925613318616870696027411162171797959002334921720792035718': 2102.866292}\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "apply_trade_to_position() missing 2 required positional arguments: 'asset' and 'size'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mrun_tracker\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbot_wallet\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m0x6031b6eed1c97e853c6e0f03ad3ce3529351f96d\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcondition_id\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m0x4f563c18d100afd42f6a28d91ee7589e04fbce81c1de193ca17a4c2995da9ae5\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevent_slug\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbtc-updown-15m-1766301300\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m      5\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 175\u001b[39m, in \u001b[36mrun_tracker\u001b[39m\u001b[34m(bot_wallet, condition_id, event_slug, poll_seconds, positions_poll_every, out_jsonl_path)\u001b[39m\n\u001b[32m    172\u001b[39m seen.add(k)\n\u001b[32m    174\u001b[39m te = normalize_trade(t)\n\u001b[32m--> \u001b[39m\u001b[32m175\u001b[39m \u001b[43mapply_trade_to_position\u001b[49m\u001b[43m(\u001b[49m\u001b[43mposition\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mte\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    177\u001b[39m snapshot = {\n\u001b[32m    178\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtimestamp\u001b[39m\u001b[33m\"\u001b[39m: te.timestamp,\n\u001b[32m    179\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mside\u001b[39m\u001b[33m\"\u001b[39m: te.side,\n\u001b[32m   (...)\u001b[39m\u001b[32m    188\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mconditionId\u001b[39m\u001b[33m\"\u001b[39m: condition_id,\n\u001b[32m    189\u001b[39m }\n\u001b[32m    190\u001b[39m f.write(json.dumps(snapshot) + \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mTypeError\u001b[39m: apply_trade_to_position() missing 2 required positional arguments: 'asset' and 'size'"
     ]
    }
   ],
   "source": [
    "run_tracker(\n",
    "    bot_wallet = \"0x6031b6eed1c97e853c6e0f03ad3ce3529351f96d\",\n",
    "    condition_id = \"0x4f563c18d100afd42f6a28d91ee7589e04fbce81c1de193ca17a4c2995da9ae5\",\n",
    "    event_slug = \"btc-updown-15m-1766301300\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dee01fff-161b-4961-9285-d1ea24ae65c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import time\n",
    "import json\n",
    "from typing import Dict, Any, List, Optional, Tuple\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "DATA_API = \"https://data-api.polymarket.com\"\n",
    "\n",
    "ASSETS = {\n",
    "    \"Up\":   \"65746565293819997775300173478269020460544951341535209461919854133553859025488\",\n",
    "    \"Down\": \"42751939750927982695925613318616870696027411162171797959002334921720792035718\",\n",
    "}\n",
    "\n",
    "SLUG = \"btc-updown-15m-1766302200\"\n",
    "\n",
    "# ---------- Rate limiter (token bucket) ----------\n",
    "class TokenBucket:\n",
    "    \"\"\"\n",
    "    Approximates \"X requests per 10s\" by refilling tokens continuously.\n",
    "    Good enough to stay under limits with a buffer.\n",
    "    \"\"\"\n",
    "    def __init__(self, capacity: float, refill_per_sec: float):\n",
    "        self.capacity = float(capacity)\n",
    "        self.refill_per_sec = float(refill_per_sec)\n",
    "        self.tokens = float(capacity)\n",
    "        self.last = time.monotonic()\n",
    "        self._lock = asyncio.Lock()\n",
    "\n",
    "    async def acquire(self, n: float = 1.0):\n",
    "        async with self._lock:\n",
    "            while True:\n",
    "                now = time.monotonic()\n",
    "                elapsed = now - self.last\n",
    "                self.last = now\n",
    "                self.tokens = min(self.capacity, self.tokens + elapsed * self.refill_per_sec)\n",
    "\n",
    "                if self.tokens >= n:\n",
    "                    self.tokens -= n\n",
    "                    return\n",
    "\n",
    "                # Sleep just enough to earn the missing tokens\n",
    "                missing = n - self.tokens\n",
    "                sleep_s = missing / self.refill_per_sec if self.refill_per_sec > 0 else 0.1\n",
    "                await asyncio.sleep(max(0.001, sleep_s))\n",
    "\n",
    "\n",
    "# ---------- Helpers ----------\n",
    "def trade_key(t: Dict[str, Any]) -> Tuple:\n",
    "    tx = t.get(\"transactionHash\") or t.get(\"txHash\")\n",
    "    if tx:\n",
    "        return (\"tx\", tx)\n",
    "    return (\n",
    "        \"k\",\n",
    "        int(t.get(\"timestamp\", 0)),\n",
    "        str(t.get(\"asset\", \"\")),\n",
    "        str(t.get(\"side\", \"\")).upper(),\n",
    "        float(t.get(\"price\", 0.0)),\n",
    "        float(t.get(\"size\", 0.0)),\n",
    "    )\n",
    "\n",
    "def fetch_json(session: requests.Session, url: str, params: Dict[str, Any]) -> Any:\n",
    "    r = session.get(url, params=params, timeout=20)\n",
    "    r.raise_for_status()\n",
    "    return r.json()\n",
    "\n",
    "def normalize_list_payload(payload: Any) -> List[Dict[str, Any]]:\n",
    "    if isinstance(payload, list):\n",
    "        return payload\n",
    "    if isinstance(payload, dict) and \"data\" in payload and isinstance(payload[\"data\"], list):\n",
    "        return payload[\"data\"]\n",
    "    raise ValueError(f\"Unexpected response shape: {type(payload)}\")\n",
    "\n",
    "def apply_trade_to_position(pos: Dict[str, float], side: str, asset: str, size: float):\n",
    "    side = side.upper()\n",
    "    delta = size if side == \"BUY\" else -size\n",
    "    pos[asset] = pos.get(asset, 0.0) + delta\n",
    "\n",
    "\n",
    "# ---------- Main tracker ----------\n",
    "class PolymarketUserTracker:\n",
    "    def __init__(\n",
    "        self,\n",
    "        bot_wallet: str,\n",
    "        slug: str,\n",
    "        assets: Dict[str, str],\n",
    "        trades_rps: float,\n",
    "        positions_rps: float,\n",
    "        trades_limit: int = 200,\n",
    "        flush_every: int = 2000,  # convert buffer to df every N new trades\n",
    "    ):\n",
    "        self.bot_wallet = bot_wallet\n",
    "        self.slug = slug\n",
    "        self.assets = assets\n",
    "        self.asset_set = set(assets.values())\n",
    "\n",
    "        self.session = requests.Session()\n",
    "\n",
    "        self.trades_bucket = TokenBucket(capacity=trades_rps * 2, refill_per_sec=trades_rps)\n",
    "        self.positions_bucket = TokenBucket(capacity=positions_rps * 2, refill_per_sec=positions_rps)\n",
    "\n",
    "        self.trades_limit = trades_limit\n",
    "        self.flush_every = flush_every\n",
    "\n",
    "        self.seen = set()\n",
    "        self.pos_replayed = {assets[\"Up\"]: 0.0, assets[\"Down\"]: 0.0}\n",
    "\n",
    "        self.buffer: List[Dict[str, Any]] = []\n",
    "        self.df = pd.DataFrame()\n",
    "\n",
    "        self.latest_positions_snapshot: Optional[Dict[str, Any]] = None\n",
    "\n",
    "    async def poll_trades_loop(self):\n",
    "        \"\"\"\n",
    "        Near-max polling of /trades. Each new fill is appended with replayed position-at-that-trade.\n",
    "        \"\"\"\n",
    "        while True:\n",
    "            await self.trades_bucket.acquire(1.0)\n",
    "\n",
    "            try:\n",
    "                payload = await asyncio.to_thread(\n",
    "                    fetch_json,\n",
    "                    self.session,\n",
    "                    f\"{DATA_API}/trades\",\n",
    "                    {\n",
    "                        \"user\": self.bot_wallet,\n",
    "                        \"eventSlug\": self.slug,   # if your deployment prefers conditionId, swap it in\n",
    "                        \"limit\": self.trades_limit,\n",
    "                    },\n",
    "                )\n",
    "                trades = normalize_list_payload(payload)\n",
    "            except Exception as e:\n",
    "                # brief backoff on transient issues\n",
    "                await asyncio.sleep(0.25)\n",
    "                continue\n",
    "\n",
    "            # Filter to our two assets and process oldest->newest\n",
    "            trades = [t for t in trades if str(t.get(\"asset\")) in self.asset_set]\n",
    "            trades.sort(key=lambda x: int(x.get(\"timestamp\", 0)))\n",
    "\n",
    "            new_count = 0\n",
    "            for t in trades:\n",
    "                k = trade_key(t)\n",
    "                if k in self.seen:\n",
    "                    continue\n",
    "                self.seen.add(k)\n",
    "                new_count += 1\n",
    "\n",
    "                ts = int(t[\"timestamp\"])\n",
    "                side = str(t[\"side\"]).upper()\n",
    "                asset = str(t[\"asset\"])\n",
    "                price = float(t[\"price\"])\n",
    "                size = float(t[\"size\"])\n",
    "                usdc_size = float(t[\"usdcSize\"]) if t.get(\"usdcSize\") is not None else None\n",
    "                tx = t.get(\"transactionHash\") or t.get(\"txHash\")\n",
    "\n",
    "                apply_trade_to_position(self.pos_replayed, side, asset, size)\n",
    "\n",
    "                row = {\n",
    "                    \"timestamp\": ts,\n",
    "                    \"side\": side,\n",
    "                    \"asset\": asset,\n",
    "                    \"price\": price,\n",
    "                    \"size\": size,\n",
    "                    \"usdcSize\": usdc_size,\n",
    "                    \"txHash\": tx,\n",
    "                    \"pos_up_replayed\": self.pos_replayed[self.assets[\"Up\"]],\n",
    "                    \"pos_down_replayed\": self.pos_replayed[self.assets[\"Down\"]],\n",
    "                }\n",
    "\n",
    "                # attach latest polled /positions snapshot info if you want (optional)\n",
    "                if self.latest_positions_snapshot is not None:\n",
    "                    row[\"positions_snapshot_ts\"] = self.latest_positions_snapshot.get(\"snapshot_ts\")\n",
    "                    row[\"pos_up_snapshot\"] = self.latest_positions_snapshot.get(\"pos_up\")\n",
    "                    row[\"pos_down_snapshot\"] = self.latest_positions_snapshot.get(\"pos_down\")\n",
    "\n",
    "                self.buffer.append(row)\n",
    "\n",
    "            # Flush buffer -> DataFrame periodically (avoid per-row df.append which is slow)\n",
    "            if len(self.buffer) >= self.flush_every:\n",
    "                self._flush_buffer_to_df()\n",
    "\n",
    "            # tiny yield so we don't starve event loop if responses are immediate\n",
    "            await asyncio.sleep(0)\n",
    "\n",
    "    async def poll_positions_loop(self):\n",
    "        \"\"\"\n",
    "        Poll /positions at configured rate. Useful as a sanity-check snapshot (current positions).\n",
    "        \"\"\"\n",
    "        while True:\n",
    "            await self.positions_bucket.acquire(1.0)\n",
    "            try:\n",
    "                payload = await asyncio.to_thread(\n",
    "                    fetch_json,\n",
    "                    self.session,\n",
    "                    f\"{DATA_API}/positions\",\n",
    "                    {\"user\": self.bot_wallet, \"eventSlug\": self.slug},\n",
    "                )\n",
    "                positions = normalize_list_payload(payload)\n",
    "            except Exception:\n",
    "                await asyncio.sleep(0.25)\n",
    "                continue\n",
    "\n",
    "            # Pull just our two assets\n",
    "            cur = {self.assets[\"Up\"]: None, self.assets[\"Down\"]: None}\n",
    "            for p in positions:\n",
    "                asset = str(p.get(\"asset\", \"\"))\n",
    "                if asset in cur:\n",
    "                    cur[asset] = float(p.get(\"size\", 0.0))\n",
    "\n",
    "            self.latest_positions_snapshot = {\n",
    "                \"snapshot_ts\": int(time.time()),\n",
    "                \"pos_up\": cur[self.assets[\"Up\"]],\n",
    "                \"pos_down\": cur[self.assets[\"Down\"]],\n",
    "            }\n",
    "\n",
    "            await asyncio.sleep(0)\n",
    "\n",
    "    def _flush_buffer_to_df(self):\n",
    "        if not self.buffer:\n",
    "            return\n",
    "        chunk = pd.DataFrame(self.buffer)\n",
    "        self.buffer.clear()\n",
    "        if self.df.empty:\n",
    "            self.df = chunk\n",
    "        else:\n",
    "            self.df = pd.concat([self.df, chunk], ignore_index=True)\n",
    "        # Optional: keep it sorted\n",
    "        self.df.sort_values(\"timestamp\", inplace=True, kind=\"stable\", ignore_index=True)\n",
    "\n",
    "    def flush(self):\n",
    "        self._flush_buffer_to_df()\n",
    "\n",
    "    def save_parquet(self, path: str):\n",
    "        self.flush()\n",
    "        self.df.to_parquet(path, index=False)\n",
    "\n",
    "    def save_csv(self, path: str):\n",
    "        self.flush()\n",
    "        self.df.to_csv(path, index=False)\n",
    "\n",
    "\n",
    "async def main():\n",
    "    bot_wallet = \"0x6031b6eed1c97e853c6e0f03ad3ce3529351f96d\"\n",
    "\n",
    "    # Compute near-max RPS with a buffer\n",
    "    buffer = 0.90\n",
    "    trades_rps = (200 / 10) * buffer       # 18 rps\n",
    "    positions_rps = (150 / 10) * buffer    # 13.5 rps  (you can set lower, e.g. 3.0)\n",
    "\n",
    "    tracker = PolymarketUserTracker(\n",
    "        bot_wallet=bot_wallet,\n",
    "        slug=SLUG,\n",
    "        assets=ASSETS,\n",
    "        trades_rps=trades_rps,\n",
    "        positions_rps=positions_rps,\n",
    "        trades_limit=200,\n",
    "        flush_every=1000,\n",
    "    )\n",
    "\n",
    "    tasks = [\n",
    "        asyncio.create_task(tracker.poll_trades_loop()),\n",
    "        asyncio.create_task(tracker.poll_positions_loop()),\n",
    "    ]\n",
    "\n",
    "    # Example: run and periodically print / save\n",
    "    try:\n",
    "        while True:\n",
    "            await asyncio.sleep(5)\n",
    "            tracker.flush()\n",
    "            if not tracker.df.empty:\n",
    "                print(\"rows:\", len(tracker.df), \"last_ts:\", tracker.df[\"timestamp\"].iloc[-1])\n",
    "                # tracker.save_parquet(\"bot_trades.parquet\")\n",
    "    finally:\n",
    "        for t in tasks:\n",
    "            t.cancel()\n",
    "        tracker.flush()\n",
    "        tracker.save_parquet(\"bot_trades.parquet\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d3063d51-f928-4ab8-bac7-5f2584e129c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rows: 66 last_ts: 1766302754\n",
      "rows: 66 last_ts: 1766302754\n",
      "rows: 66 last_ts: 1766302754\n",
      "rows: 66 last_ts: 1766302754\n",
      "rows: 66 last_ts: 1766302754\n",
      "rows: 66 last_ts: 1766302754\n"
     ]
    },
    {
     "ename": "CancelledError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mCancelledError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m main()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 269\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    267\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    268\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m269\u001b[39m         \u001b[38;5;28;01mawait\u001b[39;00m asyncio.sleep(\u001b[32m5\u001b[39m)\n\u001b[32m    270\u001b[39m         tracker.flush()\n\u001b[32m    271\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tracker.df.empty:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.8/lib/python3.11/asyncio/tasks.py:649\u001b[39m, in \u001b[36msleep\u001b[39m\u001b[34m(delay, result)\u001b[39m\n\u001b[32m    645\u001b[39m h = loop.call_later(delay,\n\u001b[32m    646\u001b[39m                     futures._set_result_unless_cancelled,\n\u001b[32m    647\u001b[39m                     future, result)\n\u001b[32m    648\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m649\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m future\n\u001b[32m    650\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    651\u001b[39m     h.cancel()\n",
      "\u001b[31mCancelledError\u001b[39m: "
     ]
    }
   ],
   "source": [
    "await main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb00f8b6-df93-498f-962a-bd895d1e85fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
