{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4b4567a6-b150-4a21-adf6-752ba205d1e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      " POLYMARKET BOT STRATEGY ANALYSIS - PHASE 1\n",
      " Individual Dataset Analysis\n",
      "================================================================================\n",
      "\n",
      "Started at: 2025-12-22 22:02:17.146059\n",
      "Output directory: analysis_output/\n",
      "\n",
      "================================================================================\n",
      " 1A. BITCOIN PRICE ANALYSIS\n",
      "================================================================================\n",
      "âœ“ Loaded 1,782 price records\n",
      "\n",
      "--- Schema ---\n",
      "system_timestamp    datetime64[ns]\n",
      "server_timestamp             int64\n",
      "symbol                      object\n",
      "price                      float64\n",
      "dtype: object\n",
      "\n",
      "Columns: ['system_timestamp', 'server_timestamp', 'symbol', 'price']\n",
      "\n",
      "--- Timestamp Analysis ---\n",
      "Time range: 2025-12-21 16:14:13.142747 to 2025-12-21 16:44:29.922066\n",
      "Total duration: 0 days 00:30:16.779319\n",
      "\n",
      "--- Tick Frequency (time between price updates) ---\n",
      "Mean: 1.0201 seconds\n",
      "Median: 0.8533 seconds\n",
      "Min: 0.3258 seconds\n",
      "Max: 3.4176 seconds\n",
      "Std: 0.3834 seconds\n",
      "\n",
      "Data gaps (>5 sec): 0 occurrences\n",
      "\n",
      "--- Price Statistics ---\n",
      "Mean price: $89,045.85\n",
      "Std dev: $192.85\n",
      "Min: $88,762.78\n",
      "Max: $89,586.20\n",
      "Range: $823.41\n",
      "Range %: 0.9247%\n",
      "\n",
      "--- Returns Analysis ---\n",
      "Mean 1-tick return: -0.000203%\n",
      "Std 1-tick return: 0.009143%\n",
      "Max positive return: 0.0713%\n",
      "Max negative return: -0.0565%\n",
      "\n",
      "--- Multi-Window Returns (for later signal analysis) ---\n",
      "Average tick interval: 0.853s\n",
      "    1s window (~1 ticks): std = 0.0091%\n",
      "    5s window (~5 ticks): std = 0.0261%\n",
      "   15s window (~17 ticks): std = 0.0557%\n",
      "   30s window (~35 ticks): std = 0.0838%\n",
      "   60s window (~70 ticks): std = 0.1166%\n",
      "  300s window (~351 ticks): std = 0.2795%\n",
      "\n",
      "--- Volatility Analysis ---\n",
      "Mean 60s rolling volatility: 0.008361%\n",
      "Max 60s rolling volatility: 0.017974%\n",
      "\n",
      "--- Direction Analysis (Up vs Down moves) ---\n",
      "Up ticks: 800 (44.9%)\n",
      "Down ticks: 799 (44.8%)\n",
      "Flat ticks: 182 (10.2%)\n",
      "\n",
      "âœ“ Saved processed BTC data to: analysis_output/btc_prices_processed.parquet\n",
      "\n",
      "================================================================================\n",
      " 1B. TRADE ANALYSIS (THE GOLDMINE)\n",
      "================================================================================\n",
      "âœ“ Loaded 1,121 trades\n",
      "\n",
      "--- Schema ---\n",
      "timestamp           datetime64[ns]\n",
      "unix_timestamp               int64\n",
      "slug                        object\n",
      "market_title                object\n",
      "side                        object\n",
      "price                      float64\n",
      "size                       float64\n",
      "value                      float64\n",
      "outcome                     object\n",
      "condition_id                object\n",
      "transaction_hash            object\n",
      "outcome_index                int64\n",
      "dtype: object\n",
      "\n",
      "Columns: ['timestamp', 'unix_timestamp', 'slug', 'market_title', 'side', 'price', 'size', 'value', 'outcome', 'condition_id', 'transaction_hash', 'outcome_index']\n",
      "\n",
      "First 3 rows:\n",
      "            timestamp  unix_timestamp                       slug  \\\n",
      "0 2025-12-21 16:15:42      1766362542  btc-updown-15m-1766362500   \n",
      "1 2025-12-21 16:15:44      1766362544  btc-updown-15m-1766362500   \n",
      "2 2025-12-21 16:15:44      1766362544  btc-updown-15m-1766362500   \n",
      "\n",
      "                                        market_title side  price  size  value  \\\n",
      "0  Bitcoin Up or Down - December 21, 7:15PM-7:30P...  BUY   0.41   5.0    0.0   \n",
      "1  Bitcoin Up or Down - December 21, 7:15PM-7:30P...  BUY   0.41  15.0    0.0   \n",
      "2  Bitcoin Up or Down - December 21, 7:15PM-7:30P...  BUY   0.41   5.0    0.0   \n",
      "\n",
      "  outcome                                       condition_id  \\\n",
      "0    Down  0xa831288114dd7039c2744bd3505d9de46ec7d9ea4e82...   \n",
      "1    Down  0xa831288114dd7039c2744bd3505d9de46ec7d9ea4e82...   \n",
      "2    Down  0xa831288114dd7039c2744bd3505d9de46ec7d9ea4e82...   \n",
      "\n",
      "                                    transaction_hash  outcome_index  \n",
      "0  0x92b657f7bd00dbd71acf753567ceda5b9c6a03e783b4...              1  \n",
      "1  0x4932fa7d7823481c9a335d8a62981385432e1a200b23...              1  \n",
      "2  0x63ce6876e3029ff5a25f2fa9817a44c0172a0a4de13f...              1  \n",
      "\n",
      "--- Timestamp Analysis ---\n",
      "Time range: 2025-12-21 16:15:42 to 2025-12-21 16:44:06\n",
      "Total duration: 0 days 00:28:24\n",
      "\n",
      "--- Trade Frequency ---\n",
      "Total trades: 1,121\n",
      "Trades per minute: 39.47\n",
      "\n",
      "Time between trades:\n",
      "  Mean: 1.52 seconds\n",
      "  Median: 0.00 seconds\n",
      "  Min: 0.00 seconds\n",
      "  Max: 356.00 seconds\n",
      "\n",
      "--- Side Analysis (BUY vs SELL) ---\n",
      "side\n",
      "BUY    1121\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Buy/Sell Ratio: 1121.00\n",
      "\n",
      "--- Outcome Analysis (UP vs DOWN) ---\n",
      "outcome\n",
      "Up      572\n",
      "Down    549\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--- Combined Side + Outcome Analysis ---\n",
      "action\n",
      "BUY_Up      572\n",
      "BUY_Down    549\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Action distribution (%):\n",
      "action\n",
      "BUY_Up      51.03\n",
      "BUY_Down    48.97\n",
      "Name: count, dtype: float64\n",
      "\n",
      "--- Trade Size Analysis ---\n",
      "Size statistics:\n",
      "  Mean: 10.6939\n",
      "  Median: 9.8500\n",
      "  Std: 7.0903\n",
      "  Min: 0.0725\n",
      "  Max: 20.0000\n",
      "\n",
      "Unique trade sizes: 389\n",
      "\n",
      "Mean size by action:\n",
      "action\n",
      "BUY_Down    10.785359\n",
      "BUY_Up      10.606032\n",
      "Name: size, dtype: float64\n",
      "\n",
      "--- Trade Price Analysis ---\n",
      "Price statistics:\n",
      "  Mean: 0.4687\n",
      "  Median: 0.4600\n",
      "  Min: 0.0200\n",
      "  Max: 0.9700\n",
      "\n",
      "Mean price by outcome:\n",
      "             mean   min   max\n",
      "outcome                      \n",
      "Down     0.461570  0.03  0.97\n",
      "Up       0.475491  0.02  0.96\n",
      "\n",
      "Mean price by action:\n",
      "action\n",
      "BUY_Down    0.461570\n",
      "BUY_Up      0.475491\n",
      "Name: price, dtype: float64\n",
      "\n",
      "--- Trade Value Analysis (price * size) ---\n",
      "Value statistics:\n",
      "  Mean: $0.0000\n",
      "  Total: $0.00\n",
      "\n",
      "--- Timing Within 15-Minute Windows ---\n",
      "Markets traded:\n",
      "slug\n",
      "btc-updown-15m-1766363400    668\n",
      "btc-updown-15m-1766362500    453\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Seconds into 15-min window when trading:\n",
      "  Mean: -28501.5s\n",
      "  Median: -28580.0s\n",
      "  Min: -28780.0s\n",
      "  Max: -27954.0s\n",
      "\n",
      "Trades by window phase:\n",
      "window_phase\n",
      "Early (0-5min)     0\n",
      "Mid (5-10min)      0\n",
      "Late (10-15min)    0\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--- Trade Sequence Analysis ---\n",
      "Most common action sequences:\n",
      "action_sequence\n",
      "BUY_Up â†’ BUY_Up        390\n",
      "BUY_Down â†’ BUY_Down    366\n",
      "BUY_Down â†’ BUY_Up      182\n",
      "BUY_Up â†’ BUY_Down      182\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Rapid trades (<5 sec apart): 1067 (95.2%)\n",
      "Rapid trade sequences:\n",
      "action_sequence\n",
      "BUY_Up â†’ BUY_Up        380\n",
      "BUY_Down â†’ BUY_Down    360\n",
      "BUY_Down â†’ BUY_Up      165\n",
      "BUY_Up â†’ BUY_Down      162\n",
      "Name: count, dtype: int64\n",
      "\n",
      "âœ“ Saved processed trades data to: analysis_output/trades_processed.parquet\n",
      "\n",
      "================================================================================\n",
      " 1C. POSITION ANALYSIS\n",
      "================================================================================\n",
      "âœ“ Loaded 6,447 position snapshots\n",
      "\n",
      "--- Schema ---\n",
      "timestamp               datetime64[ns]\n",
      "wallet_address                  object\n",
      "market_title                    object\n",
      "market_slug                     object\n",
      "event_slug                      object\n",
      "condition_id                    object\n",
      "outcome                         object\n",
      "outcome_index                    int64\n",
      "shares                         float64\n",
      "avg_price                      float64\n",
      "current_price                  float64\n",
      "initial_value                  float64\n",
      "current_value                  float64\n",
      "cash_pnl                       float64\n",
      "percent_pnl                    float64\n",
      "total_bought                   float64\n",
      "realized_pnl                   float64\n",
      "percent_realized_pnl           float64\n",
      "redeemable                        bool\n",
      "end_date                        object\n",
      "dtype: object\n",
      "\n",
      "Columns: ['timestamp', 'wallet_address', 'market_title', 'market_slug', 'event_slug', 'condition_id', 'outcome', 'outcome_index', 'shares', 'avg_price', 'current_price', 'initial_value', 'current_value', 'cash_pnl', 'percent_pnl', 'total_bought', 'realized_pnl', 'percent_realized_pnl', 'redeemable', 'end_date']\n",
      "\n",
      "--- Basic Statistics ---\n",
      "Total snapshots: 6,447\n",
      "\n",
      "--- Outcome Distribution (UP vs DOWN positions) ---\n",
      "outcome\n",
      "Down    3234\n",
      "Up      3213\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--- Shares (Position Size) Analysis ---\n",
      "Shares statistics:\n",
      "  Mean: 1346.06\n",
      "  Median: 1306.99\n",
      "  Std: 855.11\n",
      "  Max: 3325.38\n",
      "\n",
      "Shares by outcome:\n",
      "          count         mean         std  min         25%          50%  \\\n",
      "outcome                                                                  \n",
      "Down     3234.0  1341.770939  856.536287  5.0  565.954107  1271.341611   \n",
      "Up       3213.0  1350.381510  853.792669  7.0  532.243499  1309.307215   \n",
      "\n",
      "                 75%          max  \n",
      "outcome                            \n",
      "Down     1992.025823  3300.787798  \n",
      "Up       2019.311988  3325.383691  \n",
      "\n",
      "--- Price Analysis ---\n",
      "Average entry price (avg_price):\n",
      "  Mean: 0.5009\n",
      "  Range: 0.1191 to 0.8874\n",
      "\n",
      "Current price:\n",
      "  Mean: 0.5001\n",
      "  Range: 0.2550 to 0.7450\n",
      "\n",
      "--- PnL Analysis (CRITICAL) ---\n",
      "Cash PnL statistics:\n",
      "  Mean: $0.96\n",
      "  Median: $5.19\n",
      "  Std: $466.33\n",
      "  Min: $-1282.49\n",
      "  Max: $1280.90\n",
      "\n",
      "Percent PnL statistics:\n",
      "  Mean: 58.82%\n",
      "  Median: 3.49%\n",
      "  Min: -68.52%\n",
      "  Max: 303.40%\n",
      "\n",
      "Win/Loss breakdown (by snapshot):\n",
      "  Winning: 3,309 (51.3%)\n",
      "  Losing: 3,138 (48.7%)\n",
      "  Breakeven: 0 (0.0%)\n",
      "\n",
      "Average winning PnL: $309.06\n",
      "Average losing PnL: $-323.94\n",
      "\n",
      "PnL by outcome (UP vs DOWN positions):\n",
      "          count        mean         std          min         25%         50%  \\\n",
      "outcome                                                                        \n",
      "Down     3234.0  108.354834  450.891294  -291.945210 -199.458074 -102.980362   \n",
      "Up       3213.0 -107.140362  456.600611 -1282.486214 -153.512145  101.321289   \n",
      "\n",
      "                75%          max  \n",
      "outcome                           \n",
      "Down     149.273400  1280.897470  \n",
      "Up       184.088656   304.822193  \n",
      "\n",
      "--- Realized vs Unrealized PnL ---\n",
      "Realized PnL:\n",
      "  Mean: $17.55\n",
      "  Total: $113129.59\n",
      "\n",
      "Percent Realized PnL:\n",
      "  Mean: -29.95%\n",
      "\n",
      "--- Position Value Analysis ---\n",
      "Initial value:\n",
      "  Mean: $671.76\n",
      "  Total: $4330840.97\n",
      "\n",
      "Current value:\n",
      "  Mean: $672.72\n",
      "  Total: $4337018.52\n",
      "\n",
      "Total bought:\n",
      "  Mean: $3079.11\n",
      "  Max: $5116.11\n",
      "\n",
      "--- Redeemable Status ---\n",
      "redeemable\n",
      "False    6447\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--- Market End Date Analysis ---\n",
      "End dates:\n",
      "end_date\n",
      "2025-12-22    6447\n",
      "Name: count, dtype: int64\n",
      "\n",
      "âœ“ Saved processed positions data to: analysis_output/positions_processed.parquet\n",
      "\n",
      "================================================================================\n",
      " 1D. ORDERBOOK ANALYSIS\n",
      "================================================================================\n",
      "âœ“ Loaded 14,059 orderbook snapshots\n",
      "\n",
      "--- Schema ---\n",
      "timestamp          datetime64[ns]\n",
      "unixtime                  float64\n",
      "market_slug                object\n",
      "up_best_bid               float64\n",
      "up_best_ask               float64\n",
      "up_bid_depth_5            float64\n",
      "up_ask_depth_5            float64\n",
      "up_spread                 float64\n",
      "down_best_bid             float64\n",
      "down_best_ask             float64\n",
      "down_spread               float64\n",
      "implied_sum_bid           float64\n",
      "implied_sum_ask           float64\n",
      "dtype: object\n",
      "\n",
      "Columns: ['timestamp', 'unixtime', 'market_slug', 'up_best_bid', 'up_best_ask', 'up_bid_depth_5', 'up_ask_depth_5', 'up_spread', 'down_best_bid', 'down_best_ask', 'down_spread', 'implied_sum_bid', 'implied_sum_ask']\n",
      "\n",
      "--- Timestamp Analysis ---\n",
      "Time range: 2025-12-21 16:15:02.087354 to 2025-12-21 16:44:20.519204\n",
      "Total duration: 0 days 00:29:18.431850\n",
      "\n",
      "Snapshot frequency:\n",
      "  Mean: 0.13 seconds\n",
      "  Median: 0.10 seconds\n",
      "\n",
      "--- Market Coverage ---\n",
      "market_slug\n",
      "btc-updown-15m-1766363400    8280\n",
      "btc-updown-15m-1766362500    5779\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--- UP Outcome Orderbook ---\n",
      "UP Best Bid:\n",
      "  Mean: 0.0100\n",
      "  Min: 0.0100\n",
      "  Max: 0.0100\n",
      "\n",
      "UP Best Ask:\n",
      "  Mean: 0.9900\n",
      "  Min: 0.9900\n",
      "  Max: 0.9900\n",
      "\n",
      "UP Spread:\n",
      "  Mean: 0.9800\n",
      "  Min: 0.9800\n",
      "  Max: 0.9800\n",
      "\n",
      "--- DOWN Outcome Orderbook ---\n",
      "DOWN Best Bid:\n",
      "  Mean: 0.0100\n",
      "  Min: 0.0100\n",
      "  Max: 0.0100\n",
      "\n",
      "DOWN Best Ask:\n",
      "  Mean: 0.9900\n",
      "  Min: 0.9900\n",
      "  Max: 0.9900\n",
      "\n",
      "DOWN Spread:\n",
      "  Mean: 0.9800\n",
      "  Min: 0.9800\n",
      "  Max: 0.9800\n",
      "\n",
      "--- Implied Probabilities (Midpoint Prices) ---\n",
      "UP implied probability (midpoint):\n",
      "  Mean: 0.5000 (50.0%)\n",
      "  Range: 0.5000 to 0.5000\n",
      "\n",
      "DOWN implied probability (midpoint):\n",
      "  Mean: 0.5000 (50.0%)\n",
      "  Range: 0.5000 to 0.5000\n",
      "\n",
      "--- Market Efficiency Analysis ---\n",
      "Sum of midpoint probabilities (should be ~1.0):\n",
      "  Mean: 1.0000\n",
      "  Min: 1.0000\n",
      "  Max: 1.0000\n",
      "\n",
      "Sum of best asks (cost to buy both outcomes):\n",
      "  Mean: 1.9800\n",
      "  Min: 1.9800\n",
      "\n",
      "Sum of best bids (revenue from selling both outcomes):\n",
      "  Mean: 0.0200\n",
      "  Max: 0.0200\n",
      "\n",
      "Arbitrage opportunities (buy both < $1): 0 snapshots\n",
      "Arbitrage opportunities (sell both > $1): 0 snapshots\n",
      "\n",
      "--- Orderbook Depth Analysis ---\n",
      "UP Bid Depth (5 levels):\n",
      "  Mean: $8609.57\n",
      "  Max: $15668.42\n",
      "\n",
      "UP Ask Depth (5 levels):\n",
      "  Mean: $9187.21\n",
      "  Max: $14884.12\n",
      "\n",
      "--- Implied Sum (Bid/Ask) ---\n",
      "Implied Sum Bid: 0.0200\n",
      "Implied Sum Ask: 1.9800\n",
      "\n",
      "--- UP vs DOWN Spread Comparison ---\n",
      "UP spread - DOWN spread:\n",
      "  Mean: 0.0000\n",
      "  Positive (UP wider): 0 snapshots\n",
      "  Negative (DOWN wider): 0 snapshots\n",
      "\n",
      "âœ“ Saved processed orderbook data to: analysis_output/orderbook_processed.parquet\n",
      "\n",
      "================================================================================\n",
      " PHASE 1 SUMMARY REPORT\n",
      "================================================================================\n",
      "\n",
      "ðŸ“Š DATA OVERVIEW\n",
      "----------------------------------------\n",
      "Bitcoin Prices: 1,782 records\n",
      "Trades: 1,121 records\n",
      "Position Snapshots: 6,447 records\n",
      "Orderbook Snapshots: 14,059 records\n",
      "\n",
      "ðŸ” KEY FINDINGS\n",
      "----------------------------------------\n",
      "\n",
      "TRADING BEHAVIOR:\n",
      "  BUY_Up: 51.0%\n",
      "  BUY_Down: 49.0%\n",
      "\n",
      "  Trade size mode: 20.0\n",
      "\n",
      "POSITION PERFORMANCE:\n",
      "  Mean PnL: $0.96\n",
      "  Win rate (by snapshot): 51.3%\n",
      "\n",
      "MARKET CONDITIONS:\n",
      "  Avg UP spread: 0.9800\n",
      "  Avg DOWN spread: 0.9800\n",
      "  Avg UP implied prob: 50.0%\n",
      "\n",
      "ðŸ“‹ NEXT STEPS (Phase 2)\n",
      "----------------------------------------\n",
      "1. Merge trades with BTC prices to find entry triggers\n",
      "2. Merge trades with orderbook to analyze execution\n",
      "3. Build full state reconstruction\n",
      "4. Run decision tree analysis to extract rules\n",
      "\n",
      "âœ“ Phase 1 analysis complete at: 2025-12-22 22:02:17.258818\n",
      "âœ“ Processed data saved to: analysis_output/\n",
      "\n",
      "Run Phase 2 for merged analysis and strategy identification.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "================================================================================\n",
    "PHASE 1: INDIVIDUAL DATASET ANALYSIS\n",
    "================================================================================\n",
    "Polymarket Bitcoin Bot Strategy Reverse-Engineering\n",
    "\n",
    "This script analyzes each of the 4 datasets individually to understand:\n",
    "1. Data quality, completeness, and temporal coverage\n",
    "2. Basic statistical properties\n",
    "3. Patterns that might hint at the bot's strategy\n",
    "\n",
    "JUSTIFICATION FOR PHASE 1:\n",
    "Before merging datasets, we need to understand each one individually:\n",
    "- Verify data integrity and identify any gaps/anomalies\n",
    "- Establish baseline statistics for comparison\n",
    "- Identify obvious patterns that don't require cross-referencing\n",
    "- Ensure timestamp formats are compatible for later merging\n",
    "\n",
    "Author: Strategy Analysis Pipeline\n",
    "Date: December 2024\n",
    "================================================================================\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# For visualization (optional - comment out if not needed)\n",
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "    import matplotlib.dates as mdates\n",
    "    PLOTTING_AVAILABLE = True\n",
    "except ImportError:\n",
    "    PLOTTING_AVAILABLE = False\n",
    "    print(\"matplotlib not available - will skip visualizations\")\n",
    "\n",
    "try:\n",
    "    import seaborn as sns\n",
    "    SEABORN_AVAILABLE = True\n",
    "except ImportError:\n",
    "    SEABORN_AVAILABLE = False\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# CONFIGURATION - UPDATE THESE PATHS TO MATCH YOUR LOCAL SETUP\n",
    "# ============================================================================\n",
    "\n",
    "CONFIG = {\n",
    "    'bitcoin_prices_path': 'polymarket_data/bitcoin_prices.parquet',\n",
    "    'orderbook_path': 'polymarket_data/orderbook_snapshots.parquet',\n",
    "    'positions_path': 'polymarket_data/positions_live.parquet',  # Update filename\n",
    "    'trades_path': 'polymarket_data/trades_history.parquet',  # Update filename\n",
    "    'output_dir': 'analysis_output/',\n",
    "}\n",
    "\n",
    "# Create output directory\n",
    "import os\n",
    "os.makedirs(CONFIG['output_dir'], exist_ok=True)\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# UTILITY FUNCTIONS\n",
    "# ============================================================================\n",
    "\n",
    "def print_section(title):\n",
    "    \"\"\"Print a formatted section header\"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\" {title}\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "def print_subsection(title):\n",
    "    \"\"\"Print a formatted subsection header\"\"\"\n",
    "    print(f\"\\n--- {title} ---\")\n",
    "\n",
    "def safe_describe(series, name=\"\"):\n",
    "    \"\"\"Safely describe a series, handling edge cases\"\"\"\n",
    "    print(f\"\\n{name}:\")\n",
    "    try:\n",
    "        desc = series.describe()\n",
    "        print(desc)\n",
    "        return desc\n",
    "    except Exception as e:\n",
    "        print(f\"  Error describing: {e}\")\n",
    "        return None\n",
    "\n",
    "def convert_unix_timestamp(ts, unit='s'):\n",
    "    \"\"\"\n",
    "    Convert unix timestamp to datetime.\n",
    "    \n",
    "    JUSTIFICATION:\n",
    "    The datasets use different timestamp formats:\n",
    "    - Some use seconds since epoch\n",
    "    - Some use milliseconds or microseconds\n",
    "    We need to normalize all to datetime for proper merging.\n",
    "    \"\"\"\n",
    "    if ts > 1e12:  # Likely milliseconds\n",
    "        return pd.to_datetime(ts, unit='ms')\n",
    "    elif ts > 1e15:  # Likely microseconds\n",
    "        return pd.to_datetime(ts, unit='us')\n",
    "    else:  # Likely seconds\n",
    "        return pd.to_datetime(ts, unit='s')\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# 1A. BITCOIN PRICE ANALYSIS\n",
    "# ============================================================================\n",
    "\n",
    "def analyze_bitcoin_prices(filepath):\n",
    "    \"\"\"\n",
    "    Comprehensive analysis of the Bitcoin price dataset.\n",
    "    \n",
    "    JUSTIFICATION:\n",
    "    The BTC price is the fundamental input that likely drives the bot's decisions.\n",
    "    Understanding price dynamics during the trading period tells us:\n",
    "    - What market conditions the bot operates in\n",
    "    - What price movements might trigger entries/exits\n",
    "    - The baseline volatility the bot is trying to predict\n",
    "    \n",
    "    KEY QUESTIONS:\n",
    "    - What's the tick frequency? (determines reaction time possible)\n",
    "    - What's the typical price movement in a 15-min window?\n",
    "    - Are there any data gaps that could affect analysis?\n",
    "    \"\"\"\n",
    "    print_section(\"1A. BITCOIN PRICE ANALYSIS\")\n",
    "    \n",
    "    try:\n",
    "        df = pd.read_parquet(filepath)\n",
    "        print(f\"âœ“ Loaded {len(df):,} price records\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"âœ— File not found: {filepath}\")\n",
    "        print(\"  Please update CONFIG['bitcoin_prices_path'] with the correct path\")\n",
    "        return None\n",
    "    \n",
    "    # Display schema\n",
    "    print_subsection(\"Schema\")\n",
    "    print(df.dtypes)\n",
    "    print(f\"\\nColumns: {list(df.columns)}\")\n",
    "    \n",
    "    # Parse timestamps\n",
    "    print_subsection(\"Timestamp Analysis\")\n",
    "    \n",
    "    # Check if system_timestamp is already datetime\n",
    "    if df['system_timestamp'].dtype == 'datetime64[ns]':\n",
    "        df['datetime'] = df['system_timestamp']\n",
    "    else:\n",
    "        # Try to parse\n",
    "        df['datetime'] = pd.to_datetime(df['system_timestamp'])\n",
    "    \n",
    "    print(f\"Time range: {df['datetime'].min()} to {df['datetime'].max()}\")\n",
    "    print(f\"Total duration: {df['datetime'].max() - df['datetime'].min()}\")\n",
    "    \n",
    "    # Tick frequency analysis\n",
    "    # JUSTIFICATION: Understanding tick frequency tells us the minimum reaction time\n",
    "    # the bot can have - if ticks are every 100ms, bot can't react faster than that\n",
    "    df_sorted = df.sort_values('datetime')\n",
    "    df_sorted['time_delta'] = df_sorted['datetime'].diff().dt.total_seconds()\n",
    "    \n",
    "    print_subsection(\"Tick Frequency (time between price updates)\")\n",
    "    print(f\"Mean: {df_sorted['time_delta'].mean():.4f} seconds\")\n",
    "    print(f\"Median: {df_sorted['time_delta'].median():.4f} seconds\")\n",
    "    print(f\"Min: {df_sorted['time_delta'].min():.4f} seconds\")\n",
    "    print(f\"Max: {df_sorted['time_delta'].max():.4f} seconds\")\n",
    "    print(f\"Std: {df_sorted['time_delta'].std():.4f} seconds\")\n",
    "    \n",
    "    # Check for gaps (> 5 seconds between ticks)\n",
    "    gaps = df_sorted[df_sorted['time_delta'] > 5]\n",
    "    print(f\"\\nData gaps (>5 sec): {len(gaps)} occurrences\")\n",
    "    if len(gaps) > 0:\n",
    "        print(\"Largest gaps:\")\n",
    "        print(gaps.nlargest(5, 'time_delta')[['datetime', 'time_delta']])\n",
    "    \n",
    "    # Price statistics\n",
    "    print_subsection(\"Price Statistics\")\n",
    "    print(f\"Mean price: ${df['price'].mean():,.2f}\")\n",
    "    print(f\"Std dev: ${df['price'].std():,.2f}\")\n",
    "    print(f\"Min: ${df['price'].min():,.2f}\")\n",
    "    print(f\"Max: ${df['price'].max():,.2f}\")\n",
    "    print(f\"Range: ${df['price'].max() - df['price'].min():,.2f}\")\n",
    "    print(f\"Range %: {(df['price'].max() - df['price'].min()) / df['price'].mean() * 100:.4f}%\")\n",
    "    \n",
    "    # Returns analysis\n",
    "    # JUSTIFICATION: Returns (not raw prices) are what the bot likely uses for signals\n",
    "    # A prediction market on \"BTC up or down\" cares about direction, not level\n",
    "    print_subsection(\"Returns Analysis\")\n",
    "    df_sorted['return_1tick'] = df_sorted['price'].pct_change()\n",
    "    df_sorted['return_abs'] = df_sorted['price'].diff()\n",
    "    \n",
    "    print(f\"Mean 1-tick return: {df_sorted['return_1tick'].mean()*100:.6f}%\")\n",
    "    print(f\"Std 1-tick return: {df_sorted['return_1tick'].std()*100:.6f}%\")\n",
    "    print(f\"Max positive return: {df_sorted['return_1tick'].max()*100:.4f}%\")\n",
    "    print(f\"Max negative return: {df_sorted['return_1tick'].min()*100:.4f}%\")\n",
    "    \n",
    "    # Compute returns over different windows\n",
    "    # JUSTIFICATION: Bot might use different lookback windows - we need to test several\n",
    "    print_subsection(\"Multi-Window Returns (for later signal analysis)\")\n",
    "    \n",
    "    # Approximate returns for different time windows\n",
    "    # Note: This is approximate since ticks aren't perfectly spaced\n",
    "    avg_tick_time = df_sorted['time_delta'].median()\n",
    "    print(f\"Average tick interval: {avg_tick_time:.3f}s\")\n",
    "    \n",
    "    windows_seconds = [1, 5, 15, 30, 60, 300]  # 1s, 5s, 15s, 30s, 1min, 5min\n",
    "    for window in windows_seconds:\n",
    "        n_ticks = max(1, int(window / avg_tick_time))\n",
    "        df_sorted[f'return_{window}s'] = df_sorted['price'].pct_change(n_ticks)\n",
    "        std_return = df_sorted[f'return_{window}s'].std() * 100\n",
    "        print(f\"  {window:>3}s window (~{n_ticks} ticks): std = {std_return:.4f}%\")\n",
    "    \n",
    "    # Volatility analysis\n",
    "    # JUSTIFICATION: High volatility periods might be when the bot is most active\n",
    "    # or conversely when it stays out\n",
    "    print_subsection(\"Volatility Analysis\")\n",
    "    df_sorted['rolling_vol_60s'] = df_sorted['return_1tick'].rolling(\n",
    "        window=int(60/avg_tick_time)\n",
    "    ).std() * 100\n",
    "    \n",
    "    print(f\"Mean 60s rolling volatility: {df_sorted['rolling_vol_60s'].mean():.6f}%\")\n",
    "    print(f\"Max 60s rolling volatility: {df_sorted['rolling_vol_60s'].max():.6f}%\")\n",
    "    \n",
    "    # Direction analysis - crucial for up/down market\n",
    "    # JUSTIFICATION: This is literally what the prediction market is about\n",
    "    print_subsection(\"Direction Analysis (Up vs Down moves)\")\n",
    "    up_moves = (df_sorted['return_1tick'] > 0).sum()\n",
    "    down_moves = (df_sorted['return_1tick'] < 0).sum()\n",
    "    flat = (df_sorted['return_1tick'] == 0).sum()\n",
    "    \n",
    "    print(f\"Up ticks: {up_moves:,} ({up_moves/len(df_sorted)*100:.1f}%)\")\n",
    "    print(f\"Down ticks: {down_moves:,} ({down_moves/len(df_sorted)*100:.1f}%)\")\n",
    "    print(f\"Flat ticks: {flat:,} ({flat/len(df_sorted)*100:.1f}%)\")\n",
    "    \n",
    "    # Save processed data\n",
    "    output_path = CONFIG['output_dir'] + 'btc_prices_processed.parquet'\n",
    "    df_sorted.to_parquet(output_path)\n",
    "    print(f\"\\nâœ“ Saved processed BTC data to: {output_path}\")\n",
    "    \n",
    "    return df_sorted\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# 1B. TRADE ANALYSIS\n",
    "# ============================================================================\n",
    "\n",
    "def analyze_trades(filepath):\n",
    "    \"\"\"\n",
    "    Comprehensive analysis of the bot's executed trades.\n",
    "    \n",
    "    JUSTIFICATION:\n",
    "    This is THE GOLDMINE. Every trade is a decision the bot made.\n",
    "    By analyzing trade patterns, we can understand:\n",
    "    - When does the bot enter/exit?\n",
    "    - What sizes does it use?\n",
    "    - Does it prefer UP or DOWN outcomes?\n",
    "    - What prices does it pay (market vs limit)?\n",
    "    \n",
    "    KEY QUESTIONS:\n",
    "    - What's the distribution of BUY vs SELL?\n",
    "    - What's the distribution of UP vs DOWN outcomes?\n",
    "    - Are trade sizes fixed or variable?\n",
    "    - What's the timing pattern within 15-min windows?\n",
    "    \"\"\"\n",
    "    print_section(\"1B. TRADE ANALYSIS (THE GOLDMINE)\")\n",
    "    \n",
    "    try:\n",
    "        df = pd.read_parquet(filepath)\n",
    "        print(f\"âœ“ Loaded {len(df):,} trades\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"âœ— File not found: {filepath}\")\n",
    "        print(\"  Please update CONFIG['trades_path'] with the correct path\")\n",
    "        return None\n",
    "    \n",
    "    # Display schema\n",
    "    print_subsection(\"Schema\")\n",
    "    print(df.dtypes)\n",
    "    print(f\"\\nColumns: {list(df.columns)}\")\n",
    "    print(f\"\\nFirst 3 rows:\")\n",
    "    print(df.head(3))\n",
    "    \n",
    "    # Parse timestamps\n",
    "    print_subsection(\"Timestamp Analysis\")\n",
    "    \n",
    "    # Check if timestamp is already datetime, otherwise convert\n",
    "    if 'timestamp' in df.columns and pd.api.types.is_datetime64_any_dtype(df['timestamp']):\n",
    "        df['datetime'] = df['timestamp']\n",
    "    elif 'unix_timestamp' in df.columns:\n",
    "        df['datetime'] = pd.to_datetime(df['unix_timestamp'], unit='s')\n",
    "    elif 'timestamp' in df.columns:\n",
    "        df['datetime'] = pd.to_datetime(df['timestamp'])\n",
    "    \n",
    "    print(f\"Time range: {df['datetime'].min()} to {df['datetime'].max()}\")\n",
    "    print(f\"Total duration: {df['datetime'].max() - df['datetime'].min()}\")\n",
    "    \n",
    "    # Trade count and frequency\n",
    "    print_subsection(\"Trade Frequency\")\n",
    "    total_seconds = (df['datetime'].max() - df['datetime'].min()).total_seconds()\n",
    "    trades_per_minute = len(df) / (total_seconds / 60) if total_seconds > 0 else 0\n",
    "    print(f\"Total trades: {len(df):,}\")\n",
    "    print(f\"Trades per minute: {trades_per_minute:.2f}\")\n",
    "    \n",
    "    # Inter-trade time analysis\n",
    "    df_sorted = df.sort_values('datetime')\n",
    "    df_sorted['time_since_last_trade'] = df_sorted['datetime'].diff().dt.total_seconds()\n",
    "    \n",
    "    print(f\"\\nTime between trades:\")\n",
    "    print(f\"  Mean: {df_sorted['time_since_last_trade'].mean():.2f} seconds\")\n",
    "    print(f\"  Median: {df_sorted['time_since_last_trade'].median():.2f} seconds\")\n",
    "    print(f\"  Min: {df_sorted['time_since_last_trade'].min():.2f} seconds\")\n",
    "    print(f\"  Max: {df_sorted['time_since_last_trade'].max():.2f} seconds\")\n",
    "    \n",
    "    # Side analysis (BUY vs SELL)\n",
    "    # JUSTIFICATION: Understanding when bot buys vs sells reveals entry/exit logic\n",
    "    print_subsection(\"Side Analysis (BUY vs SELL)\")\n",
    "    side_counts = df['side'].value_counts()\n",
    "    print(side_counts)\n",
    "    print(f\"\\nBuy/Sell Ratio: {side_counts.get('BUY', 0) / max(side_counts.get('SELL', 1), 1):.2f}\")\n",
    "    \n",
    "    # Outcome analysis (UP vs DOWN)\n",
    "    # JUSTIFICATION: Does bot favor one direction? Or trade both equally?\n",
    "    print_subsection(\"Outcome Analysis (UP vs DOWN)\")\n",
    "    outcome_counts = df['outcome'].value_counts()\n",
    "    print(outcome_counts)\n",
    "    \n",
    "    # Combined side + outcome analysis\n",
    "    # JUSTIFICATION: The 4 combinations reveal the full strategy:\n",
    "    # BUY UP = betting BTC goes up\n",
    "    # SELL UP = closing a BTC up bet OR shorting\n",
    "    # BUY DOWN = betting BTC goes down\n",
    "    # SELL DOWN = closing a BTC down bet OR shorting\n",
    "    print_subsection(\"Combined Side + Outcome Analysis\")\n",
    "    df['action'] = df['side'] + '_' + df['outcome']\n",
    "    df_sorted['action'] = df_sorted['side'] + '_' + df_sorted['outcome']  # Add to sorted df too\n",
    "    action_counts = df['action'].value_counts()\n",
    "    print(action_counts)\n",
    "    print(f\"\\nAction distribution (%):\")\n",
    "    print((action_counts / len(df) * 100).round(2))\n",
    "    \n",
    "    # Trade size analysis\n",
    "    # JUSTIFICATION: Fixed sizes suggest systematic strategy; variable sizes suggest scaling\n",
    "    print_subsection(\"Trade Size Analysis\")\n",
    "    print(f\"Size statistics:\")\n",
    "    print(f\"  Mean: {df['size'].mean():.4f}\")\n",
    "    print(f\"  Median: {df['size'].median():.4f}\")\n",
    "    print(f\"  Std: {df['size'].std():.4f}\")\n",
    "    print(f\"  Min: {df['size'].min():.4f}\")\n",
    "    print(f\"  Max: {df['size'].max():.4f}\")\n",
    "    \n",
    "    # Check if sizes are fixed\n",
    "    unique_sizes = df['size'].nunique()\n",
    "    print(f\"\\nUnique trade sizes: {unique_sizes}\")\n",
    "    if unique_sizes <= 10:\n",
    "        print(\"Size distribution:\")\n",
    "        print(df['size'].value_counts().head(10))\n",
    "    \n",
    "    # Size by action\n",
    "    print(\"\\nMean size by action:\")\n",
    "    print(df.groupby('action')['size'].mean())\n",
    "    \n",
    "    # Trade price analysis\n",
    "    # JUSTIFICATION: Prices reveal if bot is paying spread (market orders) \n",
    "    # or getting filled at limit prices\n",
    "    print_subsection(\"Trade Price Analysis\")\n",
    "    print(f\"Price statistics:\")\n",
    "    print(f\"  Mean: {df['price'].mean():.4f}\")\n",
    "    print(f\"  Median: {df['price'].median():.4f}\")\n",
    "    print(f\"  Min: {df['price'].min():.4f}\")\n",
    "    print(f\"  Max: {df['price'].max():.4f}\")\n",
    "    \n",
    "    # Price by outcome\n",
    "    print(\"\\nMean price by outcome:\")\n",
    "    print(df.groupby('outcome')['price'].agg(['mean', 'min', 'max']))\n",
    "    \n",
    "    # Price by action\n",
    "    print(\"\\nMean price by action:\")\n",
    "    print(df.groupby('action')['price'].mean())\n",
    "    \n",
    "    # Trade value analysis\n",
    "    # JUSTIFICATION: Total capital deployed per trade\n",
    "    print_subsection(\"Trade Value Analysis (price * size)\")\n",
    "    if 'value' in df.columns:\n",
    "        print(f\"Value statistics:\")\n",
    "        print(f\"  Mean: ${df['value'].mean():.4f}\")\n",
    "        print(f\"  Total: ${df['value'].sum():.2f}\")\n",
    "    else:\n",
    "        df['value'] = df['price'] * df['size']\n",
    "        print(f\"Computed value (price * size):\")\n",
    "        print(f\"  Mean: ${df['value'].mean():.4f}\")\n",
    "        print(f\"  Total: ${df['value'].sum():.2f}\")\n",
    "    \n",
    "    # Timing within market window analysis\n",
    "    # JUSTIFICATION: 15-minute markets have a specific lifecycle\n",
    "    # Bot might trade more at open, close, or specific times\n",
    "    print_subsection(\"Timing Within 15-Minute Windows\")\n",
    "    \n",
    "    # Extract the market slug to understand which 15-min window\n",
    "    if 'slug' in df.columns or 'market_slug' in df.columns:\n",
    "        slug_col = 'slug' if 'slug' in df.columns else 'market_slug'\n",
    "        print(f\"Markets traded:\")\n",
    "        print(df[slug_col].value_counts())\n",
    "    \n",
    "    # Calculate seconds into each 15-minute window\n",
    "    # The market slug contains the start timestamp\n",
    "    # Format: btc-updown-15m-{unix_timestamp}\n",
    "    if 'slug' in df.columns:\n",
    "        try:\n",
    "            # Extract market start time from slug\n",
    "            df['market_start_unix'] = df['slug'].str.extract(r'(\\d+)$').astype(float)\n",
    "            df['market_start'] = pd.to_datetime(df['market_start_unix'], unit='s')\n",
    "            df['seconds_into_window'] = (df['datetime'] - df['market_start']).dt.total_seconds()\n",
    "            \n",
    "            print(f\"\\nSeconds into 15-min window when trading:\")\n",
    "            print(f\"  Mean: {df['seconds_into_window'].mean():.1f}s\")\n",
    "            print(f\"  Median: {df['seconds_into_window'].median():.1f}s\")\n",
    "            print(f\"  Min: {df['seconds_into_window'].min():.1f}s\")\n",
    "            print(f\"  Max: {df['seconds_into_window'].max():.1f}s\")\n",
    "            \n",
    "            # Bin into early/mid/late\n",
    "            df['window_phase'] = pd.cut(\n",
    "                df['seconds_into_window'], \n",
    "                bins=[0, 300, 600, 900],  # 0-5min, 5-10min, 10-15min\n",
    "                labels=['Early (0-5min)', 'Mid (5-10min)', 'Late (10-15min)']\n",
    "            )\n",
    "            print(\"\\nTrades by window phase:\")\n",
    "            print(df['window_phase'].value_counts())\n",
    "        except Exception as e:\n",
    "            print(f\"Could not parse market timing: {e}\")\n",
    "    \n",
    "    # Sequence analysis\n",
    "    # JUSTIFICATION: Understanding trade sequences reveals position building/closing patterns\n",
    "    print_subsection(\"Trade Sequence Analysis\")\n",
    "    \n",
    "    # Look at consecutive trades\n",
    "    df_sorted['prev_action'] = df_sorted['action'].shift(1)\n",
    "    df_sorted['action_sequence'] = df_sorted['prev_action'] + ' â†’ ' + df_sorted['action']\n",
    "    \n",
    "    print(\"Most common action sequences:\")\n",
    "    print(df_sorted['action_sequence'].value_counts().head(10))\n",
    "    \n",
    "    # Check for rapid sequences (trades within 5 seconds)\n",
    "    rapid_trades = df_sorted[df_sorted['time_since_last_trade'] < 5]\n",
    "    print(f\"\\nRapid trades (<5 sec apart): {len(rapid_trades)} ({len(rapid_trades)/len(df)*100:.1f}%)\")\n",
    "    if len(rapid_trades) > 0:\n",
    "        print(\"Rapid trade sequences:\")\n",
    "        print(rapid_trades['action_sequence'].value_counts().head(5))\n",
    "    \n",
    "    # Save processed data\n",
    "    output_path = CONFIG['output_dir'] + 'trades_processed.parquet'\n",
    "    df_sorted.to_parquet(output_path)\n",
    "    print(f\"\\nâœ“ Saved processed trades data to: {output_path}\")\n",
    "    \n",
    "    return df_sorted\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# 1C. POSITION ANALYSIS\n",
    "# ============================================================================\n",
    "\n",
    "def analyze_positions(filepath):\n",
    "    \"\"\"\n",
    "    Comprehensive analysis of position snapshots.\n",
    "    \n",
    "    JUSTIFICATION:\n",
    "    Position data shows the bot's exposure over time:\n",
    "    - How positions evolve from entry to exit\n",
    "    - PnL characteristics (wins vs losses)\n",
    "    - Position sizing patterns\n",
    "    - Risk management behavior\n",
    "    \n",
    "    KEY QUESTIONS:\n",
    "    - What's the typical position size?\n",
    "    - How long are positions held?\n",
    "    - What's the win rate and average win/loss?\n",
    "    - Does the bot cut losses or let them run?\n",
    "    \"\"\"\n",
    "    print_section(\"1C. POSITION ANALYSIS\")\n",
    "    \n",
    "    try:\n",
    "        df = pd.read_parquet(filepath)\n",
    "        print(f\"âœ“ Loaded {len(df):,} position snapshots\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"âœ— File not found: {filepath}\")\n",
    "        print(\"  Please update CONFIG['positions_path'] with the correct path\")\n",
    "        return None\n",
    "    \n",
    "    # Display schema\n",
    "    print_subsection(\"Schema\")\n",
    "    print(df.dtypes)\n",
    "    print(f\"\\nColumns: {list(df.columns)}\")\n",
    "    \n",
    "    # Basic stats\n",
    "    print_subsection(\"Basic Statistics\")\n",
    "    print(f\"Total snapshots: {len(df):,}\")\n",
    "    \n",
    "    # Unique positions\n",
    "    if 'position_id' in df.columns:\n",
    "        print(f\"Unique position IDs: {df['position_id'].nunique()}\")\n",
    "    \n",
    "    # Outcome distribution\n",
    "    print_subsection(\"Outcome Distribution (UP vs DOWN positions)\")\n",
    "    if 'outcome' in df.columns:\n",
    "        print(df['outcome'].value_counts())\n",
    "    \n",
    "    # Shares analysis\n",
    "    # JUSTIFICATION: Position sizes reveal risk appetite and scaling behavior\n",
    "    print_subsection(\"Shares (Position Size) Analysis\")\n",
    "    print(f\"Shares statistics:\")\n",
    "    print(f\"  Mean: {df['shares'].mean():.2f}\")\n",
    "    print(f\"  Median: {df['shares'].median():.2f}\")\n",
    "    print(f\"  Std: {df['shares'].std():.2f}\")\n",
    "    print(f\"  Max: {df['shares'].max():.2f}\")\n",
    "    \n",
    "    print(\"\\nShares by outcome:\")\n",
    "    print(df.groupby('outcome')['shares'].describe())\n",
    "    \n",
    "    # Price analysis\n",
    "    # JUSTIFICATION: avg_price vs current_price shows position profitability\n",
    "    print_subsection(\"Price Analysis\")\n",
    "    print(f\"Average entry price (avg_price):\")\n",
    "    print(f\"  Mean: {df['avg_price'].mean():.4f}\")\n",
    "    print(f\"  Range: {df['avg_price'].min():.4f} to {df['avg_price'].max():.4f}\")\n",
    "    \n",
    "    print(f\"\\nCurrent price:\")\n",
    "    print(f\"  Mean: {df['current_price'].mean():.4f}\")\n",
    "    print(f\"  Range: {df['current_price'].min():.4f} to {df['current_price'].max():.4f}\")\n",
    "    \n",
    "    # PnL Analysis - THIS IS CRITICAL\n",
    "    # JUSTIFICATION: PnL distribution reveals strategy effectiveness\n",
    "    print_subsection(\"PnL Analysis (CRITICAL)\")\n",
    "    \n",
    "    # Cash PnL\n",
    "    print(f\"Cash PnL statistics:\")\n",
    "    print(f\"  Mean: ${df['cash_pnl'].mean():.2f}\")\n",
    "    print(f\"  Median: ${df['cash_pnl'].median():.2f}\")\n",
    "    print(f\"  Std: ${df['cash_pnl'].std():.2f}\")\n",
    "    print(f\"  Min: ${df['cash_pnl'].min():.2f}\")\n",
    "    print(f\"  Max: ${df['cash_pnl'].max():.2f}\")\n",
    "    \n",
    "    # Percent PnL\n",
    "    print(f\"\\nPercent PnL statistics:\")\n",
    "    print(f\"  Mean: {df['percent_pnl'].mean():.2f}%\")\n",
    "    print(f\"  Median: {df['percent_pnl'].median():.2f}%\")\n",
    "    print(f\"  Min: {df['percent_pnl'].min():.2f}%\")\n",
    "    print(f\"  Max: {df['percent_pnl'].max():.2f}%\")\n",
    "    \n",
    "    # Win/Loss analysis\n",
    "    winning = df[df['cash_pnl'] > 0]\n",
    "    losing = df[df['cash_pnl'] < 0]\n",
    "    breakeven = df[df['cash_pnl'] == 0]\n",
    "    \n",
    "    print(f\"\\nWin/Loss breakdown (by snapshot):\")\n",
    "    print(f\"  Winning: {len(winning):,} ({len(winning)/len(df)*100:.1f}%)\")\n",
    "    print(f\"  Losing: {len(losing):,} ({len(losing)/len(df)*100:.1f}%)\")\n",
    "    print(f\"  Breakeven: {len(breakeven):,} ({len(breakeven)/len(df)*100:.1f}%)\")\n",
    "    \n",
    "    if len(winning) > 0:\n",
    "        print(f\"\\nAverage winning PnL: ${winning['cash_pnl'].mean():.2f}\")\n",
    "    if len(losing) > 0:\n",
    "        print(f\"Average losing PnL: ${losing['cash_pnl'].mean():.2f}\")\n",
    "    \n",
    "    # PnL by outcome\n",
    "    print(\"\\nPnL by outcome (UP vs DOWN positions):\")\n",
    "    print(df.groupby('outcome')['cash_pnl'].describe())\n",
    "    \n",
    "    # Realized vs Unrealized PnL\n",
    "    # JUSTIFICATION: Shows if bot is locking in profits or letting them ride\n",
    "    print_subsection(\"Realized vs Unrealized PnL\")\n",
    "    if 'realized_pnl' in df.columns:\n",
    "        print(f\"Realized PnL:\")\n",
    "        print(f\"  Mean: ${df['realized_pnl'].mean():.2f}\")\n",
    "        print(f\"  Total: ${df['realized_pnl'].sum():.2f}\")\n",
    "        \n",
    "        print(f\"\\nPercent Realized PnL:\")\n",
    "        print(f\"  Mean: {df['percent_realized_pnl'].mean():.2f}%\")\n",
    "    \n",
    "    # Value analysis\n",
    "    print_subsection(\"Position Value Analysis\")\n",
    "    print(f\"Initial value:\")\n",
    "    print(f\"  Mean: ${df['initial_value'].mean():.2f}\")\n",
    "    print(f\"  Total: ${df['initial_value'].sum():.2f}\")\n",
    "    \n",
    "    print(f\"\\nCurrent value:\")\n",
    "    print(f\"  Mean: ${df['current_value'].mean():.2f}\")\n",
    "    print(f\"  Total: ${df['current_value'].sum():.2f}\")\n",
    "    \n",
    "    # Total bought\n",
    "    print(f\"\\nTotal bought:\")\n",
    "    print(f\"  Mean: ${df['total_bought'].mean():.2f}\")\n",
    "    print(f\"  Max: ${df['total_bought'].max():.2f}\")\n",
    "    \n",
    "    # Redeemable status\n",
    "    # JUSTIFICATION: Shows if positions are being closed at market resolution\n",
    "    print_subsection(\"Redeemable Status\")\n",
    "    if 'redeemable' in df.columns:\n",
    "        print(df['redeemable'].value_counts())\n",
    "    \n",
    "    # End date analysis\n",
    "    print_subsection(\"Market End Date Analysis\")\n",
    "    if 'end_date' in df.columns:\n",
    "        print(f\"End dates:\")\n",
    "        print(df['end_date'].value_counts())\n",
    "    \n",
    "    # Save processed data\n",
    "    output_path = CONFIG['output_dir'] + 'positions_processed.parquet'\n",
    "    df.to_parquet(output_path)\n",
    "    print(f\"\\nâœ“ Saved processed positions data to: {output_path}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# 1D. ORDERBOOK ANALYSIS\n",
    "# ============================================================================\n",
    "\n",
    "def analyze_orderbook(filepath):\n",
    "    \"\"\"\n",
    "    Comprehensive analysis of orderbook snapshots.\n",
    "    \n",
    "    JUSTIFICATION:\n",
    "    The orderbook reveals market microstructure:\n",
    "    - What prices are available when bot trades\n",
    "    - Spread conditions (cost of trading)\n",
    "    - Market-implied probabilities\n",
    "    - Liquidity conditions\n",
    "    \n",
    "    KEY QUESTIONS:\n",
    "    - What's the typical spread?\n",
    "    - How do UP and DOWN prices relate?\n",
    "    - Are there arbitrage opportunities?\n",
    "    - When is liquidity best/worst?\n",
    "    \"\"\"\n",
    "    print_section(\"1D. ORDERBOOK ANALYSIS\")\n",
    "    \n",
    "    try:\n",
    "        df = pd.read_parquet(filepath)\n",
    "        print(f\"âœ“ Loaded {len(df):,} orderbook snapshots\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"âœ— File not found: {filepath}\")\n",
    "        print(\"  Please update CONFIG['orderbook_path'] with the correct path\")\n",
    "        return None\n",
    "    \n",
    "    # Display schema\n",
    "    print_subsection(\"Schema\")\n",
    "    print(df.dtypes)\n",
    "    print(f\"\\nColumns: {list(df.columns)}\")\n",
    "    \n",
    "    # Parse timestamps\n",
    "    print_subsection(\"Timestamp Analysis\")\n",
    "    if 'timestamp' in df.columns:\n",
    "        df['datetime'] = pd.to_datetime(df['timestamp'])\n",
    "    elif 'unixtime' in df.columns:\n",
    "        df['datetime'] = pd.to_datetime(df['unixtime'], unit='s')\n",
    "    \n",
    "    print(f\"Time range: {df['datetime'].min()} to {df['datetime'].max()}\")\n",
    "    print(f\"Total duration: {df['datetime'].max() - df['datetime'].min()}\")\n",
    "    \n",
    "    # Snapshot frequency\n",
    "    df_sorted = df.sort_values('datetime')\n",
    "    df_sorted['time_delta'] = df_sorted['datetime'].diff().dt.total_seconds()\n",
    "    print(f\"\\nSnapshot frequency:\")\n",
    "    print(f\"  Mean: {df_sorted['time_delta'].mean():.2f} seconds\")\n",
    "    print(f\"  Median: {df_sorted['time_delta'].median():.2f} seconds\")\n",
    "    \n",
    "    # Market slug analysis\n",
    "    print_subsection(\"Market Coverage\")\n",
    "    if 'market_slug' in df.columns:\n",
    "        print(df['market_slug'].value_counts())\n",
    "    \n",
    "    # UP outcome analysis\n",
    "    # JUSTIFICATION: UP prices tell us market's view on BTC going up\n",
    "    print_subsection(\"UP Outcome Orderbook\")\n",
    "    print(f\"UP Best Bid:\")\n",
    "    print(f\"  Mean: {df['up_best_bid'].mean():.4f}\")\n",
    "    print(f\"  Min: {df['up_best_bid'].min():.4f}\")\n",
    "    print(f\"  Max: {df['up_best_bid'].max():.4f}\")\n",
    "    \n",
    "    print(f\"\\nUP Best Ask:\")\n",
    "    print(f\"  Mean: {df['up_best_ask'].mean():.4f}\")\n",
    "    print(f\"  Min: {df['up_best_ask'].min():.4f}\")\n",
    "    print(f\"  Max: {df['up_best_ask'].max():.4f}\")\n",
    "    \n",
    "    print(f\"\\nUP Spread:\")\n",
    "    print(f\"  Mean: {df['up_spread'].mean():.4f}\")\n",
    "    print(f\"  Min: {df['up_spread'].min():.4f}\")\n",
    "    print(f\"  Max: {df['up_spread'].max():.4f}\")\n",
    "    \n",
    "    # DOWN outcome analysis\n",
    "    print_subsection(\"DOWN Outcome Orderbook\")\n",
    "    print(f\"DOWN Best Bid:\")\n",
    "    print(f\"  Mean: {df['down_best_bid'].mean():.4f}\")\n",
    "    print(f\"  Min: {df['down_best_bid'].min():.4f}\")\n",
    "    print(f\"  Max: {df['down_best_bid'].max():.4f}\")\n",
    "    \n",
    "    print(f\"\\nDOWN Best Ask:\")\n",
    "    print(f\"  Mean: {df['down_best_ask'].mean():.4f}\")\n",
    "    print(f\"  Min: {df['down_best_ask'].min():.4f}\")\n",
    "    print(f\"  Max: {df['down_best_ask'].max():.4f}\")\n",
    "    \n",
    "    print(f\"\\nDOWN Spread:\")\n",
    "    print(f\"  Mean: {df['down_spread'].mean():.4f}\")\n",
    "    print(f\"  Min: {df['down_spread'].min():.4f}\")\n",
    "    print(f\"  Max: {df['down_spread'].max():.4f}\")\n",
    "    \n",
    "    # Midpoint prices (implied probabilities)\n",
    "    # JUSTIFICATION: Midpoint = market's implied probability of that outcome\n",
    "    print_subsection(\"Implied Probabilities (Midpoint Prices)\")\n",
    "    df['up_midpoint'] = (df['up_best_bid'] + df['up_best_ask']) / 2\n",
    "    df['down_midpoint'] = (df['down_best_bid'] + df['down_best_ask']) / 2\n",
    "    \n",
    "    print(f\"UP implied probability (midpoint):\")\n",
    "    print(f\"  Mean: {df['up_midpoint'].mean():.4f} ({df['up_midpoint'].mean()*100:.1f}%)\")\n",
    "    print(f\"  Range: {df['up_midpoint'].min():.4f} to {df['up_midpoint'].max():.4f}\")\n",
    "    \n",
    "    print(f\"\\nDOWN implied probability (midpoint):\")\n",
    "    print(f\"  Mean: {df['down_midpoint'].mean():.4f} ({df['down_midpoint'].mean()*100:.1f}%)\")\n",
    "    print(f\"  Range: {df['down_midpoint'].min():.4f} to {df['down_midpoint'].max():.4f}\")\n",
    "    \n",
    "    # Probability sum analysis\n",
    "    # JUSTIFICATION: UP + DOWN should = 1 in efficient market\n",
    "    # Deviation = overround (house edge) or arbitrage opportunity\n",
    "    print_subsection(\"Market Efficiency Analysis\")\n",
    "    df['prob_sum_mid'] = df['up_midpoint'] + df['down_midpoint']\n",
    "    df['prob_sum_bid'] = df['up_best_bid'] + df['down_best_bid']  # Can buy both for this\n",
    "    df['prob_sum_ask'] = df['up_best_ask'] + df['down_best_ask']  # Can sell both for this\n",
    "    \n",
    "    print(f\"Sum of midpoint probabilities (should be ~1.0):\")\n",
    "    print(f\"  Mean: {df['prob_sum_mid'].mean():.4f}\")\n",
    "    print(f\"  Min: {df['prob_sum_mid'].min():.4f}\")\n",
    "    print(f\"  Max: {df['prob_sum_mid'].max():.4f}\")\n",
    "    \n",
    "    # If you can buy both UP and DOWN for < $1, that's an arb\n",
    "    print(f\"\\nSum of best asks (cost to buy both outcomes):\")\n",
    "    print(f\"  Mean: {df['prob_sum_ask'].mean():.4f}\")\n",
    "    print(f\"  Min: {df['prob_sum_ask'].min():.4f}\")\n",
    "    \n",
    "    # If you can sell both UP and DOWN for > $1, that's an arb\n",
    "    print(f\"\\nSum of best bids (revenue from selling both outcomes):\")\n",
    "    print(f\"  Mean: {df['prob_sum_bid'].mean():.4f}\")\n",
    "    print(f\"  Max: {df['prob_sum_bid'].max():.4f}\")\n",
    "    \n",
    "    # Check for arbitrage opportunities\n",
    "    arb_buy = df[df['prob_sum_ask'] < 1.0]\n",
    "    arb_sell = df[df['prob_sum_bid'] > 1.0]\n",
    "    print(f\"\\nArbitrage opportunities (buy both < $1): {len(arb_buy)} snapshots\")\n",
    "    print(f\"Arbitrage opportunities (sell both > $1): {len(arb_sell)} snapshots\")\n",
    "    \n",
    "    # Depth analysis\n",
    "    # JUSTIFICATION: Depth = how much can be traded at current prices\n",
    "    print_subsection(\"Orderbook Depth Analysis\")\n",
    "    if 'up_bid_depth_5' in df.columns:\n",
    "        print(f\"UP Bid Depth (5 levels):\")\n",
    "        print(f\"  Mean: ${df['up_bid_depth_5'].mean():.2f}\")\n",
    "        print(f\"  Max: ${df['up_bid_depth_5'].max():.2f}\")\n",
    "        \n",
    "        print(f\"\\nUP Ask Depth (5 levels):\")\n",
    "        print(f\"  Mean: ${df['up_ask_depth_5'].mean():.2f}\")\n",
    "        print(f\"  Max: ${df['up_ask_depth_5'].max():.2f}\")\n",
    "    \n",
    "    # Implied sum analysis\n",
    "    # JUSTIFICATION: These appear to be the total implied probabilities from orderbook\n",
    "    print_subsection(\"Implied Sum (Bid/Ask)\")\n",
    "    if 'implied_sum_bid' in df.columns:\n",
    "        print(f\"Implied Sum Bid: {df['implied_sum_bid'].mean():.4f}\")\n",
    "        print(f\"Implied Sum Ask: {df['implied_sum_ask'].mean():.4f}\")\n",
    "    \n",
    "    # Spread comparison\n",
    "    # JUSTIFICATION: If one outcome has tighter spread, might be more liquid/efficient\n",
    "    print_subsection(\"UP vs DOWN Spread Comparison\")\n",
    "    df['spread_diff'] = df['up_spread'] - df['down_spread']\n",
    "    print(f\"UP spread - DOWN spread:\")\n",
    "    print(f\"  Mean: {df['spread_diff'].mean():.4f}\")\n",
    "    print(f\"  Positive (UP wider): {(df['spread_diff'] > 0).sum()} snapshots\")\n",
    "    print(f\"  Negative (DOWN wider): {(df['spread_diff'] < 0).sum()} snapshots\")\n",
    "    \n",
    "    # Save processed data\n",
    "    output_path = CONFIG['output_dir'] + 'orderbook_processed.parquet'\n",
    "    df.to_parquet(output_path)\n",
    "    print(f\"\\nâœ“ Saved processed orderbook data to: {output_path}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# SUMMARY REPORT\n",
    "# ============================================================================\n",
    "\n",
    "def generate_summary_report(btc_df, trades_df, positions_df, orderbook_df):\n",
    "    \"\"\"Generate a summary report of Phase 1 findings\"\"\"\n",
    "    print_section(\"PHASE 1 SUMMARY REPORT\")\n",
    "    \n",
    "    print(\"\\nðŸ“Š DATA OVERVIEW\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    if btc_df is not None:\n",
    "        print(f\"Bitcoin Prices: {len(btc_df):,} records\")\n",
    "    if trades_df is not None:\n",
    "        print(f\"Trades: {len(trades_df):,} records\")\n",
    "    if positions_df is not None:\n",
    "        print(f\"Position Snapshots: {len(positions_df):,} records\")\n",
    "    if orderbook_df is not None:\n",
    "        print(f\"Orderbook Snapshots: {len(orderbook_df):,} records\")\n",
    "    \n",
    "    print(\"\\nðŸ” KEY FINDINGS\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    if trades_df is not None:\n",
    "        print(\"\\nTRADING BEHAVIOR:\")\n",
    "        if 'action' in trades_df.columns:\n",
    "            action_pcts = trades_df['action'].value_counts(normalize=True) * 100\n",
    "            for action, pct in action_pcts.items():\n",
    "                print(f\"  {action}: {pct:.1f}%\")\n",
    "        \n",
    "        print(f\"\\n  Trade size mode: {trades_df['size'].mode().values[0] if len(trades_df['size'].mode()) > 0 else 'N/A'}\")\n",
    "        \n",
    "        if 'seconds_into_window' in trades_df.columns:\n",
    "            print(f\"  Avg entry time: {trades_df['seconds_into_window'].mean():.0f}s into window\")\n",
    "    \n",
    "    if positions_df is not None:\n",
    "        print(\"\\nPOSITION PERFORMANCE:\")\n",
    "        print(f\"  Mean PnL: ${positions_df['cash_pnl'].mean():.2f}\")\n",
    "        win_rate = (positions_df['cash_pnl'] > 0).mean() * 100\n",
    "        print(f\"  Win rate (by snapshot): {win_rate:.1f}%\")\n",
    "    \n",
    "    if orderbook_df is not None:\n",
    "        print(\"\\nMARKET CONDITIONS:\")\n",
    "        print(f\"  Avg UP spread: {orderbook_df['up_spread'].mean():.4f}\")\n",
    "        print(f\"  Avg DOWN spread: {orderbook_df['down_spread'].mean():.4f}\")\n",
    "        if 'up_midpoint' in orderbook_df.columns:\n",
    "            print(f\"  Avg UP implied prob: {orderbook_df['up_midpoint'].mean()*100:.1f}%\")\n",
    "    \n",
    "    print(\"\\nðŸ“‹ NEXT STEPS (Phase 2)\")\n",
    "    print(\"-\" * 40)\n",
    "    print(\"1. Merge trades with BTC prices to find entry triggers\")\n",
    "    print(\"2. Merge trades with orderbook to analyze execution\")\n",
    "    print(\"3. Build full state reconstruction\")\n",
    "    print(\"4. Run decision tree analysis to extract rules\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# MAIN EXECUTION\n",
    "# ============================================================================\n",
    "\n",
    "def main():\n",
    "    \"\"\"Run the complete Phase 1 analysis\"\"\"\n",
    "    print(\"=\"*80)\n",
    "    print(\" POLYMARKET BOT STRATEGY ANALYSIS - PHASE 1\")\n",
    "    print(\" Individual Dataset Analysis\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"\\nStarted at: {datetime.now()}\")\n",
    "    print(f\"Output directory: {CONFIG['output_dir']}\")\n",
    "    \n",
    "    # Run each analysis\n",
    "    btc_df = analyze_bitcoin_prices(CONFIG['bitcoin_prices_path'])\n",
    "    trades_df = analyze_trades(CONFIG['trades_path'])\n",
    "    positions_df = analyze_positions(CONFIG['positions_path'])\n",
    "    orderbook_df = analyze_orderbook(CONFIG['orderbook_path'])\n",
    "    \n",
    "    # Generate summary\n",
    "    generate_summary_report(btc_df, trades_df, positions_df, orderbook_df)\n",
    "    \n",
    "    print(f\"\\nâœ“ Phase 1 analysis complete at: {datetime.now()}\")\n",
    "    print(f\"âœ“ Processed data saved to: {CONFIG['output_dir']}\")\n",
    "    print(\"\\nRun Phase 2 for merged analysis and strategy identification.\")\n",
    "    \n",
    "    return {\n",
    "        'btc': btc_df,\n",
    "        'trades': trades_df,\n",
    "        'positions': positions_df,\n",
    "        'orderbook': orderbook_df\n",
    "    }\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    results = main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6de21571-8b9d-4f15-8bb5-8b16b2dfb67a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      " PHASE 1 VISUALIZATIONS\n",
      "============================================================\n",
      "\n",
      "Output directory: analysis_output/charts/\n",
      "\n",
      "Loading processed data...\n",
      "  âœ“ BTC data: 1,782 rows\n",
      "  âœ“ Trades data: 1,121 rows\n",
      "  âœ“ Positions data: 6,447 rows\n",
      "  âœ“ Orderbook data: 14,059 rows\n",
      "\n",
      "Generating visualizations...\n",
      "âœ“ Saved: analysis_output/charts/btc_analysis.png\n",
      "âœ“ Saved: analysis_output/charts/trade_analysis.png\n",
      "âœ“ Saved: analysis_output/charts/trade_price_analysis.png\n",
      "âœ“ Saved: analysis_output/charts/position_analysis.png\n",
      "âœ“ Saved: analysis_output/charts/orderbook_analysis.png\n",
      "âœ“ Saved: analysis_output/charts/orderbook_depth_analysis.png\n",
      "\n",
      "âœ“ All visualizations saved to: analysis_output/charts/\n",
      "\n",
      "Generated files:\n",
      "  - trade_price_analysis.png\n",
      "  - position_analysis.png\n",
      "  - orderbook_analysis.png\n",
      "  - btc_analysis.png\n",
      "  - orderbook_depth_analysis.png\n",
      "  - trade_analysis.png\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "================================================================================\n",
    "PHASE 1 VISUALIZATIONS\n",
    "================================================================================\n",
    "Generates charts for visual analysis of individual datasets.\n",
    "\n",
    "Run this AFTER phase1_individual_analysis.py to create visualizations.\n",
    "\n",
    "JUSTIFICATION:\n",
    "Visual analysis helps identify patterns that statistics alone might miss:\n",
    "- Distributions reveal outliers and skewness\n",
    "- Time series show temporal patterns\n",
    "- Histograms reveal clustering in decision variables\n",
    "================================================================================\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "# Try to import seaborn for better styling\n",
    "try:\n",
    "    import seaborn as sns\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    SEABORN_AVAILABLE = True\n",
    "except ImportError:\n",
    "    SEABORN_AVAILABLE = False\n",
    "\n",
    "# Configuration - same as main script\n",
    "CONFIG = {\n",
    "    'btc_processed': 'analysis_output/btc_prices_processed.parquet',\n",
    "    'trades_processed': 'analysis_output/trades_processed.parquet',\n",
    "    'positions_processed': 'analysis_output/positions_processed.parquet',\n",
    "    'orderbook_processed': 'analysis_output/orderbook_processed.parquet',\n",
    "    'output_dir': 'analysis_output/charts/',\n",
    "}\n",
    "\n",
    "os.makedirs(CONFIG['output_dir'], exist_ok=True)\n",
    "\n",
    "\n",
    "def plot_btc_analysis(df):\n",
    "    \"\"\"\n",
    "    Create visualizations for Bitcoin price data.\n",
    "    \n",
    "    JUSTIFICATION:\n",
    "    - Price chart shows overall market context\n",
    "    - Return distribution reveals if normal or fat-tailed\n",
    "    - Volatility chart shows when market is calm vs turbulent\n",
    "    \"\"\"\n",
    "    if df is None:\n",
    "        print(\"No BTC data to plot\")\n",
    "        return\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    fig.suptitle('Bitcoin Price Analysis', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # 1. Price over time\n",
    "    ax1 = axes[0, 0]\n",
    "    ax1.plot(df['datetime'], df['price'], linewidth=0.5, alpha=0.8)\n",
    "    ax1.set_title('BTC Price Over Time')\n",
    "    ax1.set_xlabel('Time')\n",
    "    ax1.set_ylabel('Price (USD)')\n",
    "    ax1.tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # 2. Return distribution\n",
    "    ax2 = axes[0, 1]\n",
    "    returns = df['return_1tick'].dropna()\n",
    "    ax2.hist(returns * 100, bins=100, edgecolor='black', alpha=0.7)\n",
    "    ax2.axvline(x=0, color='red', linestyle='--', label='Zero')\n",
    "    ax2.set_title('1-Tick Return Distribution')\n",
    "    ax2.set_xlabel('Return (%)')\n",
    "    ax2.set_ylabel('Frequency')\n",
    "    ax2.set_xlim(-0.1, 0.1)  # Focus on typical range\n",
    "    \n",
    "    # 3. Rolling volatility\n",
    "    ax3 = axes[1, 0]\n",
    "    if 'rolling_vol_60s' in df.columns:\n",
    "        ax3.plot(df['datetime'], df['rolling_vol_60s'], linewidth=0.5, alpha=0.8)\n",
    "        ax3.set_title('60-Second Rolling Volatility')\n",
    "        ax3.set_xlabel('Time')\n",
    "        ax3.set_ylabel('Volatility (%)')\n",
    "        ax3.tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # 4. Tick interval distribution\n",
    "    ax4 = axes[1, 1]\n",
    "    if 'time_delta' in df.columns:\n",
    "        valid_deltas = df['time_delta'].dropna()\n",
    "        valid_deltas = valid_deltas[valid_deltas < 10]  # Focus on typical range\n",
    "        ax4.hist(valid_deltas, bins=50, edgecolor='black', alpha=0.7)\n",
    "        ax4.set_title('Time Between Ticks Distribution')\n",
    "        ax4.set_xlabel('Seconds')\n",
    "        ax4.set_ylabel('Frequency')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(CONFIG['output_dir'] + 'btc_analysis.png', dpi=150, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"âœ“ Saved: {CONFIG['output_dir']}btc_analysis.png\")\n",
    "\n",
    "\n",
    "def plot_trade_analysis(df):\n",
    "    \"\"\"\n",
    "    Create visualizations for trade data.\n",
    "    \n",
    "    JUSTIFICATION:\n",
    "    - Action distribution shows strategy bias\n",
    "    - Size distribution reveals position sizing logic\n",
    "    - Timing histogram shows when bot is active within windows\n",
    "    - Sequence chart shows trade patterns\n",
    "    \"\"\"\n",
    "    if df is None:\n",
    "        print(\"No trade data to plot\")\n",
    "        return\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    fig.suptitle('Trade Analysis', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # 1. Action distribution (pie/bar)\n",
    "    ax1 = axes[0, 0]\n",
    "    if 'action' in df.columns:\n",
    "        action_counts = df['action'].value_counts()\n",
    "        colors = ['#2ecc71', '#e74c3c', '#3498db', '#f39c12'][:len(action_counts)]\n",
    "        bars = ax1.bar(action_counts.index, action_counts.values, color=colors, edgecolor='black')\n",
    "        ax1.set_title('Trade Actions Distribution')\n",
    "        ax1.set_ylabel('Count')\n",
    "        ax1.tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        # Add percentage labels\n",
    "        total = action_counts.sum()\n",
    "        for bar, count in zip(bars, action_counts.values):\n",
    "            ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5,\n",
    "                    f'{count/total*100:.1f}%', ha='center', va='bottom', fontsize=10)\n",
    "    \n",
    "    # 2. Trade size distribution\n",
    "    ax2 = axes[0, 1]\n",
    "    ax2.hist(df['size'], bins=30, edgecolor='black', alpha=0.7)\n",
    "    ax2.axvline(x=df['size'].mean(), color='red', linestyle='--', label=f'Mean: {df[\"size\"].mean():.2f}')\n",
    "    ax2.axvline(x=df['size'].median(), color='orange', linestyle='--', label=f'Median: {df[\"size\"].median():.2f}')\n",
    "    ax2.set_title('Trade Size Distribution')\n",
    "    ax2.set_xlabel('Size')\n",
    "    ax2.set_ylabel('Frequency')\n",
    "    ax2.legend()\n",
    "    \n",
    "    # 3. Trade timing within 15-min window\n",
    "    ax3 = axes[1, 0]\n",
    "    if 'seconds_into_window' in df.columns:\n",
    "        # Histogram of when trades occur\n",
    "        ax3.hist(df['seconds_into_window'], bins=30, edgecolor='black', alpha=0.7, range=(0, 900))\n",
    "        ax3.axvline(x=300, color='gray', linestyle='--', alpha=0.5, label='5 min')\n",
    "        ax3.axvline(x=600, color='gray', linestyle='--', alpha=0.5, label='10 min')\n",
    "        ax3.set_title('Trade Timing Within 15-Min Window')\n",
    "        ax3.set_xlabel('Seconds into Window')\n",
    "        ax3.set_ylabel('Number of Trades')\n",
    "        ax3.set_xlim(0, 900)\n",
    "        ax3.legend()\n",
    "    \n",
    "    # 4. Inter-trade time distribution\n",
    "    ax4 = axes[1, 1]\n",
    "    if 'time_since_last_trade' in df.columns:\n",
    "        valid_times = df['time_since_last_trade'].dropna()\n",
    "        valid_times = valid_times[valid_times < 120]  # Focus on <2 min\n",
    "        ax4.hist(valid_times, bins=50, edgecolor='black', alpha=0.7)\n",
    "        ax4.set_title('Time Between Consecutive Trades')\n",
    "        ax4.set_xlabel('Seconds')\n",
    "        ax4.set_ylabel('Frequency')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(CONFIG['output_dir'] + 'trade_analysis.png', dpi=150, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"âœ“ Saved: {CONFIG['output_dir']}trade_analysis.png\")\n",
    "\n",
    "\n",
    "def plot_trade_price_analysis(df):\n",
    "    \"\"\"\n",
    "    Additional trade analysis focusing on prices.\n",
    "    \n",
    "    JUSTIFICATION:\n",
    "    - Price by outcome reveals what prices bot pays for UP vs DOWN\n",
    "    - Trade price over time shows if strategy is consistent\n",
    "    \"\"\"\n",
    "    if df is None:\n",
    "        print(\"No trade data to plot\")\n",
    "        return\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    fig.suptitle('Trade Price Analysis', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # 1. Trade price by action\n",
    "    ax1 = axes[0]\n",
    "    if 'action' in df.columns:\n",
    "        # Box plot of prices by action\n",
    "        actions = df['action'].unique()\n",
    "        data_to_plot = [df[df['action'] == a]['price'].values for a in actions]\n",
    "        bp = ax1.boxplot(data_to_plot, labels=actions, patch_artist=True)\n",
    "        colors = ['#2ecc71', '#e74c3c', '#3498db', '#f39c12'][:len(actions)]\n",
    "        for patch, color in zip(bp['boxes'], colors):\n",
    "            patch.set_facecolor(color)\n",
    "            patch.set_alpha(0.7)\n",
    "        ax1.set_title('Trade Price by Action')\n",
    "        ax1.set_ylabel('Price')\n",
    "        ax1.tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # 2. Trade price over time\n",
    "    ax2 = axes[1]\n",
    "    if 'datetime' in df.columns:\n",
    "        for outcome in df['outcome'].unique():\n",
    "            subset = df[df['outcome'] == outcome]\n",
    "            ax2.scatter(subset['datetime'], subset['price'], \n",
    "                       alpha=0.5, s=20, label=outcome)\n",
    "        ax2.set_title('Trade Prices Over Time')\n",
    "        ax2.set_xlabel('Time')\n",
    "        ax2.set_ylabel('Price')\n",
    "        ax2.legend()\n",
    "        ax2.tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(CONFIG['output_dir'] + 'trade_price_analysis.png', dpi=150, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"âœ“ Saved: {CONFIG['output_dir']}trade_price_analysis.png\")\n",
    "\n",
    "\n",
    "def plot_position_analysis(df):\n",
    "    \"\"\"\n",
    "    Create visualizations for position data.\n",
    "    \n",
    "    JUSTIFICATION:\n",
    "    - PnL distribution shows strategy profitability\n",
    "    - Position size distribution shows risk taking\n",
    "    - PnL by outcome shows which direction is more profitable\n",
    "    \"\"\"\n",
    "    if df is None:\n",
    "        print(\"No position data to plot\")\n",
    "        return\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    fig.suptitle('Position Analysis', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # 1. Cash PnL distribution\n",
    "    ax1 = axes[0, 0]\n",
    "    pnl = df['cash_pnl'].dropna()\n",
    "    ax1.hist(pnl, bins=50, edgecolor='black', alpha=0.7)\n",
    "    ax1.axvline(x=0, color='red', linestyle='--', label='Break-even')\n",
    "    ax1.axvline(x=pnl.mean(), color='green', linestyle='--', label=f'Mean: ${pnl.mean():.2f}')\n",
    "    ax1.set_title('Cash PnL Distribution')\n",
    "    ax1.set_xlabel('PnL ($)')\n",
    "    ax1.set_ylabel('Frequency')\n",
    "    ax1.legend()\n",
    "    \n",
    "    # 2. Percent PnL distribution\n",
    "    ax2 = axes[0, 1]\n",
    "    pct_pnl = df['percent_pnl'].dropna()\n",
    "    ax2.hist(pct_pnl, bins=50, edgecolor='black', alpha=0.7)\n",
    "    ax2.axvline(x=0, color='red', linestyle='--', label='Break-even')\n",
    "    ax2.axvline(x=pct_pnl.mean(), color='green', linestyle='--', label=f'Mean: {pct_pnl.mean():.1f}%')\n",
    "    ax2.set_title('Percent PnL Distribution')\n",
    "    ax2.set_xlabel('PnL (%)')\n",
    "    ax2.set_ylabel('Frequency')\n",
    "    ax2.legend()\n",
    "    \n",
    "    # 3. Position size (shares) by outcome\n",
    "    ax3 = axes[1, 0]\n",
    "    if 'outcome' in df.columns:\n",
    "        for outcome in df['outcome'].unique():\n",
    "            subset = df[df['outcome'] == outcome]\n",
    "            ax3.hist(subset['shares'], bins=30, alpha=0.5, label=outcome, edgecolor='black')\n",
    "        ax3.set_title('Position Size by Outcome')\n",
    "        ax3.set_xlabel('Shares')\n",
    "        ax3.set_ylabel('Frequency')\n",
    "        ax3.legend()\n",
    "    \n",
    "    # 4. PnL by outcome (box plot)\n",
    "    ax4 = axes[1, 1]\n",
    "    if 'outcome' in df.columns:\n",
    "        outcomes = df['outcome'].unique()\n",
    "        data_to_plot = [df[df['outcome'] == o]['cash_pnl'].values for o in outcomes]\n",
    "        bp = ax4.boxplot(data_to_plot, labels=outcomes, patch_artist=True)\n",
    "        colors = ['#3498db', '#e74c3c'][:len(outcomes)]\n",
    "        for patch, color in zip(bp['boxes'], colors):\n",
    "            patch.set_facecolor(color)\n",
    "            patch.set_alpha(0.7)\n",
    "        ax4.axhline(y=0, color='gray', linestyle='--', alpha=0.5)\n",
    "        ax4.set_title('Cash PnL by Outcome')\n",
    "        ax4.set_ylabel('PnL ($)')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(CONFIG['output_dir'] + 'position_analysis.png', dpi=150, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"âœ“ Saved: {CONFIG['output_dir']}position_analysis.png\")\n",
    "\n",
    "\n",
    "def plot_orderbook_analysis(df):\n",
    "    \"\"\"\n",
    "    Create visualizations for orderbook data.\n",
    "    \n",
    "    JUSTIFICATION:\n",
    "    - Spread distributions show trading costs\n",
    "    - Implied probabilities show market pricing\n",
    "    - Probability sum shows market efficiency\n",
    "    \"\"\"\n",
    "    if df is None:\n",
    "        print(\"No orderbook data to plot\")\n",
    "        return\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    fig.suptitle('Orderbook Analysis', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # 1. UP spread distribution\n",
    "    ax1 = axes[0, 0]\n",
    "    ax1.hist(df['up_spread'], bins=50, edgecolor='black', alpha=0.7, label='UP')\n",
    "    ax1.hist(df['down_spread'], bins=50, edgecolor='black', alpha=0.5, label='DOWN')\n",
    "    ax1.set_title('Bid-Ask Spread Distribution')\n",
    "    ax1.set_xlabel('Spread')\n",
    "    ax1.set_ylabel('Frequency')\n",
    "    ax1.legend()\n",
    "    \n",
    "    # 2. Implied probabilities over time\n",
    "    ax2 = axes[0, 1]\n",
    "    if 'up_midpoint' in df.columns and 'datetime' in df.columns:\n",
    "        ax2.plot(df['datetime'], df['up_midpoint'], label='UP implied prob', alpha=0.7)\n",
    "        ax2.plot(df['datetime'], df['down_midpoint'], label='DOWN implied prob', alpha=0.7)\n",
    "        ax2.set_title('Implied Probabilities Over Time')\n",
    "        ax2.set_xlabel('Time')\n",
    "        ax2.set_ylabel('Probability')\n",
    "        ax2.legend()\n",
    "        ax2.tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # 3. Probability sum distribution (efficiency check)\n",
    "    ax3 = axes[1, 0]\n",
    "    if 'prob_sum_mid' in df.columns:\n",
    "        ax3.hist(df['prob_sum_mid'], bins=50, edgecolor='black', alpha=0.7)\n",
    "        ax3.axvline(x=1.0, color='red', linestyle='--', label='Efficient (1.0)')\n",
    "        ax3.set_title('Probability Sum Distribution (UP + DOWN)')\n",
    "        ax3.set_xlabel('Sum of Probabilities')\n",
    "        ax3.set_ylabel('Frequency')\n",
    "        ax3.legend()\n",
    "    \n",
    "    # 4. UP vs DOWN midpoint scatter\n",
    "    ax4 = axes[1, 1]\n",
    "    if 'up_midpoint' in df.columns:\n",
    "        ax4.scatter(df['up_midpoint'], df['down_midpoint'], alpha=0.3, s=10)\n",
    "        ax4.plot([0, 1], [1, 0], 'r--', label='Efficient frontier (sum=1)')\n",
    "        ax4.set_title('UP vs DOWN Implied Probabilities')\n",
    "        ax4.set_xlabel('UP Probability')\n",
    "        ax4.set_ylabel('DOWN Probability')\n",
    "        ax4.set_xlim(0, 1)\n",
    "        ax4.set_ylim(0, 1)\n",
    "        ax4.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(CONFIG['output_dir'] + 'orderbook_analysis.png', dpi=150, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"âœ“ Saved: {CONFIG['output_dir']}orderbook_analysis.png\")\n",
    "\n",
    "\n",
    "def plot_orderbook_depth(df):\n",
    "    \"\"\"\n",
    "    Additional orderbook analysis focusing on depth and liquidity.\n",
    "    \"\"\"\n",
    "    if df is None:\n",
    "        print(\"No orderbook data to plot\")\n",
    "        return\n",
    "    \n",
    "    if 'up_bid_depth_5' not in df.columns:\n",
    "        print(\"No depth data available\")\n",
    "        return\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    fig.suptitle('Orderbook Depth Analysis', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # 1. Depth distribution\n",
    "    ax1 = axes[0]\n",
    "    ax1.hist(df['up_bid_depth_5'], bins=50, alpha=0.5, label='UP Bid Depth', edgecolor='black')\n",
    "    ax1.hist(df['up_ask_depth_5'], bins=50, alpha=0.5, label='UP Ask Depth', edgecolor='black')\n",
    "    ax1.set_title('UP Orderbook Depth Distribution')\n",
    "    ax1.set_xlabel('Depth ($)')\n",
    "    ax1.set_ylabel('Frequency')\n",
    "    ax1.legend()\n",
    "    \n",
    "    # 2. Depth over time\n",
    "    ax2 = axes[1]\n",
    "    if 'datetime' in df.columns:\n",
    "        ax2.plot(df['datetime'], df['up_bid_depth_5'], label='UP Bid', alpha=0.7)\n",
    "        ax2.plot(df['datetime'], df['up_ask_depth_5'], label='UP Ask', alpha=0.7)\n",
    "        ax2.set_title('UP Orderbook Depth Over Time')\n",
    "        ax2.set_xlabel('Time')\n",
    "        ax2.set_ylabel('Depth ($)')\n",
    "        ax2.legend()\n",
    "        ax2.tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(CONFIG['output_dir'] + 'orderbook_depth_analysis.png', dpi=150, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"âœ“ Saved: {CONFIG['output_dir']}orderbook_depth_analysis.png\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"Generate all Phase 1 visualizations\"\"\"\n",
    "    print(\"=\"*60)\n",
    "    print(\" PHASE 1 VISUALIZATIONS\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"\\nOutput directory: {CONFIG['output_dir']}\")\n",
    "    \n",
    "    # Load processed data\n",
    "    print(\"\\nLoading processed data...\")\n",
    "    \n",
    "    try:\n",
    "        btc_df = pd.read_parquet(CONFIG['btc_processed'])\n",
    "        print(f\"  âœ“ BTC data: {len(btc_df):,} rows\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"  âœ— BTC data not found\")\n",
    "        btc_df = None\n",
    "    \n",
    "    try:\n",
    "        trades_df = pd.read_parquet(CONFIG['trades_processed'])\n",
    "        print(f\"  âœ“ Trades data: {len(trades_df):,} rows\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"  âœ— Trades data not found\")\n",
    "        trades_df = None\n",
    "    \n",
    "    try:\n",
    "        positions_df = pd.read_parquet(CONFIG['positions_processed'])\n",
    "        print(f\"  âœ“ Positions data: {len(positions_df):,} rows\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"  âœ— Positions data not found\")\n",
    "        positions_df = None\n",
    "    \n",
    "    try:\n",
    "        orderbook_df = pd.read_parquet(CONFIG['orderbook_processed'])\n",
    "        print(f\"  âœ“ Orderbook data: {len(orderbook_df):,} rows\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"  âœ— Orderbook data not found\")\n",
    "        orderbook_df = None\n",
    "    \n",
    "    # Generate visualizations\n",
    "    print(\"\\nGenerating visualizations...\")\n",
    "    \n",
    "    plot_btc_analysis(btc_df)\n",
    "    plot_trade_analysis(trades_df)\n",
    "    plot_trade_price_analysis(trades_df)\n",
    "    plot_position_analysis(positions_df)\n",
    "    plot_orderbook_analysis(orderbook_df)\n",
    "    plot_orderbook_depth(orderbook_df)\n",
    "    \n",
    "    print(f\"\\nâœ“ All visualizations saved to: {CONFIG['output_dir']}\")\n",
    "    print(\"\\nGenerated files:\")\n",
    "    for f in os.listdir(CONFIG['output_dir']):\n",
    "        if f.endswith('.png'):\n",
    "            print(f\"  - {f}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a4aaddb5-124b-4167-93fe-6afbbb3cec05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      " POLYMARKET BOT STRATEGY ANALYSIS - PHASE 2\n",
      " Merged Analysis & Strategy Identification\n",
      "================================================================================\n",
      "\n",
      "Started at: 2025-12-22 22:06:55.961763\n",
      "\n",
      "Loading Phase 1 processed data...\n",
      "  âœ“ BTC: 1,782 rows\n",
      "  âœ“ Trades: 1,121 rows\n",
      "  âœ“ Positions: 6,447 rows\n",
      "  âœ“ Orderbook: 14,059 rows\n",
      "\n",
      "================================================================================\n",
      " 2A. TRADES + BTC PRICES ANALYSIS\n",
      "================================================================================\n",
      "Trades: 1,121 rows\n",
      "BTC prices: 1,782 rows\n",
      "\n",
      "Merging on timestamp (backward asof merge)...\n",
      "\n",
      "Merged dataset: 1,121 rows\n",
      "Average BTC data lag: 0.60 seconds\n",
      "\n",
      "--- BTC Returns Before Each Action Type ---\n",
      "\n",
      "btc_return_5s:\n",
      "              mean       std    median  mean_pct\n",
      "action                                          \n",
      "BUY_Down -0.000083  0.000320 -0.000064 -0.008296\n",
      "BUY_Up    0.000049  0.000282  0.000030  0.004856\n",
      "\n",
      "btc_return_15s:\n",
      "              mean       std    median  mean_pct\n",
      "action                                          \n",
      "BUY_Down -0.000134  0.000563 -0.000065 -0.013418\n",
      "BUY_Up   -0.000044  0.000537 -0.000019 -0.004392\n",
      "\n",
      "btc_return_30s:\n",
      "              mean       std    median  mean_pct\n",
      "action                                          \n",
      "BUY_Down -0.000188  0.000787 -0.000084 -0.018813\n",
      "BUY_Up   -0.000187  0.000874 -0.000123 -0.018669\n",
      "\n",
      "btc_return_60s:\n",
      "              mean       std    median  mean_pct\n",
      "action                                          \n",
      "BUY_Down  0.000022  0.001295  0.000034  0.002225\n",
      "BUY_Up   -0.000144  0.001430 -0.000117 -0.014356\n",
      "\n",
      "--- KEY INSIGHT: Does BTC direction predict trade direction? ---\n",
      "\n",
      "5s window:\n",
      "  When BTCâ†‘: BUY UP = 59.4%, BUY DOWN = 40.6%\n",
      "  When BTCâ†“: BUY UP = 42.9%, BUY DOWN = 57.1%\n",
      "\n",
      "15s window:\n",
      "  When BTCâ†‘: BUY UP = 56.3%, BUY DOWN = 43.7%\n",
      "  When BTCâ†“: BUY UP = 46.9%, BUY DOWN = 53.1%\n",
      "\n",
      "30s window:\n",
      "  When BTCâ†‘: BUY UP = 49.8%, BUY DOWN = 50.2%\n",
      "  When BTCâ†“: BUY UP = 52.0%, BUY DOWN = 48.0%\n",
      "\n",
      "60s window:\n",
      "  When BTCâ†‘: BUY UP = 49.8%, BUY DOWN = 50.2%\n",
      "  When BTCâ†“: BUY UP = 52.2%, BUY DOWN = 47.8%\n",
      "\n",
      "âœ“ Saved: analysis_output/phase2/trades_with_btc.parquet\n",
      "\n",
      "================================================================================\n",
      " 2B. TRADES + ORDERBOOK ANALYSIS\n",
      "================================================================================\n",
      "Trades: 1,121 rows\n",
      "Orderbook snapshots: 14,059 rows\n",
      "\n",
      "Merging on timestamp...\n",
      "\n",
      "Merged dataset: 1,121 rows\n",
      "Average orderbook data lag: 0.05 seconds\n",
      "\n",
      "--- Execution Quality Analysis ---\n",
      "\n",
      "Up outcome trades:\n",
      "  BUY trades: 572\n",
      "    Avg trade price: 0.4755\n",
      "    Avg best ask: 0.9900\n",
      "    Avg spread paid: -0.5145\n",
      "\n",
      "Down outcome trades:\n",
      "  BUY trades: 549\n",
      "    Avg trade price: 0.4616\n",
      "    Avg best ask: 0.9900\n",
      "    Avg spread paid: -0.5284\n",
      "\n",
      "--- Spread Conditions at Trade Time ---\n",
      "UP spread at trade time:\n",
      "  Mean: 0.9800\n",
      "  Median: 0.9800\n",
      "\n",
      "DOWN spread at trade time:\n",
      "  Mean: 0.9800\n",
      "  Median: 0.9800\n",
      "\n",
      "--- Implied Probabilities at Trade Time ---\n",
      "UP implied probability when trading UP:\n",
      "  Mean: 0.5000 (50.0%)\n",
      "\n",
      "DOWN implied probability when trading DOWN:\n",
      "  Mean: 0.5000 (50.0%)\n",
      "\n",
      "âœ“ Saved: analysis_output/phase2/trades_with_orderbook.parquet\n",
      "\n",
      "================================================================================\n",
      " 2C. FULL STATE RECONSTRUCTION\n",
      "================================================================================\n",
      "Starting with 1,121 trades\n",
      "  âœ“ Added BTC state\n",
      "  âœ“ Added orderbook state\n",
      "  âš  Position merge may need custom handling based on your data format\n",
      "\n",
      "--- Feature Engineering ---\n",
      "  âœ“ Added spread features\n",
      "  âœ“ Added probability features\n",
      "\n",
      "Final dataset: 1,121 rows, 46 columns\n",
      "\n",
      "Columns: ['timestamp', 'unix_timestamp', 'slug', 'market_title', 'side', 'price', 'size', 'value', 'outcome', 'condition_id', 'transaction_hash', 'outcome_index', 'datetime', 'time_since_last_trade', 'action', 'prev_action', 'action_sequence', 'btc_datetime', 'btc_price', 'return_1tick', 'return_abs', 'return_1s', 'return_5s', 'return_15s', 'return_30s', 'return_60s', 'return_300s', 'rolling_vol_60s', 'ob_datetime', 'up_best_bid', 'up_best_ask', 'up_spread', 'down_best_bid', 'down_best_ask', 'down_spread', 'up_midpoint', 'down_midpoint', 'prob_sum_mid', 'up_bid_depth_5', 'up_ask_depth_5', 'total_spread', 'spread_ratio', 'up_implied_deviation', 'market_inefficiency', 'is_buy', 'is_up']\n",
      "\n",
      "âœ“ Saved: analysis_output/phase2/full_state_reconstruction.parquet\n",
      "\n",
      "================================================================================\n",
      " 2D. STRATEGY IDENTIFICATION (Decision Trees)\n",
      "================================================================================\n",
      "Using features: ['up_spread', 'down_spread', 'total_spread', 'spread_ratio', 'up_midpoint', 'down_midpoint', 'up_implied_deviation', 'market_inefficiency']\n",
      "\n",
      "Valid samples for modeling: 1,121\n",
      "\n",
      "--- Model 1: Predicting BUY vs SELL ---\n",
      "Accuracy: 100.00%\n",
      "\n",
      "Feature Importances:\n",
      "\n",
      "Decision Rules:\n",
      "|--- class: 0\n",
      "\n",
      "\n",
      "--- Model 2: Predicting UP vs DOWN Outcome ---\n",
      "Accuracy: 51.03%\n",
      "\n",
      "Feature Importances:\n",
      "\n",
      "Decision Rules:\n",
      "|--- class: 1\n",
      "\n",
      "\n",
      "--- Model 3: Predicting Full Action ---\n",
      "Accuracy: 51.03%\n",
      "Classes: ['BUY_Down' 'BUY_Up']\n",
      "\n",
      "Feature Importances:\n",
      "\n",
      "Decision Rules:\n",
      "|--- class: BUY_Up\n",
      "\n",
      "\n",
      "âœ“ Saved decision tree visualization\n",
      "\n",
      "================================================================================\n",
      " 2E. THRESHOLD DETECTION\n",
      "================================================================================\n",
      "\n",
      "--- Feature Distributions by Action ---\n",
      "\n",
      "up_spread:\n",
      "          mean  median  std\n",
      "action                     \n",
      "BUY_Down  0.98    0.98  0.0\n",
      "BUY_Up    0.98    0.98  0.0\n",
      "\n",
      "down_spread:\n",
      "          mean  median  std\n",
      "action                     \n",
      "BUY_Down  0.98    0.98  0.0\n",
      "BUY_Up    0.98    0.98  0.0\n",
      "\n",
      "--- Hypothesis Tests ---\n",
      "\n",
      "H3: Bot trades only when spread < threshold\n",
      "  UP spread percentiles: 25%=0.9800, 50%=0.9800, 75%=0.9800\n",
      "\n",
      "================================================================================\n",
      " 2F. EVENT STUDY (Price Action Around Trades)\n",
      "================================================================================\n",
      "Analyzing price action from -60s to +60s around trades\n",
      "  BUY_Down: 549 valid trade windows\n",
      "  BUY_Up: 572 valid trade windows\n",
      "\n",
      "âœ“ Saved: analysis_output/phase2/event_study.png\n",
      "\n",
      "================================================================================\n",
      " PHASE 2 SUMMARY: STRATEGY HYPOTHESIS\n",
      "================================================================================\n",
      "\n",
      "ðŸ“Š STRATEGY INDICATORS\n",
      "----------------------------------------\n",
      "\n",
      "3. SIZING LOGIC:\n",
      "   Size CV (std/mean): 0.66\n",
      "   â†’ VARIABLE SIZING: Adaptive position sizing\n",
      "\n",
      "========================================\n",
      "PRELIMINARY STRATEGY DESCRIPTION:\n",
      "========================================\n",
      "\n",
      "[Fill this in based on the analysis results above]\n",
      "\n",
      "The bot appears to:\n",
      "- Entry trigger: [momentum / mean-reversion / spread-based]\n",
      "- Exit trigger: [time-based / profit-target / price-based]\n",
      "- Position sizing: [fixed / scaled]\n",
      "- Timing: [early / mid / late window]\n",
      "\n",
      "âœ“ Phase 2 analysis complete at: 2025-12-22 22:06:57.358453\n",
      "âœ“ Output saved to: analysis_output/phase2/\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "================================================================================\n",
    "PHASE 2: MERGED ANALYSIS & STRATEGY IDENTIFICATION\n",
    "================================================================================\n",
    "This script merges all 4 datasets to reconstruct the bot's decision-making\n",
    "environment at each trade, then uses various techniques to identify the strategy.\n",
    "\n",
    "JUSTIFICATION FOR PHASE 2:\n",
    "Phase 1 showed us patterns in individual datasets. Now we need to understand\n",
    "HOW these datasets relate to each other:\n",
    "- What was BTC doing when the bot traded?\n",
    "- What were the orderbook conditions?\n",
    "- What was the bot's existing position?\n",
    "\n",
    "By merging on timestamp, we reconstruct the EXACT market state at each decision.\n",
    "\n",
    "Author: Strategy Analysis Pipeline\n",
    "Date: December 2024\n",
    "================================================================================\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# For visualization\n",
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    PLOTTING_AVAILABLE = True\n",
    "except ImportError:\n",
    "    PLOTTING_AVAILABLE = False\n",
    "\n",
    "# For decision tree analysis\n",
    "try:\n",
    "    from sklearn.tree import DecisionTreeClassifier, plot_tree, export_text\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    SKLEARN_AVAILABLE = True\n",
    "except ImportError:\n",
    "    SKLEARN_AVAILABLE = False\n",
    "    print(\"sklearn not available - decision tree analysis will be skipped\")\n",
    "\n",
    "import os\n",
    "\n",
    "# ============================================================================\n",
    "# CONFIGURATION\n",
    "# ============================================================================\n",
    "\n",
    "CONFIG = {\n",
    "    # Input: processed files from Phase 1\n",
    "    'btc_processed': 'analysis_output/btc_prices_processed.parquet',\n",
    "    'trades_processed': 'analysis_output/trades_processed.parquet',\n",
    "    'positions_processed': 'analysis_output/positions_processed.parquet',\n",
    "    'orderbook_processed': 'analysis_output/orderbook_processed.parquet',\n",
    "    \n",
    "    # Output\n",
    "    'output_dir': 'analysis_output/phase2/',\n",
    "}\n",
    "\n",
    "os.makedirs(CONFIG['output_dir'], exist_ok=True)\n",
    "\n",
    "\n",
    "def print_section(title):\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\" {title}\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "def print_subsection(title):\n",
    "    print(f\"\\n--- {title} ---\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# 2A. MERGE TRADES WITH BTC PRICES\n",
    "# ============================================================================\n",
    "\n",
    "def merge_trades_with_btc(trades_df, btc_df):\n",
    "    \"\"\"\n",
    "    Merge trades with BTC prices to understand what triggered each trade.\n",
    "    \n",
    "    JUSTIFICATION:\n",
    "    This is THE KEY ANALYSIS. By knowing the BTC price behavior at each trade,\n",
    "    we can answer:\n",
    "    - Does the bot trade after momentum (BTC going up â†’ BUY UP)?\n",
    "    - Does the bot trade mean-reversion (BTC going up â†’ BUY DOWN)?\n",
    "    - What time window of returns matters (1s? 5s? 30s? 60s)?\n",
    "    \n",
    "    Uses merge_asof with direction='backward' to get the MOST RECENT BTC price\n",
    "    before each trade (the information the bot would have had).\n",
    "    \"\"\"\n",
    "    print_section(\"2A. TRADES + BTC PRICES ANALYSIS\")\n",
    "    \n",
    "    if trades_df is None or btc_df is None:\n",
    "        print(\"Missing required data\")\n",
    "        return None\n",
    "    \n",
    "    # Ensure both are sorted by datetime\n",
    "    trades_sorted = trades_df.sort_values('datetime').copy()\n",
    "    btc_sorted = btc_df.sort_values('datetime').copy()\n",
    "    \n",
    "    print(f\"Trades: {len(trades_sorted):,} rows\")\n",
    "    print(f\"BTC prices: {len(btc_sorted):,} rows\")\n",
    "    \n",
    "    # Merge: for each trade, get the most recent BTC price\n",
    "    print(\"\\nMerging on timestamp (backward asof merge)...\")\n",
    "    \n",
    "    merged = pd.merge_asof(\n",
    "        trades_sorted,\n",
    "        btc_sorted[['datetime', 'price', 'return_1tick', 'return_5s', 'return_15s', \n",
    "                   'return_30s', 'return_60s', 'rolling_vol_60s']].rename(\n",
    "            columns={\n",
    "                'datetime': 'btc_datetime',\n",
    "                'price': 'btc_price',\n",
    "                'return_1tick': 'btc_return_1tick',\n",
    "                'return_5s': 'btc_return_5s',\n",
    "                'return_15s': 'btc_return_15s',\n",
    "                'return_30s': 'btc_return_30s',\n",
    "                'return_60s': 'btc_return_60s',\n",
    "                'rolling_vol_60s': 'btc_vol_60s'\n",
    "            }\n",
    "        ),\n",
    "        left_on='datetime',\n",
    "        right_on='btc_datetime',\n",
    "        direction='backward'\n",
    "    )\n",
    "    \n",
    "    # Calculate time lag between BTC price and trade\n",
    "    merged['btc_lag_seconds'] = (merged['datetime'] - merged['btc_datetime']).dt.total_seconds()\n",
    "    \n",
    "    print(f\"\\nMerged dataset: {len(merged):,} rows\")\n",
    "    print(f\"Average BTC data lag: {merged['btc_lag_seconds'].mean():.2f} seconds\")\n",
    "    \n",
    "    # ANALYSIS: What BTC returns precede each action?\n",
    "    print_subsection(\"BTC Returns Before Each Action Type\")\n",
    "    \n",
    "    for return_col in ['btc_return_5s', 'btc_return_15s', 'btc_return_30s', 'btc_return_60s']:\n",
    "        print(f\"\\n{return_col}:\")\n",
    "        stats = merged.groupby('action')[return_col].agg(['mean', 'std', 'median'])\n",
    "        stats['mean_pct'] = stats['mean'] * 100\n",
    "        print(stats.round(6))\n",
    "    \n",
    "    # KEY INSIGHT: Direction correlation\n",
    "    print_subsection(\"KEY INSIGHT: Does BTC direction predict trade direction?\")\n",
    "    \n",
    "    # For each return window, check if positive returns â†’ BUY UP (momentum)\n",
    "    # or positive returns â†’ BUY DOWN (mean reversion)\n",
    "    \n",
    "    for window in ['5s', '15s', '30s', '60s']:\n",
    "        col = f'btc_return_{window}'\n",
    "        \n",
    "        # When BTC is going UP (positive return)\n",
    "        btc_up = merged[merged[col] > 0]\n",
    "        btc_down = merged[merged[col] < 0]\n",
    "        \n",
    "        if len(btc_up) > 0:\n",
    "            buy_up_when_btc_up = (btc_up['action'] == 'BUY_Up').sum() / len(btc_up)\n",
    "            buy_down_when_btc_up = (btc_up['action'] == 'BUY_Down').sum() / len(btc_up)\n",
    "            \n",
    "            print(f\"\\n{window} window:\")\n",
    "            print(f\"  When BTCâ†‘: BUY UP = {buy_up_when_btc_up*100:.1f}%, BUY DOWN = {buy_down_when_btc_up*100:.1f}%\")\n",
    "        \n",
    "        if len(btc_down) > 0:\n",
    "            buy_up_when_btc_down = (btc_down['action'] == 'BUY_Up').sum() / len(btc_down)\n",
    "            buy_down_when_btc_down = (btc_down['action'] == 'BUY_Down').sum() / len(btc_down)\n",
    "            \n",
    "            print(f\"  When BTCâ†“: BUY UP = {buy_up_when_btc_down*100:.1f}%, BUY DOWN = {buy_down_when_btc_down*100:.1f}%\")\n",
    "    \n",
    "    # Save merged data\n",
    "    output_path = CONFIG['output_dir'] + 'trades_with_btc.parquet'\n",
    "    merged.to_parquet(output_path)\n",
    "    print(f\"\\nâœ“ Saved: {output_path}\")\n",
    "    \n",
    "    return merged\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# 2B. MERGE TRADES WITH ORDERBOOK\n",
    "# ============================================================================\n",
    "\n",
    "def merge_trades_with_orderbook(trades_df, orderbook_df):\n",
    "    \"\"\"\n",
    "    Merge trades with orderbook to understand execution context.\n",
    "    \n",
    "    JUSTIFICATION:\n",
    "    The orderbook tells us:\n",
    "    - What spread was the bot paying?\n",
    "    - Was it taking liquidity or providing it?\n",
    "    - What were the implied probabilities when it traded?\n",
    "    - Was there any edge visible in the orderbook?\n",
    "    \"\"\"\n",
    "    print_section(\"2B. TRADES + ORDERBOOK ANALYSIS\")\n",
    "    \n",
    "    if trades_df is None or orderbook_df is None:\n",
    "        print(\"Missing required data\")\n",
    "        return None\n",
    "    \n",
    "    trades_sorted = trades_df.sort_values('datetime').copy()\n",
    "    orderbook_sorted = orderbook_df.sort_values('datetime').copy()\n",
    "    \n",
    "    print(f\"Trades: {len(trades_sorted):,} rows\")\n",
    "    print(f\"Orderbook snapshots: {len(orderbook_sorted):,} rows\")\n",
    "    \n",
    "    # Merge\n",
    "    print(\"\\nMerging on timestamp...\")\n",
    "    \n",
    "    merged = pd.merge_asof(\n",
    "        trades_sorted,\n",
    "        orderbook_sorted[[\n",
    "            'datetime', 'up_best_bid', 'up_best_ask', 'up_spread',\n",
    "            'down_best_bid', 'down_best_ask', 'down_spread',\n",
    "            'up_midpoint', 'down_midpoint', 'prob_sum_mid'\n",
    "        ]].rename(columns={'datetime': 'ob_datetime'}),\n",
    "        left_on='datetime',\n",
    "        right_on='ob_datetime',\n",
    "        direction='backward'\n",
    "    )\n",
    "    \n",
    "    merged['ob_lag_seconds'] = (merged['datetime'] - merged['ob_datetime']).dt.total_seconds()\n",
    "    \n",
    "    print(f\"\\nMerged dataset: {len(merged):,} rows\")\n",
    "    print(f\"Average orderbook data lag: {merged['ob_lag_seconds'].mean():.2f} seconds\")\n",
    "    \n",
    "    # ANALYSIS: Execution quality\n",
    "    print_subsection(\"Execution Quality Analysis\")\n",
    "    \n",
    "    # Compare trade price to best bid/ask\n",
    "    # If buying: trade_price vs best_ask (should be <= ask)\n",
    "    # If selling: trade_price vs best_bid (should be >= bid)\n",
    "    \n",
    "    for outcome in ['Up', 'Down']:\n",
    "        print(f\"\\n{outcome} outcome trades:\")\n",
    "        outcome_trades = merged[merged['outcome'] == outcome]\n",
    "        \n",
    "        bid_col = f'{outcome.lower()}_best_bid'\n",
    "        ask_col = f'{outcome.lower()}_best_ask'\n",
    "        \n",
    "        buys = outcome_trades[outcome_trades['side'] == 'BUY']\n",
    "        sells = outcome_trades[outcome_trades['side'] == 'SELL']\n",
    "        \n",
    "        if len(buys) > 0:\n",
    "            # For buys, compare trade price to ask\n",
    "            buys['spread_paid'] = buys['price'] - buys[ask_col]\n",
    "            print(f\"  BUY trades: {len(buys)}\")\n",
    "            print(f\"    Avg trade price: {buys['price'].mean():.4f}\")\n",
    "            print(f\"    Avg best ask: {buys[ask_col].mean():.4f}\")\n",
    "            print(f\"    Avg spread paid: {buys['spread_paid'].mean():.4f}\")\n",
    "        \n",
    "        if len(sells) > 0:\n",
    "            # For sells, compare trade price to bid\n",
    "            sells['spread_received'] = sells[bid_col] - sells['price']\n",
    "            print(f\"  SELL trades: {len(sells)}\")\n",
    "            print(f\"    Avg trade price: {sells['price'].mean():.4f}\")\n",
    "            print(f\"    Avg best bid: {sells[bid_col].mean():.4f}\")\n",
    "            print(f\"    Avg spread received: {sells['spread_received'].mean():.4f}\")\n",
    "    \n",
    "    # ANALYSIS: What spreads exist when bot trades?\n",
    "    print_subsection(\"Spread Conditions at Trade Time\")\n",
    "    \n",
    "    print(f\"UP spread at trade time:\")\n",
    "    print(f\"  Mean: {merged['up_spread'].mean():.4f}\")\n",
    "    print(f\"  Median: {merged['up_spread'].median():.4f}\")\n",
    "    \n",
    "    print(f\"\\nDOWN spread at trade time:\")\n",
    "    print(f\"  Mean: {merged['down_spread'].mean():.4f}\")\n",
    "    print(f\"  Median: {merged['down_spread'].median():.4f}\")\n",
    "    \n",
    "    # ANALYSIS: Implied probabilities when trading\n",
    "    print_subsection(\"Implied Probabilities at Trade Time\")\n",
    "    \n",
    "    print(f\"UP implied probability when trading UP:\")\n",
    "    up_trades = merged[merged['outcome'] == 'Up']\n",
    "    if len(up_trades) > 0:\n",
    "        print(f\"  Mean: {up_trades['up_midpoint'].mean():.4f} ({up_trades['up_midpoint'].mean()*100:.1f}%)\")\n",
    "    \n",
    "    print(f\"\\nDOWN implied probability when trading DOWN:\")\n",
    "    down_trades = merged[merged['outcome'] == 'Down']\n",
    "    if len(down_trades) > 0:\n",
    "        print(f\"  Mean: {down_trades['down_midpoint'].mean():.4f} ({down_trades['down_midpoint'].mean()*100:.1f}%)\")\n",
    "    \n",
    "    # Save\n",
    "    output_path = CONFIG['output_dir'] + 'trades_with_orderbook.parquet'\n",
    "    merged.to_parquet(output_path)\n",
    "    print(f\"\\nâœ“ Saved: {output_path}\")\n",
    "    \n",
    "    return merged\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# 2C. FULL STATE RECONSTRUCTION\n",
    "# ============================================================================\n",
    "\n",
    "def create_full_state_dataframe(trades_df, btc_df, orderbook_df, positions_df):\n",
    "    \"\"\"\n",
    "    Create a comprehensive dataframe with EVERYTHING at each trade.\n",
    "    \n",
    "    JUSTIFICATION:\n",
    "    This is the ultimate dataset for strategy identification.\n",
    "    Each row = one trade, with columns for:\n",
    "    - Trade details (side, price, size, outcome)\n",
    "    - BTC state (price, returns at various windows, volatility)\n",
    "    - Orderbook state (spreads, depths, implied probs)\n",
    "    - Position state (current exposure, unrealized PnL)\n",
    "    \n",
    "    This lets us ask: \"Given ALL this information, what did the bot do?\"\n",
    "    \"\"\"\n",
    "    print_section(\"2C. FULL STATE RECONSTRUCTION\")\n",
    "    \n",
    "    if trades_df is None:\n",
    "        print(\"No trades data - cannot proceed\")\n",
    "        return None\n",
    "    \n",
    "    # Start with trades\n",
    "    df = trades_df.sort_values('datetime').copy()\n",
    "    print(f\"Starting with {len(df):,} trades\")\n",
    "    \n",
    "    # Add BTC state\n",
    "    if btc_df is not None:\n",
    "        btc_sorted = btc_df.sort_values('datetime').copy()\n",
    "        \n",
    "        btc_cols = ['datetime', 'price']\n",
    "        # Add return columns if they exist\n",
    "        for col in btc_df.columns:\n",
    "            if 'return' in col or 'vol' in col:\n",
    "                btc_cols.append(col)\n",
    "        \n",
    "        btc_subset = btc_sorted[btc_cols].rename(columns={'datetime': 'btc_datetime', 'price': 'btc_price'})\n",
    "        \n",
    "        df = pd.merge_asof(\n",
    "            df, btc_subset,\n",
    "            left_on='datetime', right_on='btc_datetime',\n",
    "            direction='backward'\n",
    "        )\n",
    "        print(f\"  âœ“ Added BTC state\")\n",
    "    \n",
    "    # Add orderbook state\n",
    "    if orderbook_df is not None:\n",
    "        ob_sorted = orderbook_df.sort_values('datetime').copy()\n",
    "        \n",
    "        ob_cols = ['datetime', 'up_best_bid', 'up_best_ask', 'up_spread',\n",
    "                  'down_best_bid', 'down_best_ask', 'down_spread']\n",
    "        if 'up_midpoint' in ob_sorted.columns:\n",
    "            ob_cols.extend(['up_midpoint', 'down_midpoint', 'prob_sum_mid'])\n",
    "        if 'up_bid_depth_5' in ob_sorted.columns:\n",
    "            ob_cols.extend(['up_bid_depth_5', 'up_ask_depth_5'])\n",
    "        \n",
    "        ob_subset = ob_sorted[ob_cols].rename(columns={'datetime': 'ob_datetime'})\n",
    "        \n",
    "        df = pd.merge_asof(\n",
    "            df, ob_subset,\n",
    "            left_on='datetime', right_on='ob_datetime',\n",
    "            direction='backward'\n",
    "        )\n",
    "        print(f\"  âœ“ Added orderbook state\")\n",
    "    \n",
    "    # Add position state (this is trickier - need most recent position snapshot)\n",
    "    if positions_df is not None:\n",
    "        # Positions might not have a simple datetime - need to handle this\n",
    "        # For now, we'll skip if timestamps don't align well\n",
    "        print(f\"  âš  Position merge may need custom handling based on your data format\")\n",
    "    \n",
    "    # Feature engineering\n",
    "    print_subsection(\"Feature Engineering\")\n",
    "    \n",
    "    # BTC momentum indicators\n",
    "    if 'btc_return_30s' in df.columns:\n",
    "        df['btc_momentum'] = np.sign(df['btc_return_30s'])\n",
    "        print(\"  âœ“ Added btc_momentum (sign of 30s return)\")\n",
    "    \n",
    "    # Orderbook features\n",
    "    if 'up_spread' in df.columns and 'down_spread' in df.columns:\n",
    "        df['total_spread'] = df['up_spread'] + df['down_spread']\n",
    "        df['spread_ratio'] = df['up_spread'] / df['down_spread'].replace(0, np.nan)\n",
    "        print(\"  âœ“ Added spread features\")\n",
    "    \n",
    "    if 'up_midpoint' in df.columns and 'down_midpoint' in df.columns:\n",
    "        # Deviation from 50/50\n",
    "        df['up_implied_deviation'] = df['up_midpoint'] - 0.5\n",
    "        df['market_inefficiency'] = abs(df['prob_sum_mid'] - 1.0)\n",
    "        print(\"  âœ“ Added probability features\")\n",
    "    \n",
    "    # Time features\n",
    "    if 'seconds_into_window' in df.columns:\n",
    "        df['window_pct'] = df['seconds_into_window'] / 900  # 900 seconds = 15 min\n",
    "        print(\"  âœ“ Added window timing features\")\n",
    "    \n",
    "    # Create binary target for prediction\n",
    "    df['is_buy'] = (df['side'] == 'BUY').astype(int)\n",
    "    df['is_up'] = (df['outcome'] == 'Up').astype(int)\n",
    "    \n",
    "    print(f\"\\nFinal dataset: {len(df):,} rows, {len(df.columns)} columns\")\n",
    "    print(f\"\\nColumns: {list(df.columns)}\")\n",
    "    \n",
    "    # Save\n",
    "    output_path = CONFIG['output_dir'] + 'full_state_reconstruction.parquet'\n",
    "    df.to_parquet(output_path)\n",
    "    print(f\"\\nâœ“ Saved: {output_path}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# 2D. STRATEGY IDENTIFICATION\n",
    "# ============================================================================\n",
    "\n",
    "def identify_strategy_with_decision_tree(df):\n",
    "    \"\"\"\n",
    "    Use decision trees to extract interpretable rules.\n",
    "    \n",
    "    JUSTIFICATION:\n",
    "    Decision trees are perfect for reverse-engineering because:\n",
    "    - They produce human-readable rules\n",
    "    - They automatically find important thresholds\n",
    "    - They reveal which features matter most\n",
    "    \n",
    "    We train separate trees for:\n",
    "    1. Predicting BUY vs SELL\n",
    "    2. Predicting UP vs DOWN\n",
    "    3. Predicting the full action (BUY_UP, SELL_UP, etc.)\n",
    "    \"\"\"\n",
    "    print_section(\"2D. STRATEGY IDENTIFICATION (Decision Trees)\")\n",
    "    \n",
    "    if not SKLEARN_AVAILABLE:\n",
    "        print(\"sklearn not available - skipping decision tree analysis\")\n",
    "        return None\n",
    "    \n",
    "    if df is None:\n",
    "        print(\"No data available\")\n",
    "        return None\n",
    "    \n",
    "    # Select features for the model\n",
    "    potential_features = [\n",
    "        # BTC features\n",
    "        'btc_return_5s', 'btc_return_15s', 'btc_return_30s', 'btc_return_60s',\n",
    "        'btc_momentum',\n",
    "        # Orderbook features\n",
    "        'up_spread', 'down_spread', 'total_spread', 'spread_ratio',\n",
    "        'up_midpoint', 'down_midpoint', 'up_implied_deviation', 'market_inefficiency',\n",
    "        # Timing features\n",
    "        'seconds_into_window', 'window_pct'\n",
    "    ]\n",
    "    \n",
    "    # Filter to features that exist\n",
    "    features = [f for f in potential_features if f in df.columns]\n",
    "    print(f\"Using features: {features}\")\n",
    "    \n",
    "    if len(features) < 2:\n",
    "        print(\"Not enough features for decision tree analysis\")\n",
    "        return None\n",
    "    \n",
    "    # Prepare data\n",
    "    X = df[features].copy()\n",
    "    \n",
    "    # Handle missing values\n",
    "    X = X.fillna(X.median())\n",
    "    \n",
    "    # Drop rows where we still have issues\n",
    "    valid_mask = ~X.isnull().any(axis=1)\n",
    "    X = X[valid_mask]\n",
    "    df_valid = df[valid_mask]\n",
    "    \n",
    "    print(f\"\\nValid samples for modeling: {len(X):,}\")\n",
    "    \n",
    "    # =====================\n",
    "    # MODEL 1: Predict BUY vs SELL\n",
    "    # =====================\n",
    "    print_subsection(\"Model 1: Predicting BUY vs SELL\")\n",
    "    \n",
    "    y_side = df_valid['is_buy']\n",
    "    \n",
    "    tree_side = DecisionTreeClassifier(max_depth=4, min_samples_leaf=10, random_state=42)\n",
    "    tree_side.fit(X, y_side)\n",
    "    \n",
    "    print(f\"Accuracy: {tree_side.score(X, y_side):.2%}\")\n",
    "    print(f\"\\nFeature Importances:\")\n",
    "    for feat, imp in sorted(zip(features, tree_side.feature_importances_), key=lambda x: -x[1]):\n",
    "        if imp > 0.01:\n",
    "            print(f\"  {feat}: {imp:.3f}\")\n",
    "    \n",
    "    print(f\"\\nDecision Rules:\")\n",
    "    print(export_text(tree_side, feature_names=features, max_depth=3))\n",
    "    \n",
    "    # =====================\n",
    "    # MODEL 2: Predict UP vs DOWN outcome\n",
    "    # =====================\n",
    "    print_subsection(\"Model 2: Predicting UP vs DOWN Outcome\")\n",
    "    \n",
    "    y_outcome = df_valid['is_up']\n",
    "    \n",
    "    tree_outcome = DecisionTreeClassifier(max_depth=4, min_samples_leaf=10, random_state=42)\n",
    "    tree_outcome.fit(X, y_outcome)\n",
    "    \n",
    "    print(f\"Accuracy: {tree_outcome.score(X, y_outcome):.2%}\")\n",
    "    print(f\"\\nFeature Importances:\")\n",
    "    for feat, imp in sorted(zip(features, tree_outcome.feature_importances_), key=lambda x: -x[1]):\n",
    "        if imp > 0.01:\n",
    "            print(f\"  {feat}: {imp:.3f}\")\n",
    "    \n",
    "    print(f\"\\nDecision Rules:\")\n",
    "    print(export_text(tree_outcome, feature_names=features, max_depth=3))\n",
    "    \n",
    "    # =====================\n",
    "    # MODEL 3: Predict Full Action\n",
    "    # =====================\n",
    "    print_subsection(\"Model 3: Predicting Full Action\")\n",
    "    \n",
    "    if 'action' in df_valid.columns:\n",
    "        le = LabelEncoder()\n",
    "        y_action = le.fit_transform(df_valid['action'])\n",
    "        \n",
    "        tree_action = DecisionTreeClassifier(max_depth=5, min_samples_leaf=5, random_state=42)\n",
    "        tree_action.fit(X, y_action)\n",
    "        \n",
    "        print(f\"Accuracy: {tree_action.score(X, y_action):.2%}\")\n",
    "        print(f\"Classes: {le.classes_}\")\n",
    "        print(f\"\\nFeature Importances:\")\n",
    "        for feat, imp in sorted(zip(features, tree_action.feature_importances_), key=lambda x: -x[1]):\n",
    "            if imp > 0.01:\n",
    "                print(f\"  {feat}: {imp:.3f}\")\n",
    "        \n",
    "        print(f\"\\nDecision Rules:\")\n",
    "        print(export_text(tree_action, feature_names=features, \n",
    "                         class_names=list(le.classes_), max_depth=3))\n",
    "    \n",
    "    # Save visualization if matplotlib available\n",
    "    if PLOTTING_AVAILABLE:\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(20, 8))\n",
    "        \n",
    "        plot_tree(tree_side, feature_names=features, class_names=['SELL', 'BUY'],\n",
    "                 filled=True, ax=axes[0], max_depth=3, fontsize=8)\n",
    "        axes[0].set_title('Decision Tree: BUY vs SELL')\n",
    "        \n",
    "        plot_tree(tree_outcome, feature_names=features, class_names=['DOWN', 'UP'],\n",
    "                 filled=True, ax=axes[1], max_depth=3, fontsize=8)\n",
    "        axes[1].set_title('Decision Tree: UP vs DOWN Outcome')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(CONFIG['output_dir'] + 'decision_trees.png', dpi=150, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        print(f\"\\nâœ“ Saved decision tree visualization\")\n",
    "    \n",
    "    return {\n",
    "        'tree_side': tree_side,\n",
    "        'tree_outcome': tree_outcome,\n",
    "        'features': features\n",
    "    }\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# 2E. THRESHOLD DETECTION\n",
    "# ============================================================================\n",
    "\n",
    "def detect_thresholds(df):\n",
    "    \"\"\"\n",
    "    Find specific thresholds that trigger trading decisions.\n",
    "    \n",
    "    JUSTIFICATION:\n",
    "    Even if we don't use ML, we can find thresholds by:\n",
    "    - Comparing distributions of features split by action\n",
    "    - Looking for clear separation points\n",
    "    - Testing specific threshold hypotheses\n",
    "    \"\"\"\n",
    "    print_section(\"2E. THRESHOLD DETECTION\")\n",
    "    \n",
    "    if df is None:\n",
    "        print(\"No data available\")\n",
    "        return\n",
    "    \n",
    "    # For each numeric feature, compare distributions by action\n",
    "    print_subsection(\"Feature Distributions by Action\")\n",
    "    \n",
    "    numeric_features = ['btc_return_5s', 'btc_return_15s', 'btc_return_30s', 'btc_return_60s',\n",
    "                       'up_spread', 'down_spread', 'seconds_into_window']\n",
    "    \n",
    "    for feat in numeric_features:\n",
    "        if feat not in df.columns:\n",
    "            continue\n",
    "        \n",
    "        print(f\"\\n{feat}:\")\n",
    "        stats = df.groupby('action')[feat].agg(['mean', 'median', 'std'])\n",
    "        print(stats.round(6))\n",
    "    \n",
    "    # Specific hypothesis tests\n",
    "    print_subsection(\"Hypothesis Tests\")\n",
    "    \n",
    "    # Hypothesis 1: Bot buys UP when BTC is rising\n",
    "    if 'btc_return_30s' in df.columns:\n",
    "        print(\"\\nH1: Bot buys UP when BTC 30s return > 0\")\n",
    "        \n",
    "        buy_up = df[df['action'] == 'BUY_Up']\n",
    "        buy_down = df[df['action'] == 'BUY_Down']\n",
    "        \n",
    "        if len(buy_up) > 0 and len(buy_down) > 0:\n",
    "            pct_buy_up_when_btc_positive = (buy_up['btc_return_30s'] > 0).mean() * 100\n",
    "            pct_buy_down_when_btc_positive = (buy_down['btc_return_30s'] > 0).mean() * 100\n",
    "            \n",
    "            print(f\"  BUY UP trades with positive BTC return: {pct_buy_up_when_btc_positive:.1f}%\")\n",
    "            print(f\"  BUY DOWN trades with positive BTC return: {pct_buy_down_when_btc_positive:.1f}%\")\n",
    "            \n",
    "            if pct_buy_up_when_btc_positive > 60:\n",
    "                print(\"  â†’ MOMENTUM STRATEGY: Buying direction of BTC movement\")\n",
    "            elif pct_buy_up_when_btc_positive < 40:\n",
    "                print(\"  â†’ MEAN REVERSION STRATEGY: Fading BTC movement\")\n",
    "            else:\n",
    "                print(\"  â†’ MIXED or COMPLEX strategy\")\n",
    "    \n",
    "    # Hypothesis 2: Bot trades more actively early in window\n",
    "    if 'seconds_into_window' in df.columns:\n",
    "        print(\"\\nH2: Bot trades early in 15-min window\")\n",
    "        \n",
    "        early = (df['seconds_into_window'] < 300).mean() * 100  # First 5 min\n",
    "        mid = ((df['seconds_into_window'] >= 300) & (df['seconds_into_window'] < 600)).mean() * 100\n",
    "        late = (df['seconds_into_window'] >= 600).mean() * 100\n",
    "        \n",
    "        print(f\"  Early (0-5 min): {early:.1f}%\")\n",
    "        print(f\"  Mid (5-10 min): {mid:.1f}%\")\n",
    "        print(f\"  Late (10-15 min): {late:.1f}%\")\n",
    "    \n",
    "    # Hypothesis 3: Bot only trades when spread is below threshold\n",
    "    if 'up_spread' in df.columns:\n",
    "        print(\"\\nH3: Bot trades only when spread < threshold\")\n",
    "        \n",
    "        spread_percentiles = df['up_spread'].quantile([0.25, 0.5, 0.75])\n",
    "        print(f\"  UP spread percentiles: 25%={spread_percentiles[0.25]:.4f}, \" +\n",
    "              f\"50%={spread_percentiles[0.5]:.4f}, 75%={spread_percentiles[0.75]:.4f}\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# 2F. EVENT STUDY\n",
    "# ============================================================================\n",
    "\n",
    "def event_study(trades_df, btc_df, window_before=60, window_after=60):\n",
    "    \"\"\"\n",
    "    Align all trades to t=0 and plot average BTC price around trades.\n",
    "    \n",
    "    JUSTIFICATION:\n",
    "    This visually reveals what BTC was doing before and after trades.\n",
    "    If bot uses momentum: BTC will be moving in trade direction before entry\n",
    "    If bot uses mean-reversion: BTC will be moving opposite before entry\n",
    "    \"\"\"\n",
    "    print_section(\"2F. EVENT STUDY (Price Action Around Trades)\")\n",
    "    \n",
    "    if trades_df is None or btc_df is None:\n",
    "        print(\"Missing required data\")\n",
    "        return\n",
    "    \n",
    "    if not PLOTTING_AVAILABLE:\n",
    "        print(\"matplotlib not available - skipping event study visualization\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Analyzing price action from -{window_before}s to +{window_after}s around trades\")\n",
    "    \n",
    "    btc_sorted = btc_df.sort_values('datetime')\n",
    "    \n",
    "    # For each action type, collect price paths\n",
    "    action_paths = {}\n",
    "    \n",
    "    for action in trades_df['action'].unique():\n",
    "        action_trades = trades_df[trades_df['action'] == action]\n",
    "        paths = []\n",
    "        \n",
    "        for _, trade in action_trades.iterrows():\n",
    "            trade_time = trade['datetime']\n",
    "            start_time = trade_time - timedelta(seconds=window_before)\n",
    "            end_time = trade_time + timedelta(seconds=window_after)\n",
    "            \n",
    "            # Get BTC prices in this window\n",
    "            window_btc = btc_sorted[\n",
    "                (btc_sorted['datetime'] >= start_time) & \n",
    "                (btc_sorted['datetime'] <= end_time)\n",
    "            ].copy()\n",
    "            \n",
    "            if len(window_btc) > 10:  # Need enough data points\n",
    "                # Normalize: set t=0 price to 0 (show relative change)\n",
    "                window_btc['rel_time'] = (window_btc['datetime'] - trade_time).dt.total_seconds()\n",
    "                \n",
    "                # Get price at t=0 (closest to trade time)\n",
    "                t0_idx = (window_btc['rel_time'].abs()).idxmin()\n",
    "                t0_price = window_btc.loc[t0_idx, 'price']\n",
    "                \n",
    "                # Express as percentage change from t=0\n",
    "                window_btc['rel_price'] = (window_btc['price'] / t0_price - 1) * 100\n",
    "                \n",
    "                paths.append(window_btc[['rel_time', 'rel_price']])\n",
    "        \n",
    "        if paths:\n",
    "            action_paths[action] = paths\n",
    "            print(f\"  {action}: {len(paths)} valid trade windows\")\n",
    "    \n",
    "    # Plot average paths\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    \n",
    "    colors = {'BUY_Up': 'green', 'SELL_Up': 'lightgreen', \n",
    "              'BUY_Down': 'red', 'SELL_Down': 'lightcoral'}\n",
    "    \n",
    "    for action, paths in action_paths.items():\n",
    "        # Interpolate all paths to common time grid\n",
    "        time_grid = np.linspace(-window_before, window_after, 121)  # 1-second resolution\n",
    "        \n",
    "        interp_paths = []\n",
    "        for path_df in paths:\n",
    "            interp_price = np.interp(time_grid, path_df['rel_time'], path_df['rel_price'])\n",
    "            interp_paths.append(interp_price)\n",
    "        \n",
    "        # Calculate mean and confidence interval\n",
    "        interp_paths = np.array(interp_paths)\n",
    "        mean_path = np.mean(interp_paths, axis=0)\n",
    "        std_path = np.std(interp_paths, axis=0)\n",
    "        \n",
    "        color = colors.get(action, 'gray')\n",
    "        ax.plot(time_grid, mean_path, label=f'{action} (n={len(paths)})', \n",
    "                color=color, linewidth=2)\n",
    "        ax.fill_between(time_grid, mean_path - std_path, mean_path + std_path,\n",
    "                       alpha=0.2, color=color)\n",
    "    \n",
    "    ax.axvline(x=0, color='black', linestyle='--', alpha=0.5, label='Trade Time')\n",
    "    ax.axhline(y=0, color='gray', linestyle='-', alpha=0.3)\n",
    "    ax.set_xlabel('Seconds Relative to Trade')\n",
    "    ax.set_ylabel('BTC Price Change (%)')\n",
    "    ax.set_title('Event Study: BTC Price Action Around Bot Trades')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(CONFIG['output_dir'] + 'event_study.png', dpi=150, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"\\nâœ“ Saved: {CONFIG['output_dir']}event_study.png\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# SUMMARY REPORT\n",
    "# ============================================================================\n",
    "\n",
    "def generate_phase2_summary(df):\n",
    "    \"\"\"Generate a summary of Phase 2 findings\"\"\"\n",
    "    print_section(\"PHASE 2 SUMMARY: STRATEGY HYPOTHESIS\")\n",
    "    \n",
    "    if df is None:\n",
    "        print(\"No data available for summary\")\n",
    "        return\n",
    "    \n",
    "    print(\"\\nðŸ“Š STRATEGY INDICATORS\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Direction logic\n",
    "    if 'btc_return_30s' in df.columns:\n",
    "        buy_up = df[df['action'] == 'BUY_Up']\n",
    "        buy_down = df[df['action'] == 'BUY_Down']\n",
    "        \n",
    "        if len(buy_up) > 0:\n",
    "            btc_up_before_buy_up = (buy_up['btc_return_30s'] > 0).mean()\n",
    "            print(f\"\\n1. DIRECTION LOGIC:\")\n",
    "            print(f\"   BTC rising (30s) before BUY UP: {btc_up_before_buy_up*100:.1f}%\")\n",
    "            \n",
    "            if btc_up_before_buy_up > 0.6:\n",
    "                print(f\"   â†’ MOMENTUM: Bot follows BTC direction\")\n",
    "            elif btc_up_before_buy_up < 0.4:\n",
    "                print(f\"   â†’ MEAN REVERSION: Bot fades BTC moves\")\n",
    "            else:\n",
    "                print(f\"   â†’ COMPLEX: Not simple momentum or reversion\")\n",
    "    \n",
    "    # Timing logic\n",
    "    if 'seconds_into_window' in df.columns:\n",
    "        avg_entry_time = df['seconds_into_window'].mean()\n",
    "        print(f\"\\n2. TIMING LOGIC:\")\n",
    "        print(f\"   Average entry: {avg_entry_time:.0f}s into window\")\n",
    "        print(f\"   ({avg_entry_time/60:.1f} minutes)\")\n",
    "    \n",
    "    # Sizing logic\n",
    "    size_std = df['size'].std()\n",
    "    size_mean = df['size'].mean()\n",
    "    cv = size_std / size_mean if size_mean > 0 else 0\n",
    "    print(f\"\\n3. SIZING LOGIC:\")\n",
    "    print(f\"   Size CV (std/mean): {cv:.2f}\")\n",
    "    if cv < 0.1:\n",
    "        print(f\"   â†’ FIXED SIZING: Nearly constant position size\")\n",
    "    else:\n",
    "        print(f\"   â†’ VARIABLE SIZING: Adaptive position sizing\")\n",
    "    \n",
    "    # Overall summary\n",
    "    print(f\"\\n\" + \"=\"*40)\n",
    "    print(\"PRELIMINARY STRATEGY DESCRIPTION:\")\n",
    "    print(\"=\"*40)\n",
    "    print(\"\\n[Fill this in based on the analysis results above]\")\n",
    "    print(\"\\nThe bot appears to:\")\n",
    "    print(\"- Entry trigger: [momentum / mean-reversion / spread-based]\")\n",
    "    print(\"- Exit trigger: [time-based / profit-target / price-based]\")\n",
    "    print(\"- Position sizing: [fixed / scaled]\")\n",
    "    print(\"- Timing: [early / mid / late window]\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# MAIN EXECUTION\n",
    "# ============================================================================\n",
    "\n",
    "def main():\n",
    "    \"\"\"Run the complete Phase 2 analysis\"\"\"\n",
    "    print(\"=\"*80)\n",
    "    print(\" POLYMARKET BOT STRATEGY ANALYSIS - PHASE 2\")\n",
    "    print(\" Merged Analysis & Strategy Identification\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"\\nStarted at: {datetime.now()}\")\n",
    "    \n",
    "    # Load processed data from Phase 1\n",
    "    print(\"\\nLoading Phase 1 processed data...\")\n",
    "    \n",
    "    try:\n",
    "        btc_df = pd.read_parquet(CONFIG['btc_processed'])\n",
    "        print(f\"  âœ“ BTC: {len(btc_df):,} rows\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"  âœ— BTC data not found - run Phase 1 first\")\n",
    "        btc_df = None\n",
    "    \n",
    "    try:\n",
    "        trades_df = pd.read_parquet(CONFIG['trades_processed'])\n",
    "        print(f\"  âœ“ Trades: {len(trades_df):,} rows\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"  âœ— Trades data not found - run Phase 1 first\")\n",
    "        trades_df = None\n",
    "    \n",
    "    try:\n",
    "        positions_df = pd.read_parquet(CONFIG['positions_processed'])\n",
    "        print(f\"  âœ“ Positions: {len(positions_df):,} rows\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"  âœ— Positions data not found\")\n",
    "        positions_df = None\n",
    "    \n",
    "    try:\n",
    "        orderbook_df = pd.read_parquet(CONFIG['orderbook_processed'])\n",
    "        print(f\"  âœ“ Orderbook: {len(orderbook_df):,} rows\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"  âœ— Orderbook data not found\")\n",
    "        orderbook_df = None\n",
    "    \n",
    "    if trades_df is None:\n",
    "        print(\"\\nâœ— Cannot proceed without trades data\")\n",
    "        return\n",
    "    \n",
    "    # Run analyses\n",
    "    trades_btc = merge_trades_with_btc(trades_df, btc_df)\n",
    "    trades_ob = merge_trades_with_orderbook(trades_df, orderbook_df)\n",
    "    \n",
    "    full_df = create_full_state_dataframe(trades_df, btc_df, orderbook_df, positions_df)\n",
    "    \n",
    "    models = identify_strategy_with_decision_tree(full_df)\n",
    "    detect_thresholds(full_df)\n",
    "    event_study(trades_df, btc_df)\n",
    "    \n",
    "    generate_phase2_summary(full_df)\n",
    "    \n",
    "    print(f\"\\nâœ“ Phase 2 analysis complete at: {datetime.now()}\")\n",
    "    print(f\"âœ“ Output saved to: {CONFIG['output_dir']}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57972ed-66a6-4601-a563-e172e82aa3b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
